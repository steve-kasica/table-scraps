- name: Source
  desc: 'Codes that describe how the raw data was obtained by journalists'
  sub:
      - name: Collect Data
        desc: 'Journalists are the initial data collector'
        sub:
          - name: Collect Raw Data
            desc: 'The journalist collected the raw data themselves.'
          - name: Freedom of Information Data
            desc: 'Data that was obtained via FOI/FOIA requests'
      - name: Acquire Data
        desc: 'Journalists acquired data from another party'
        sub:
          - name: Use Previously Cleaned Data
            desc: 'Data that originated from a colleague'
          - name: Use Public Data
            desc: 'Includes open-source datasets, datasets on Wikipedia, etc'
          - name: Use Academic Data
            desc: 'Use data collected from an academic study'
          - name: Use Non-Public, Provided data
            desc: 'Use data that is not publically available'
          - name: govt data portal
            alias: Use Open-Government Data Portal
            desc: 'Data publically available on civic data portals'
          - name: Use Another News Orgs Data
            alias: "Use Another News Organization's Data"
            desc: 'A dataset previously published by another news organization'
          - name: use data from colleague
            alias: "Use a colleague's Data"
            desc: 'A dataset was provided by another journalist'
- name: Workflow
  desc: 'Codes pertaining to how the wrangling workflow is built.'
  sub:
    - name: Annotations
      desc: 'Adding comments or notes in Markdown that explain what the journalists doing.'
    - name: Comp. processes
      alias: 'Computational Process'
      desc: 'Codes that demonstrate computational thinking on the part of the journalist.'
      sub:
        - name: Construct a Subroutine
          desc: 'A set of instructions grouped together to be performed multiple times'
        - name: Construct Data Pipeline
          desc: 'An instance where one script is designed to handle multiple data sources. Often journalists construct subroutines and loops.'
    - name: Toggle Operation
      desc: 'Ensuring that some code segments are not always run, such as by commenting out lines of code'
- name: Cause
  desc: 'Based on the final output and comments, why does it seem like this data needs to be wrangled?'
  sub:
    - name: Downstream Input
      desc: 'Output from wrangling will be input into some other program'
      sub:
        - name: Wrangle Data for Graphics
          desc: 'Data need to be formatted in order to be visualized in an article, including datasets.'
        - name: Wrangle Data for Model
          desc: 'Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification'
        - name: Create New Datasets
          desc: 'These raw datasets are being wrangled in order to create a new dataset'
          sub:
            - name: Combine Periodic Data
              desc: 'Combine many separate datasets published over time into one dataset'
            - name: Merge Seemingly Disparate Datasets
              desc: 'When a notebook largely constitutes combining seemingly unrelated datasets'
            - name: Geolocate Dataset Records
              desc: 'Pairing data with GIS info'
        - name: Generate High-Level Summary
          desc: 'Data of individual observations is aggregated in an attempt to find some meaningful structure or patterns'
- name: Themes
  desc: 'General themes for how data objects are transformed throughout the wrangling process'
  sub:
    - name: Divide and Conquer
      desc: "Instances where the data wrangling processes separates one objects into smaller components"
      sub:
        - name: Split, Compute, and Merge
          desc: 'First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again'
        - name: Split and Compute
          desc: 'One dataset is split into two or more and identical computations are applied to each dataset'      
    - name: Join Aggregate
      desc: 'When aggregated statistics about a dataset are added to the datasets as a variable, either columnwise or row-wise (as with `adorn_totals` in R)'      
    - name: Create a Frequency Table
      desc: 'A table the displays the frequency of categorical variables within a column'
    - name: Trim Fat
      desc: 'Trim the fat refers to when large amounts of observations or variables are removed from the dataset early in the wrangling processes, if not as the first step of wrangling. We infer that these sections are irrelevant to further analysis.'      
    - name: Align Variables
      desc: 'Modifying dataset variables to match each other, often prior to merging datasets.'          
- name: Analysis
  desc: 'Kinds of analysis data journalists need to wrangle data to perform'
  sub:
    - name: interpret statistical/ML model
      alias: Interpret Model
      desc: 'Analyze features from a model such as linear regression or classification trees'
    - name: Compare Groups
      desc: 'The end analysis is just comparing different groups by a common metric'
    - name: Identify Extreme Values
      desc: 'Identify values that are at the ends of the range, but not strictly outliers'
    - name: Show Trend Over Time
      desc: 'Analysis consists of showing how values change over time'
    - name: Calculate a Statistic
      desc: 'Calculate a single value from a dataset, such as number of records'
    - name: Count the Data
      desc: 'Analysis involves count-based metrics on the datasets including percentages, with optional filtering and aggregation'
    - name: Lookup Table Values
      desc: 'Analysis consists looking up values in a table'
    - name: Examine Relationship
      desc: 'Analysis consists of examining the relationship between different phenomena'
    - name: Explain Variance
      desc: 'This can be done via PCA'
    - name: Search for Clusters
      desc: 'Look for groups within the data where its presence, or lack thereof, is significant'
    - name: Perform Network Analysis
      desc: 'Journalists perform any kind of network analysis, such as finding all nearest neighbors in the network'
    - name: Explore Dynamic Network Flow
      desc: '(Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities'
    - name: Create Lookup Table
      desc: 'Make a table with two columns to map from one value to another'          
    - name: Aggregate Join
      desc: 'Aggregating a table and then joining those results to the original table'
- name: Management
  desc: 'General strategies journalists for anaging data within the wrangling environment'
  sub:
    - name: Object Persistence
      desc: 'How do journalists regard previous version of datasets after applying transformation functions?'
      sub:
        - name: Data Evolves
          desc: 'Data and objects are overwritten and replaced during the wrangling process'
          sub:
            - name: Variable Replacement
              desc: 'The output of any column calculation is reassigned to an existing column'
            - name: Temporary Joining Column
              desc: 'When a key for joining two datasets is created and deleted immediately after the join'
            - name: Refine Table
              desc: 'Dataset refinement refers to when a table is subset in place, a new object is not created in the environment'
        - name: preserve existing values
          alias: Data is Precious
          desc: 'Previous "versions" of datasets, variables, and observations are left intact within the environment'
    - name: Data Quality
      desc: 'How journalits proceed when data may be incomplete, erroneous, or otherwise not 100% clean'
      sub:
        - name: Set Data Confidence Threshold
          desc: 'Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value'
        - name: Tolerate Dirty Data
          desc: 'Analysis continues despite clear data quality issues'
- name: Pain Points
  desc: 'Areas where journalist seem/could be frustrated in the wrangling process'
  sub:
    - name: Fix Incorrect Calculation
      desc: 'Calculations in the data are incorrect and the journalist must recalculate them'      
    - name: Repetitive Code
      desc: 'Instances where code is repetitively copied and pasted'
    - name: Make an Incorrect Conclusion
      desc: 'Instances where the journalist has made an incorrect conclusion about the data'
    - name: Post-Merge Clean Up
      desc: 'Pain points that come from the result of merging two datasets together'
      sub:
        - name: Resort after Merge
          desc: 'When a sort has to be re-done because a merge ruining the pre-merged order'
        - name: Fill in NA Values After an Outer Join
          desc: 'As outer joins do not drop non-matching rows, those values have NA'
        - name: Lossy Join
          desc: 'When data is lost after integrating two tables'
        - name: Remove Duplicate Variables
          desc: 'Two tables may have duplicate variables and duplicate variables need to be removed'
    - name: Post-Aggregation Clean Up
      desc: 'Pain points that come from the result of grouping a table'
      sub:
        - name: Data Loss from Aggregation
          desc: 'When table columns are lost because they were dropped form resulting dataset due to not being relevant in aggregation'
        - name: Silently Dropping Values After Groupby
          desc: 'Values other than those being grouped and calculated upon are lost in a group-by operation'
    - name: Data too Large for Repo
      desc: 'Raw data cannot be included because files are too large'
    - name: Schema Drift
      desc: 'When the schema of a perennially published datasets varies from edition to edition'
    - name: Data Type Shyness
      desc: 'Users often seem to avoid using built in data types'