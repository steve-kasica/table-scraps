{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook\n",
    "\n",
    "This Jupyter notebook has two purposes. First, to parse all the open codes in PDF versions of computational notebooks located in the `notebooks` direction into a Pandas Data Frame and export that table as `codes.csv`. This is accomplished in the `parseCodes` First, the [Displace Codes](#Display-Codes) section displays the taxonomy represented in `code_tree.yaml` in a human-readable format. Second, the [Quality Control](#Quality-Control) section parses all the open codes in the PDF version of computational notebooks, scattered in the `notebooks` directory and identifies any difference in this set of codes and those manually written into `code_tree.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, yaml\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from lib.util import getCodes\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate rows when printing a Pandas DataFrame instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Codes\n",
    "\n",
    "All open codes, their descriptions, and the corresponding axial codes are stored in the `code_tree.yaml` file. As the master copy for all open and axial codes resides in the `code_tree.yaml` file, the raw text itself can be difficult to read. Thus, this snippet renders all the codes in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Codes\n",
       "* **Actions**: Codes that describe actions the journalist has taken to wrangle data for further analysis.\n",
       "\t* **Import**: Methods for importing data into an environment for wrangling.\n",
       "\t\t* **Download**: Data is imported via download from an external source, such as a RESTful API.\n",
       "\t\t\t* **Geocode Addresses**: Translate addresses to latitude-longitude coordinates through web service, such as those from Bing.\n",
       "\t\t\t* **Scrape Web For Data**: Systematically parsing webpages for relevant data.\n",
       "\t\t\t* **Query Database**: Data is imported through a database query.\n",
       "\t\t* **Create**: Data is created inside the wrangling environment.\n",
       "\t\t\t* **Construct Table Manually**: Using tables where column names and table values were either copy-and-pasted or entered manually.\n",
       "\t\t\t* **Generate Data Computationally**: Using tables populated programatically.\n",
       "\t\t\t* **Copy Table Schema**: A table is copied without any values but table column names and type identical, or nearly identical, to another table.\n",
       "\t\t* **Extract**: Extraction occurs when data is one step removed from the format it needs to be in to be imported into the environment.\n",
       "\t\t\t* **Pull Tables Out Of Pdf**: Using a table extraction tool, such as Tabula, to parse tables inside PDF documents.\n",
       "\t\t* **Read**: Import data by reading a file on disk such as a CSV\n",
       "\t\t\t* **Read As Tabular Data**: Refers to importing files from disk as a table in the environment. Files can be .csv, .xlsx, .fec, and .shp, .RData\n",
       "\t* **Amend**: *Amending* a table constitutes creating new columns in the table without *integrating* other tables.\n",
       "\t\t* **Detrend**: \"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating,\" Philip Meyer in *Precision Journalism*.\n",
       "\t\t\t* **Adjust For Inflation**: TK\n",
       "\t\t\t* **Compute Index Number**: TK\n",
       "\t\t* **Encode Table Identification In Row**: When some way of identifying the table is encoded as a separate column in each row. Common identification methods include the name of the corresponding file, an arbitrary table name, or boolean value.\n",
       "\t\t* **Support Network Analysis**: Actions that modify a table to directly support network analysis\n",
       "\t\t\t* **Create Edge**: A column with value that define a relationship to another row, which is not necessarily in a different table.\n",
       "\t\t\t* **Define Edge Weights**: Columns that define edge weights\n",
       "\t\t* **Formulate Performance Metric**: Codes in this category specify a calculation that is later used to compare different entities or the same entity over time. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.\n",
       "\t\t\t* **Calculate Standardized Score**: Measuring deviation from some definition of \"normal.\"\n",
       "\t\t\t\t* **Calculate Z-Score**: Calculate how many standard deviations a value in a column is away from the mean. Journalists perform this function to simply find outliers in a dataset or when preparing the data for principle component analysis.\n",
       "\t\t\t* **Calculate Normalized Score**: Measuring the differences between groups of different sizes.\n",
       "\t\t\t\t* **Calculate Ratio**: Dividing a quantitative variable by another in such a way that enables fair comparisons. Such as per capita\n",
       "\t\t\t\t* **Calculate Scaled Ratio**: For example, calculating per 1,000 rates and percentages.\n",
       "\t\t\t* **Calculate The Central Tendency**: Measuring what a typical value is in the data.\n",
       "\t\t\t\t* **Calculate Mean**: The average of a set of numbers.\n",
       "\t\t\t\t* **Calculate Median**: The middle value in a range of numbers.\n",
       "\t\t\t* **Calculate Change**: Measuring how much things change, usually over time.\n",
       "\t\t\t\t* **Calculate Percentage Difference**: \"the difference between two values taken as a percentage of whichever value you are using as the base,\" according to Philip Meyer in *Precision Journalism.* This term is synonymous with percent change.\n",
       "\t\t\t\t* **Calculate Difference**: Subtracting two quantitative variables, including scalar values, vectors, and matricies.\n",
       "\t\t* **Key Generation**: Operations that create \"key\" columns.\n",
       "\t\t\t* **Create A Semi-Unique Key**: Journalist creates a key that is a close, but imperfect, unique key, e.g. concatenating first name and surname.\n",
       "\t\t\t* **Create A Unique Key**: Journalist create a key that is actually unique in the table\n",
       "\t\t\t* **Concatenate Columns Into Key**: TK\n",
       "\t\t\t* **Designate Column As Primary Key**: Designating a column as the unique identifier for all rows in the table.\n",
       "\t\t* **Rank Data**: Operations that encode semantic meaning about the data with table index.\n",
       "\t\t\t* **Assign Ranks**: When a column of numerical ranks is explicitly assigned to rows in the table.\n",
       "\t\t\t* **Break Ties**: When the user specifies a way of breaking ties\n",
       "\t\t\t* **Sort Table**: When rank is implicitly assigned by rearranging row position in the table.\n",
       "\t\t* **Create Flag**: Flags are boolean expressed computed upon column values and used in filtering and grouping\n",
       "\t* **Clean**: Operations to correct erroneous or remove otherwise unwanted rows and values from the table.\n",
       "\t\t* **Trim Fat**: Winnow down data that is not relevant to analysis.\n",
       "\t\t\t* **Winnow Columns**: Simply put, these operations remove table columns.\n",
       "\t\t\t\t* **Subset Columns**: Removing columns from a table by specifying which ones to remove or keep.\n",
       "\t\t\t\t* **Align Table Columns For Consolidation**: TK\n",
       "\t\t\t* **Winnow Rows**: Simply put, these operations remove table rows.\n",
       "\t\t\t\t* **Trim By Date Range**: Removing rows that are inside or outside a specific date range. This can be a method for detrending data by adjusting for season.\n",
       "\t\t\t\t* **Trim By Geographic Area**: Remove rows that are inside or outside a geographic area.\n",
       "\t\t\t\t* **Trim By Quantitative Threshold**: Remove rows that are above, below, equal to, or not equal to a numeric value.\n",
       "\t\t\t\t* **Trim By Contains Value**: Remove rows that do or do not contain specific values or types of values.\n",
       "\t\t\t* **Remove Incomplete Data**: Drop row if value(s) are incomplete, usually denoted as NA.\n",
       "\t\t\t* **Drop Erroneous Rows**: Remove rows that have any number of kinds of errors in them.\n",
       "\t\t\t* **Deduplicate**: Remove rows from the table that contain two or more of the same \"observation.\" Duplicates may constitute rows with identical values in all, one, or zero columns.\n",
       "\t\t\t\t* **Drop Duplicate Rows Based On Prior Knowledge**: Drop row based on prior, possibly dataset-specific, knowledge about this dataset, such as \"Master Records.\"\n",
       "\t\t\t\t* **Drop Duplicate Rows Based On Values**: Drop row if one or more column values exactly matches all, or some, the same column values of another row.\n",
       "\t\t* **Edit**: Operations that modify table values\n",
       "\t\t\t* **Replace Na Values**: Raw data may contain incomplete table values (denoted as NA) or empty values (denoted as NULL)\n",
       "\t\t\t* **Fix Data Errors Manually**: Instances where individual row-column values are changed by a journalist.\n",
       "\t\t\t* **Fix Incorrect Calculation**: TK\n",
       "\t\t\t* **Map Values**: Codes that have to do with defining the relationship between two sets of column values\n",
       "\t\t\t\t* **Translate Entity Names**: Performing a bijective mapping between values, often to improve semantic meaning.\n",
       "\t\t\t\t\t* **Translate Entity Names Manually**: Manually specify the mapping between individual\n",
       "\t\t\t\t\t* **Pad Column Values**: Adding either character prefixes or suffixes consistently to every row within a column\n",
       "\t\t\t\t\t* **Join With Lookup Table**: Two column tables meant for mapping a key from one table to the unique column in the lookup table.\n",
       "\t\t\t\t\t* **Scale Values**: Operations that apply some mathematical operation to columns of quantitative data. This code is different from the codes under **Formulate performance metric** because this closer to cleaning.\n",
       "\t\t\t\t\t\t* **Transform Vector**: Apply a transformation to a vectory, such as scalar multiplication\n",
       "\t\t\t\t\t\t* **Whiten Matrix**: Divide each feature by its standard deviation across all observations to give it unit variance.\n",
       "\t\t\t\t* **Remove With Regular Expression**: When column values are replaced with empty strings using regular expressions.\n",
       "\t\t\t\t* **Resolve Entities**: A surjective mapping from previous column values to new column values\n",
       "\t\t\t\t\t* **Perform Entity Resolution Manually**: Manually specifying the mapping between categorical values, not changing individual rows.\n",
       "\t\t\t\t\t* **Strip Whitespace**: Removing extra whitespace characters from entity name\n",
       "\t\t\t\t\t* **Combine Entities By String Matching**: If column contains a specific string, then rename entire column to another string.\n",
       "\t\t\t\t\t* **Reconcile Primary Keys Between Tables**: Name entity resolution between tables to facilitate joining\n",
       "\t\t\t\t\t* **Resolve To Arbitrary Entity Name Among Choices**: The actual text of the entity is not necessary as import as uniqueness.\n",
       "\t\t\t\t\t* **Bin Values**: Classifying quantitative data into categories, e.g. x > 100 <=> category = \"under spent\" and x > 100 <=> category = \"over spent\"\n",
       "\t\t\t* **Backfill Missing Data**: Create new \"rows\" in the data where there are missing entries.\n",
       "\t\t* **Format**: Operations that modify the table values appearance or style.\n",
       "\t\t\t* **Format Values**: Operations that modify the values within the table.\n",
       "\t\t\t\t* **Change Case**: Change the case of string values.\n",
       "\t\t\t\t* **Change Date Format**: Specify the format which dates should be displayed\n",
       "\t\t\t\t* **Round Floating Point**: Round foating point numbers.\n",
       "\t\t\t\t* **Correct Bad Formatting**: Changes that correct ill-formed data such as HTML entities and new lines (\\n)\n",
       "\t\t\t* **Format Schema**: Operations that modify anything except table values.\n",
       "\t\t\t\t* **Canonicalize Column Names**: Operations that change column names\n",
       "\t\t\t\t* **Change Column Data Type**: For example, changing a column of values from strings to integers\n",
       "\t\t\t* **Sort Table Rows**: Sorting a table in a way that does not rank rows, such as by a unique identifier\n",
       "\t\t* **Separate**: Mapping one column into more than one because multiple dimensions of the dataset packed into one column.\n",
       "\t\t\t* **Extract Property From Datetime**: Such as extracting the day of the month, year, etc.. from a datetime column\n",
       "\t\t\t* **Slice Column Values**: Extracting the relevant column values by character position, e.g. the first five digits of a zip code.\n",
       "\t\t\t* **Split Column On Delimiter**: Separate data dimensions by a common character, e.g. lat-long coordinates separated by a comma.\n",
       "\t\t\t* **Get Unique Values**: TK\n",
       "\t\t* **Combine Columns**: Combining two columns into one\n",
       "\t* **Integrate**: Combining data residing in different tables into one table.\n",
       "\t\t* **Consolidate**: Consolidation is characterized by actions that add essentially combine rows of two tables.\n",
       "\t\t\t* **Union Tables**: TK\n",
       "\t\t\t* **Concatenate Files Together**: TK\n",
       "\t\t* **Intersect**: Joining two tables such that non-matching rows are excluded from the combined table.\n",
       "\t\t\t* **Inner Join Tables**: TK\n",
       "\t\t* **Supplement**: Supplementation is characterized by integration operations that essentially add columns to existing data\n",
       "\t\t\t* **Outer Join Tables**: A join that returns rows with no corresponding match in the table being joined two, e.g. left or right joins.\n",
       "\t\t\t* **Compute An Inter-Table Column**: When a table uses a column from a *parallel* table (like arrays) to compute a new column.\n",
       "\t\t\t* **Concat Parallel Tables**: When columns from multiple, parallel tables are concatenated together to form a new table.\n",
       "\t\t\t* **Self Join Table**: Join a table with itself\n",
       "\t\t\t* **Full Join Tables**: Combine all rows and all columns of the two tables. a.k.a full outer join\n",
       "\t\t* **Other**: Integration operations that do not fall into the previous two categories\n",
       "\t\t\t* **Cartesian Product**: TK\n",
       "\t* **Transform**: Operations that transform a table into an aggregated, lower-resolution view of the original table.\n",
       "\t\t* **Summarize**: \n",
       "\t\t\t* **Join Aggregate**: \"extends the input data objects with aggregate values in a new field\" - Vega-Lite Join Aggregate docs.\n",
       "\t\t\t* **Group**: Codes that group the table along one or more table dimension.\n",
       "\t\t\t\t* **Single Dimensional Group By**: Grouping one or more columns such that grouped columns are hierarchically ordered when grouping by two or more columns. This operation is commonly implemented with `groupby` in Pandas.\n",
       "\t\t\t\t\t* **Group By Single Column**: When a table is grouped by a single column.\n",
       "\t\t\t\t\t* **Group By Multiple Columns**: When a table is grouped by multiple columns, creating hierarchy.\n",
       "\t\t\t\t\t* **Create Lookup Table**: Creating a table with two columns that serves as a map from one value to another.\n",
       "\t\t\t\t* **Group By Double Axis**: Grouping by more than one column such that one grouped column is not hierarchically paired with another grouped column.\n",
       "\t\t\t\t\t* **Construct Pivot Table**: Is essentially the same as a crosstab except that the table axes may contain hierarchical, nominal data.\n",
       "\t\t\t\t\t* **Create A Crosstab**: User performs a crosstab query, as defined by [Microsoft Office](https://support.office.com/en-us/article/make-summary-data-easier-to-read-by-using-a-crosstab-query-8465b89c-2ff2-4cc8-ba60-2cd8484667e8). Crosstabs are very similar to the reshaping operation *spread*, except that they summarize values using aggregate functions.\n",
       "\t\t\t\t* **Create Rolling Window**: \n",
       "\t\t* **Calculate**: These are within-column calculations that often, but not always, immediately follow an *aggregation* operation.\n",
       "\t\t\t* **Sum Along Dimension**: Calculate the sum of all values within a row or column\n",
       "\t\t\t* **Get Extreme Values**: Calculate the highest or lowest value(s)\n",
       "\t\t\t* **Count Value Frequency**: Count the frequency of categorical variables within a column\n",
       "\t\t\t* **Count Unique Values In Column**: \n",
       "\t\t* **Reshape**: Operations fundamentally change the table's structure, but do not perform any kind of summarization calculation. *Constructing a pivot table* often involves a *spread-like* operation when defining what values to use as columns in the new table. The difference with *reshaping* is that sometimes the journalist may not summarize the reshaped table.\n",
       "\t\t\t* **Spread Table**: Expand two columns of key value pairs into multiple columns.\n",
       "\t\t\t* **Gather Table**: Collapses table into key value pairs.\n",
       "\t* **Display Dataset**: Different ways to check in on the state of the dataset during wrangling.\n",
       "\t\t* **Display A Table**: Operations that have to do with displaying the raw data as a table.\n",
       "\t\t\t* **Format Table Display**: Operations that adjust the table displace, such as how many decimals to round floats\n",
       "\t\t* **Understand Distribution**: Operations that reveal something of the underlying distribution of data.\n",
       "\t\t\t* **Visualize Data**: Employing any kind of data visualzation, including a table\n",
       "\t* **Check Sanity**: Operations that confirm the effect of a previous wrangling operation.\n",
       "\t\t* **Run A Test**: Operations output a clear pass or fail value, often implemented by counting things.\n",
       "\t\t\t* **Report Rows With Column Number Discrepancies**: Finds if a row has a different number of columns than the header row.\n",
       "\t\t\t* **Compare Total Number Of Rows**: \n",
       "\t\t\t* **Test For Equality**: Test if two data structures are exactly the same, e.g. two data frames.\n",
       "\t\t\t* **Test Different Computations For Equality**: \n",
       "\t\t* **Check Results**: Operations that output some visual representation of the table.\n",
       "\t\t\t* **Check Results Of Previous Operation**: \n",
       "\t\t\t* **Peek At Data**: Display the first *n* rows and all columns of the table\n",
       "\t\t\t* **Inspect Table Schema**: \n",
       "\t\t\t* **Display Rows With Missing Values**: E.g. filtering rows with a NA value in a particular column\n",
       "\t\t\t* **Check For Nas**: See if any rows have NA values.\n",
       "\t\t\t* **Count Number Of Rows**: Printing out the total number of rows in a table\n",
       "\t* **Export Data**: Ways in which journalist export the results of their data wrangling.\n",
       "\t\t* **Export Intermediate Results**: \n",
       "\t\t* **Export Results**: \n",
       "* **Observations**: These codes cover observations from the coder about the wrangling processes, not actions performed by the journalist.\n",
       "\t* **Data Acquisition**: How the data was acquired by journalists\n",
       "\t\t* **Collect Raw Data**: Using first-hand observations or logs as data.\n",
       "\t\t* **Use Previously Cleaned Data**: Data that originated from a colleague.\n",
       "\t\t* **Use Public Data**: Includes open-soucred datasets, tables on Wikipedia, etc..\n",
       "\t\t* **Use Academic Data**: \n",
       "\t\t* **Use Non-Public, Provided Data**: \n",
       "\t\t* **Use Open Government Data**: Data publically available on open data portals, such as data.gov\n",
       "\t\t* **Freedom Of Information Data**: Data that was obtained via FOI/FOIA requests.\n",
       "\t\t* **Use Another News Orgs Data**: A dataset previously published by another news organization\n",
       "\t\t* **Use Data From Colleague**: A dataset was provided by another journalist.\n",
       "\t* **Workflow Building**: Codes pretaining to how the wrangling workflow is built.\n",
       "\t\t* **Cache Results From External Service**: When results from an API call are cached in disk.\n",
       "\t\t* **Annotate Workflow**: Adding comments or notes in Markdown that explain what the journalistis doing.\n",
       "\t\t* **Think Computationally**: Codes that demonstrate computational thinking on the part of the journalist.\n",
       "\t\t\t* **Architect A Subroutine**: \n",
       "\t\t\t* **Architect Repeating Process**: Instances where journalists employed a loop.\n",
       "\t\t* **Toggle Step On And Off**: Some wrangling steps were not always run. Toggling off is often accomplished by commenting out code.\n",
       "\t* **Wrangling Purpose**: Why does this data need to be wrangled?\n",
       "\t\t* **Input For Downstream Applications**: Output from wrangling will be input into some other program\n",
       "\t\t\t* **Wrangle Data For Graphics**: Data need to be formatted in order to be visualized in an article, including tables.\n",
       "\t\t\t* **Wrangle Data For Model**: Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification\n",
       "\t\t* **Combine Drifting Datasets**: Reconcile difference in periodically published datasets that have superficially changed over time, such as schema differences or entity names, to consolidate more than one dataset.\n",
       "\t\t* **Combine Seemingly Disparate Datasets**: When a notebook largely constitutes combining seemingly unrelated datasets.\n",
       "\t\t* **Combine Data And Geography**: Pairing data with GIS info.\n",
       "\t\t* **Aggregate The Forest From The Trees**: Data of individual observations is aggregated in an attempt to find some meaningful structure or patterns\n",
       "\t* **Analysis**: Kinds of analysis data journalists need to wrangle data to perform.\n",
       "\t\t* **Interpret Statistical/Ml Model**: Analyze features from a model such as linear regression or classification trees\n",
       "\t\t* **Compare Different Groups Along A Common Metric**: The end analysis is just comparing different groups by a common metric.\n",
       "\t\t* **Show Trend Over Time**: Analysis consists of showing how values change over time\n",
       "\t\t* **Calculate A Statistic**: Calculate a single value for from a dataset, such as number of records.\n",
       "\t\t* **Explain Variance**: This can be done via PCA\n",
       "\t\t* **Answer A Question**: Analysis consists of using data to answer a specific question\n",
       "\t\t* **Outlier Detection**: Finding extreme cases or outliers in the data\n",
       "\t\t* **Find Nearest Neighbours In The Network**: (Network analysis) Find the closest neighbours for all points\n",
       "\t\t* **Explore Dynamic Network Flow**: (Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities.\n",
       "\t* **Strategies**: General strategies journalists employ when wrangling data.\n",
       "\t\t* **Tables Evolve**: Data and objects are destroyed during the wrangling process.\n",
       "\t\t\t* **Value Replacement**: The output of any column calculation is reassigned to an existing column.\n",
       "\t\t\t* **Temporary Joining Column**: When a key for joining two tables is created and destroyed immediately after the join.\n",
       "\t\t\t* **Refine Table**: Table refinement refers to when a table is subset *inplace*, a new object is not created in the environment.\n",
       "\t\t* **Data Is Precious**: Data and objects are neverly actually lost in the programming environment.\n",
       "\t\t\t* **Preserve Existing Values**: The output of any column calculation is assigned to a new column\n",
       "\t\t\t* **Create Child Table**: A child table is a subset of the parent table declared as a new object in the environment.\n",
       "\t\t* **Set Data Confidence Threshold**: Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value.\n",
       "\t\t* **Table Splitting**: Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.\n",
       "\t\t\t* **Split, Compute, And Merge**: First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.\n",
       "\t\t\t* **Split And Compute**: One table is split into two or more and identical computations are applied to each table.\n",
       "\t\t\t* **Merge Tables To Create Pivot Table**: \n",
       "\t\t* **Tolerate Dirty Data**: Analysis continues despite clear data quality issues.\n",
       "\t* **Pain Points**: Areas where journalist seem/could be frustrated in the wrangling process.\n",
       "\t\t* **Repetitive Code**: Instances where code is repetitively copied and pasted.\n",
       "\t\t* **Make An Incorrect Conclusion**: Instances where the journalist has made an incorrect conclusion about the data.\n",
       "\t\t* **Post-Merge Clean Up**: Pain points that come from the result of merging two datasets together\n",
       "\t\t\t* **Resort After Merge**: When a sort has to be re-done because a merge ruining the pre-merged order.\n",
       "\t\t\t* **Fill In Na Values After An Outer Join**: As outer joins do not drop non-matching rows, those values have NA\n",
       "\t\t* **Encode Redundant Information**: When data that already exists in the table is recoded into the table.\n",
       "\t\t* **Data Loss From Aggregation**: When table columns are lost because they were dropped form resulting table due to not being relevant in aggregation.\n",
       "\t\t* **Data Too Large For Repo**: Raw data cannot be included in SCM because files are too large\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('code_tree.yaml', 'r') as f:\n",
    "    code_yaml = yaml.safe_load(f)\n",
    "    \n",
    "codes = []\n",
    "\n",
    "def getCodeTree(node, func, lvl=0):\n",
    "    \"\"\" A recursive, pre-order traversal of the code groups YAML structure\"\"\"\n",
    "    func(node['name'], node['desc'], lvl)\n",
    "    if 'sub' in node.keys():\n",
    "        for child in node['sub']:\n",
    "            getCodeTree(child, func, lvl + 1)\n",
    "\n",
    "parseYaml = lambda k, d, l: codes.append('{}* **{}**: {}\\n'.format('\\t' * l, k.title(), d))\n",
    "\n",
    "for grp in code_yaml:\n",
    "    getCodeTree(grp, parseYaml)\n",
    "\n",
    "display(Markdown('### Codes\\n' + ''.join(codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Control\n",
    "\n",
    "Open codes are extracted from each PDF using some internals of the open-source [pdfannots CLI](https://github.com/0xabu/pdfannots). See the [main function in pdfannots.py](https://github.com/0xabu/pdfannots/blob/6dd8dd29a93a0f5ec55e4b47f0eb27d8088a11a0/pdfannots.py#L469) for more details. The `getCodes` function is located in `lib/util.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.3 s, sys: 110 ms, total: 44.4 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = getCodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that every code generated from open coding has been covered in `code_tree.yaml` and every entity in `code_tree.yaml` is actually in a `.html.pdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Codes in `*.html.pdf` but not in `code_tree.yaml`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th>analysis</th>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cube_root_law</th>\n",
       "      <th>the_cube_root_law.js</th>\n",
       "      <th>wtf</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electric-car-charging-points</th>\n",
       "      <th>calculatingnearestpoints.nb</th>\n",
       "      <th>add foreign key column</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 count\n",
       "article                      analysis                    code                         \n",
       "cube_root_law                the_cube_root_law.js        wtf                         1\n",
       "electric-car-charging-points calculatingnearestpoints.nb add foreign key column      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Codes in `code_tree.yaml` but not in `*.html.pdf`:\n",
       "* create edge\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the code YAML for just the open codes (leaves)\n",
    "leaves = []\n",
    "def collectLeaves(node, repo):\n",
    "    \"\"\"Recursively traverse dictionary tree and collect only the leave nodes\"\"\"\n",
    "    if 'sub' in node.keys():\n",
    "        for subnode in node['sub']:\n",
    "            collectLeaves(subnode, repo)\n",
    "    else:\n",
    "        safeCode = node['name'].strip().lower()\n",
    "        repo.append(safeCode)\n",
    "for grp in code_yaml:\n",
    "    collectLeaves(grp, leaves)\n",
    "\n",
    "# Convert from lists to sets\n",
    "leaves = set(leaves)\n",
    "pdf_codes = set(data['code'].unique())\n",
    "\n",
    "# Find any discrepancies\n",
    "diff = lambda a, b, codes: display(Markdown('Codes in `{}` but not in `{}`:\\n{}\\n'.format(a, b, '\\n'.join(['* ' + c for c in codes]))))\n",
    "\n",
    "falsePositives = pdf_codes.difference(leaves)\n",
    "falseNegatives = leaves.difference(pdf_codes)\n",
    "\n",
    "if not (bool(falsePositives) or bool(falseNegatives)):\n",
    "    # Both sets are the null set\n",
    "    display(Markdown('<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> '))\n",
    "else:\n",
    "    # Problems\n",
    "    if len(pdf_codes.difference(leaves)) > 0:\n",
    "        display(Markdown('Codes in `*.html.pdf` but not in `code_tree.yaml`'))\n",
    "        display(data[data.code.isin([n.lower() for n in list(pdf_codes.difference(leaves)) ])] \\\n",
    "            .groupby(['article', 'analysis', 'code']) \\\n",
    "            ['analysis'].count() \\\n",
    "            .to_frame('count'))\n",
    "        \n",
    "    if len(leaves.difference(pdf_codes)) > 0:\n",
    "        diff('code_tree.yaml', '*.html.pdf', leaves.difference(pdf_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
