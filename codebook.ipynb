{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `codebook.ipynb` notebook has three purposes. First, to parse the taxonomy of open and axial codes in `code_tree.yaml`. Second, to parse all the open codes in PDF printouts of computational notebooks located in the `notebooks/` directory. Third, it calculates code-analysis frequency for each code, the number of unique analyses that contain at least one instance of each open and axial code. It combines all this data in the `codes` data frame and exports this for further analysis in `data/codes.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import re, yaml\n",
    "import pandas as pd\n",
    "from lib.util import getCodes, displayMarkdown\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate rows when printing a Pandas DataFrame instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse code tree\n",
    "\n",
    "Recursively traverse the YAML code tree to transform the data from a tree into tabular form. The node called \"root\" does not actually exist in the code tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "      <th>level</th>\n",
       "      <th>is_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>root</td>\n",
       "      <td>actions</td>\n",
       "      <td>Codes that describe actions the journalist has...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actions</td>\n",
       "      <td>import</td>\n",
       "      <td>How raw data is introduced into the programmin...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import</td>\n",
       "      <td>fetch</td>\n",
       "      <td>Data is retrieved from some external sources t...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fetch</td>\n",
       "      <td>pull tables out of pdf</td>\n",
       "      <td>Using a table extraction tool, such as Tabula,...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fetch</td>\n",
       "      <td>geocode addresses</td>\n",
       "      <td>Translate addresses to latitude-longitude coor...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parent                    name  \\\n",
       "0     root                 actions   \n",
       "1  actions                  import   \n",
       "2   import                   fetch   \n",
       "3    fetch  pull tables out of pdf   \n",
       "4    fetch       geocode addresses   \n",
       "\n",
       "                                                desc  level  is_leaf  \n",
       "0  Codes that describe actions the journalist has...      0    False  \n",
       "1  How raw data is introduced into the programmin...      1    False  \n",
       "2  Data is retrieved from some external sources t...      2    False  \n",
       "3  Using a table extraction tool, such as Tabula,...      3     True  \n",
       "4  Translate addresses to latitude-longitude coor...      3     True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('code_tree.yaml', 'r') as f:\n",
    "    code_yaml = yaml.safe_load(f)\n",
    "    \n",
    "codes = []\n",
    "\n",
    "def preTreeWalk(pNode, node, func, lvl=0):\n",
    "    \"\"\" A recursive, pre-order traversal of the code groups YAML structure\"\"\"\n",
    "    leaf = 'sub' not in node.keys()\n",
    "    func(pNode, node, lvl, leaf)\n",
    "    if not leaf:\n",
    "        for child in node['sub']:\n",
    "            preTreeWalk(node, child, func, lvl + 1)\n",
    "\n",
    "parseYaml = lambda parent, child, lvl, leaf: codes.append({\n",
    "    'parent': parent['name'].lower(),\n",
    "    'name': child['name'].lower(),\n",
    "    'desc': child['desc'],\n",
    "    'level': lvl,\n",
    "    'is_leaf': leaf\n",
    "})\n",
    "\n",
    "for grp in code_yaml:\n",
    "    preTreeWalk({'name': 'root'}, grp, parseYaml)\n",
    "\n",
    "codes = pd.DataFrame(codes)[['parent', 'name', 'desc', 'level', 'is_leaf']]\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display code tree\n",
    "\n",
    "All open codes, their descriptions, and the corresponding axial codes are stored in the `code_tree.yaml` file. As the master copy for all open and axial codes resides here, the raw text itself can be difficult to read. Thus, it can be helpful to read this tree in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Codes\n",
       " * **Actions**: Codes that describe actions the journalist has taken to wrangle data for further analysis\n",
       "\n",
       "\t* **Import**: How raw data is introduced into the programming/wrangling environment\n",
       "\n",
       "\t\t* **Fetch**: Data is retrieved from some external sources to the programming environment\n",
       "\n",
       "\t\t\t* **Pull Tables Out Of Pdf**: Using a table extraction tool, such as Tabula, to parse tables inside PDF documents.\n",
       "\n",
       "\t\t\t* **Geocode Addresses**: Translate addresses to latitude-longitude coordinates through web service, such as those from Bing.\n",
       "\n",
       "\t\t\t* **Query Database**: Data is imported through a database query\n",
       "\n",
       "\t\t\t* **Scrape Web For Data**: Systematically parsing HTML web pages for relevant data\n",
       "\n",
       "\t\t* **Create**: Data is created inside the programming environment\n",
       "\n",
       "\t\t\t* **Construct Table Manually**: Using tables where column names and table values were either copy-and-pasted or entered manually.\n",
       "\n",
       "\t\t\t* **Generate Data Computationally**: Using tables populated programmatically.\n",
       "\n",
       "\t\t\t* **Copy Table Schema**: A table is copied without any values but table column names and type identical, or nearly identical, to another table\n",
       "\n",
       "\t\t\t* **Backfill Missing Data**: Create data observations where there are missing entries.\n",
       "\n",
       "\t\t* **Load**: Raw data resides on the local disk and is *loaded* into the environment, includes these file formats: .csv, .xlsx, .fec, .shp, .RData, etc.\n",
       "\n",
       "\t* **Amend**: *Amending* the data constitutes make minor changes without *integrating* other tables.\n",
       "\n",
       "\t\t* **Detrend**: \"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating,\" Philip Meyer in *Precision Journalism*.\n",
       "\n",
       "\t\t\t* **Adjust For Inflation**: TK\n",
       "\n",
       "\t\t\t* **Compute Index Number**: TK\n",
       "\n",
       "\t\t\t* **Adjust For Season**: Making seasonal adjustments to the data to detrend for seasonal trends.\n",
       "\n",
       "\t\t* **Encode Table Identification In Row**: When some way of identifying the table is encoded as a separate column in each row. Common identification methods include the name of the corresponding file, an arbitrary table name, or boolean value\n",
       "\n",
       "\t\t* **Network-Ify The Data**: When the data is inherently a graph, encode table columns and values to represent this structure tabularly\n",
       "\n",
       "\t\t\t* **Create Edge**: A column with value that define a relationship to another row, which is not necessarily in a different table\n",
       "\n",
       "\t\t\t* **Define Edge Weights**: Columns that define edge weights\n",
       "\n",
       "\t\t* **Formulate Performance Metric**: Codes in this category specify a calculation that is later used to compare different entities or the same entity over time. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.\n",
       "\n",
       "\t\t\t* **Standardize Values**: Measuring deviation from some definition of \"normal\", e.g. Z-scores\n",
       "\n",
       "\t\t\t* **Figure A Rate**: Convert numbers to a normalized rate to \"provide a comparison against some easily recognized baseline\" Philip Meyer in *Precision Journalism*\n",
       "\n",
       "\t\t\t* **Calculate Central Tendency**: Measuring what a typical value is in the data, e.g. mean, median.\n",
       "\n",
       "\t\t\t* **Calculate Change Over Time**: Such as the percentage difference over time.\n",
       "\n",
       "\t\t\t* **Calculate Spread**: Calculating the difference between two values or rates\n",
       "\n",
       "\t\t\t* **Domain-Specific Performance Metric**: A domain specific metric, such as the Cube Root Law for legislatures.\n",
       "\n",
       "\t\t* **Generate Keys**: Operations that create \"key\" columns.\n",
       "\n",
       "\t\t\t* **Create Soft Key**: Keys used in matching without a guarentee of uniqueness, such as combinations of names and addresses\n",
       "\n",
       "\t\t\t* **Create A Unique Key**: Journalist create a key that is actually unique in the table\n",
       "\n",
       "\t\t\t* **Concatenate Columns Into Key**: Combine two string columns into one to create a key, e.g. combine city and state.\n",
       "\n",
       "\t\t\t* **Designate Column As Primary Key**: Designating a column as the unique identifier for all rows in the table.\n",
       "\n",
       "\t\t* **Rank Data**: Operations that encode semantic meaning about the data with table index.\n",
       "\n",
       "\t\t\t* **Assign Ranks**: When a column of numerical ranks is explicitly assigned to rows in the table.\n",
       "\n",
       "\t\t\t* **Sort Table**: When rank is implicitly assigned by rearranging row position in the table.\n",
       "\n",
       "\t\t* **Create Flag**: Flags are boolean expressed computed upon column values and used in filtering and grouping\n",
       "\n",
       "\t* **Clean**: Operations to correct erroneous or remove otherwise unwanted rows and values from the table.\n",
       "\n",
       "\t\t* **Trim Fat**: Winnow down data that is not relevant to analysis.\n",
       "\n",
       "\t\t\t* **Subset Columns**: Removing columns from a table by specifying which ones to remove or keep.\n",
       "\n",
       "\t\t\t* **Winnow Rows**: Simply put, these operations remove table rows.\n",
       "\n",
       "\t\t\t\t* **Trim By Date Range**: Removing rows that are inside or outside a specific date range. This can be a method for detrending data by adjusting for season.\n",
       "\n",
       "\t\t\t\t* **Trim By Geographic Area**: Remove rows that are inside or outside the geographic area.\n",
       "\n",
       "\t\t\t\t* **Trim By Quantitative Threshold**: Remove rows that are above, below, equal to, or not equal to a numeric value.\n",
       "\n",
       "\t\t\t\t* **Trim By Contains Value**: Remove rows that do or do not contain specific values or types of values.\n",
       "\n",
       "\t\t* **Remove Incomplete Data**: Drop row if value(s) are incomplete, usually denoted as NA.\n",
       "\n",
       "\t\t* **Deduplicate**: Remove rows from the table that contain two or more of the same \"observation.\" Duplicates may constitute rows with identical values in all, one, or zero columns.\n",
       "\n",
       "\t\t* **Edit**: Operations that modify table values\n",
       "\n",
       "\t\t\t* **Edit Table Values**: Directly editing values within a column\n",
       "\n",
       "\t\t\t\t* **Fix Data Errors Manually**: Instances where individual row-column values are changed by a journalist.\n",
       "\n",
       "\t\t\t\t* **Fix Mixed Data Types**: Sometimes a column with be mixed with two data type, e.g. integers and strings.\n",
       "\n",
       "\t\t\t\t* **Remove Value Characters**: When characters inside a value are removed, such as periods, commas, dollar signs, etc\n",
       "\n",
       "\t\t\t\t* **Replace Na Values**: Raw data may contain incomplete table values (denoted as NA) or empty values (denoted as NULL)\n",
       "\n",
       "\t\t\t* **Map Column Values**: Edit operations that change all values within a column\n",
       "\n",
       "\t\t\t\t* **Translate Entity Names**: Performing a one-to-one mapping between values.\n",
       "\n",
       "\t\t\t\t\t* **Translate Entity Names Manually**: Manually specify the mapping between individual\n",
       "\n",
       "\t\t\t\t\t* **Pad Column Values**: Adding either character prefixes or suffixes consistently to every row within a column\n",
       "\n",
       "\t\t\t\t\t* **Strip Whitespace**: Removing extra whitespace characters from entity name\n",
       "\n",
       "\t\t\t\t\t* **Scale Values**: Operations that apply some mathematical operation to columns of quantitative data. This code is different from the codes under **Formulate performance metric** because this closer to cleaning.\n",
       "\n",
       "\t\t\t\t* **Combine Values**: Codes that map a set of entities to a smaller set of entities\n",
       "\n",
       "\t\t\t\t\t* **Bin Values**: Classifying quantitative data into ordinal data.\n",
       "\n",
       "\t\t\t\t\t* **Combine Entities**: Combining values in categorical data\n",
       "\n",
       "\t\t\t\t\t* **Resolve Entities**: Classic entity resolution: a column of categorical values has different names for the same entity.\n",
       "\n",
       "\t\t* **Format**: Operations that modify the table values appearance or style\n",
       "\n",
       "\t\t\t* **Format Values**: Operations that change value appearence, e.g. change case, specifying date format, rounding floats.\n",
       "\n",
       "\t\t\t* **Correct Bad Formatting**: Changes that correct ill-formed data such as HTML entities and new lines (\\n)\n",
       "\n",
       "\t\t\t* **Format Schema**: Operations that modify anything except table values\n",
       "\n",
       "\t\t\t\t* **Canonicalize Column Names**: Operations that change column names\n",
       "\n",
       "\t\t\t\t* **Change Column Data Type**: For example, changing a column of values from strings to integers\n",
       "\n",
       "\t\t\t* **Sort Table Rows**: Sorting a table in a way that does not rank rows, such as by a unique identifier\n",
       "\n",
       "\t\t* **Separate**: Mapping one column into more than one because multiple dimensions of the dataset packed into one column\n",
       "\n",
       "\t\t\t* **Extract Value Component**: A single row-column value may have multiple bits of info, e.g. dates and addresses, and journalists extracts one component from that value, e.g. year and street, respectively\n",
       "\n",
       "\t\t\t* **Extract Property From Datetime**: Such as extracting the day of the month, year, etc.. from a datetime column\n",
       "\n",
       "\t\t\t* **Slice Column Values**: Extracting the relevant column values by character position, e.g. the first five digits of a zip code\n",
       "\n",
       "\t\t\t* **Split Column On Delimiter**: Separate data dimensions by a common character, e.g. lat-long coordinates separated by a comma\n",
       "\n",
       "\t\t\t* **Get Unique Values**: TK\n",
       "\n",
       "\t\t* **Combine Columns**: Combining two columns into one\n",
       "\n",
       "\t* **Integrate**: Combining data residing in different tables into one table.\n",
       "\n",
       "\t\t* **Union Tables**: TK\n",
       "\n",
       "\t\t* **Inner Join Tables**: TK\n",
       "\n",
       "\t\t* **Supplement**: Supplementation is characterized by integration operations that essentially add columns to existing data\n",
       "\n",
       "\t\t\t* **Outer Join Tables**: A join that returns rows with no corresponding match in the table being joined two, e.g. left or right joins.\n",
       "\n",
       "\t\t\t* **Full Join Tables**: Combine all rows and all columns of the two tables. a.k.a full outer join\n",
       "\n",
       "\t\t\t* **Concat Parallel Tables**: When columns from multiple, parallel tables are concatenated together to form a new table.\n",
       "\n",
       "\t\t\t* **Use Lookup Table**: Using a table with two columns to map from one value to another.\n",
       "\n",
       "\t\t* **Cartesian Product**: TK\n",
       "\n",
       "\t\t* **Self Join Table**: Join a table with itself\n",
       "\n",
       "\t* **Transform**: Operations that transform a table into an aggregated, lower-resolution view of the original table.\n",
       "\n",
       "\t\t* **Summarize**: Codes that aggregate and calculate tables to get a more coarse view of the data.\n",
       "\n",
       "\t\t\t* **Join Aggregate**: \"extends the input data objects with aggregate values in a new field\" - Vega-Lite Join Aggregate docs.\n",
       "\n",
       "\t\t\t* **Rollup**: Rename entity to the name of its parent (for hierarchical data)\n",
       "\n",
       "\t\t\t* **Aggregate And Calculate**: When the data is grouped by one non-quantitative value and some calculation (sum, count, count unique) is applied to a different quantitative value\n",
       "\n",
       "\t\t\t\t* **Group By Single Column**: When a table is grouped by a single column.\n",
       "\n",
       "\t\t\t\t* **Group By Multiple Columns**: When a table is grouped by multiple columns, creating hierarchy.\n",
       "\n",
       "\t\t\t\t* **Rolling Window Calculation**: Performs rolling-window aggregation\n",
       "\n",
       "\t\t\t\t* **Sum Along Dimension**: Calculate the sum of all values within a row or column\n",
       "\n",
       "\t\t\t* **Create Frequency Table**: Count the frequency of non-quantitative variables within a column\n",
       "\n",
       "\t\t\t* **Count Value Frequency**: Count the frequency of categorical variables within a column\n",
       "\n",
       "\t\t* **Calculate**: These are within-column calculations that often, but not always, immediately follow an *aggregation* operation.\n",
       "\n",
       "\t\t\t* **Get Extreme Values**: Calculate the highest or lowest value(s)\n",
       "\n",
       "\t\t\t* **Count Unique Values In Column**: Produces a scalar with unique values in the column.\n",
       "\n",
       "\t\t* **Reshape**: Operations fundamentally change the table's structure, but do not perform any kind of summarization calculation. *Constructing a pivot table* often involves a *spread-like* operation when defining what values to use as columns in the new table. The difference with *reshaping* is that sometimes the journalist may not summarize the reshaped table.\n",
       "\n",
       "\t\t\t* **Spread Table**: Expand two columns of key value pairs into multiple columns.\n",
       "\n",
       "\t\t\t* **Gather Table**: Collapses table into key value pairs.\n",
       "\n",
       "\t\t\t* **Cross Tabulate**: such as with a pivot table/crosstab\n",
       "\n",
       "\t* **Display Dataset**: Different ways to check in on the state of the dataset during wrangling.\n",
       "\n",
       "\t\t* **Format Table Display**: Operations that adjust the table displace, such as how many decimals to round floats\n",
       "\n",
       "\t\t* **Visualize Data**: Employing any kind of data visualization, including a table\n",
       "\n",
       "\t\t* **Describe Statistically**: Generates any kind of descriptive statistics of the dataset's central tendency, dispersion and distribution shape\n",
       "\n",
       "\t* **Check Sanity**: Operations that confirm the effect of a previous wrangling operation.\n",
       "\n",
       "\t\t* **Run A Test**: Operations output a clear pass or fail value, often implemented by counting things\n",
       "\n",
       "\t\t\t* **Report Rows With Column Number Discrepancies**: Finds if a row has a different number of columns than the header row\n",
       "\n",
       "\t\t\t* **Test For Equality**: Test if two data structures are exactly the same, e.g. two data frames\n",
       "\n",
       "\t\t\t* **Test Different Computations For Equality**: Test the results of a calculation against different methods/packages. The Upshot did this with variance.\n",
       "\n",
       "\t\t\t* **Validate Data Quality With Domain-Specific Rules**: Such as if the average temperature is higher than the maximum recorded temperature\n",
       "\n",
       "\t\t* **Check Results**: Operations that output some visual representation of the table\n",
       "\n",
       "\t\t\t* **Check Results Of Previous Operation**: \n",
       "\n",
       "\t\t\t* **Peek At Data**: Display the first *n* rows and all columns of the table\n",
       "\n",
       "\t\t\t* **Inspect Table Schema**: Check the data types of columns\n",
       "\n",
       "\t\t\t* **Display Rows With Missing Values**: E.g. filtering rows with a NA value in a particular column\n",
       "\n",
       "\t\t\t* **Check For Nas**: See if any rows have NA values.\n",
       "\n",
       "\t\t\t* **Count Number Of Rows**: Printing out the total number of rows in a table\n",
       "\n",
       "\t* **Export**: Ways in which journalist export the results of their data wrangling.\n",
       "\n",
       "* **Observations**: These codes cover observations from the coder about the wrangling processes, not actions performed by the journalist.\n",
       "\n",
       "\t* **Data Acquisition**: How the data was acquired by journalists\n",
       "\n",
       "\t\t* **Collect Raw Data**: Using first-hand observations or logs as data.\n",
       "\n",
       "\t\t* **Use Previously Cleaned Data**: Data that originated from a colleague.\n",
       "\n",
       "\t\t* **Use Public Data**: Includes open-source datasets, tables on Wikipedia, etc..\n",
       "\n",
       "\t\t* **Use Academic Data**: \n",
       "\n",
       "\t\t* **Use Non-Public, Provided Data**: \n",
       "\n",
       "\t\t* **Use Open Government Data**: Data publically available on open data portals, such as data.gov\n",
       "\n",
       "\t\t* **Freedom Of Information Data**: Data that was obtained via FOI/FOIA requests.\n",
       "\n",
       "\t\t* **Use Another News Orgs Data**: A dataset previously published by another news organization\n",
       "\n",
       "\t\t* **Use Data From Colleague**: A dataset was provided by another journalist.\n",
       "\n",
       "\t* **Workflow Building**: Codes pertaining to how the wrangling workflow is built.\n",
       "\n",
       "\t\t* **Annotate Workflow**: Adding comments or notes in Markdown that explain what the journalists doing.\n",
       "\n",
       "\t\t* **Think Computationally**: Codes that demonstrate computational thinking on the part of the journalist.\n",
       "\n",
       "\t\t\t* **Architect A Subroutine**: A set of instructions grouped together to be performed multiple times.\n",
       "\n",
       "\t\t\t* **Architect Repeating Process**: Instances where journalists employed a loop.\n",
       "\n",
       "\t\t* **Toggle Step On And Off**: Some wrangling steps were not always run. Toggling off is often accomplished by commenting out code.\n",
       "\n",
       "\t* **Wrangling Purpose**: Why does this data need to be wrangled?\n",
       "\n",
       "\t\t* **Input For Downstream Applications**: Output from wrangling will be input into some other program\n",
       "\n",
       "\t\t\t* **Wrangle Data For Graphics**: Data need to be formatted in order to be visualized in an article, including tables.\n",
       "\n",
       "\t\t\t* **Wrangle Data For Model**: Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification\n",
       "\n",
       "\t\t* **Remove Erroneous Data**: There are errors in the data that need to be removed\n",
       "\n",
       "\t\t* **Creating New Datasets**: \n",
       "\n",
       "\t\t\t* **Combine Drifting Datasets**: Reconcile difference in periodically published datasets that have superficially changed over time, such as schema differences or entity names, to consolidate more than one dataset.\n",
       "\n",
       "\t\t\t* **Combine Seemingly Disparate Datasets**: When a notebook largely constitutes combining seemingly unrelated datasets.\n",
       "\n",
       "\t\t\t* **Combine Data And Geography**: Pairing data with GIS info.\n",
       "\n",
       "\t\t* **Aggregate The Forest From The Trees**: Data of individual observations is aggregated in an attempt to find some meaningful structure or patterns\n",
       "\n",
       "\t* **Analysis**: Kinds of analysis data journalists need to wrangle data to perform.\n",
       "\n",
       "\t\t* **Interpret Statistical/Ml Model**: Analyze features from a model such as linear regression or classification trees\n",
       "\n",
       "\t\t* **Compare Different Groups Along A Common Metric**: The end analysis is just comparing different groups by a common metric.\n",
       "\n",
       "\t\t* **Show Trend Over Time**: Analysis consists of showing how values change over time\n",
       "\n",
       "\t\t* **Calculate A Statistic**: Calculate a single value for from a dataset, such as number of records.\n",
       "\n",
       "\t\t* **Explain Variance**: This can be done via PCA\n",
       "\n",
       "\t\t* **Answer A Question**: Analysis consists of using data to answer a specific question\n",
       "\n",
       "\t\t* **Outlier Detection**: Finding extreme cases or outliers in the data\n",
       "\n",
       "\t\t* **Find Nearest Neighbours In The Network**: (Network analysis) Find the closest neighbours for all points\n",
       "\n",
       "\t\t* **Explore Dynamic Network Flow**: (Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities.\n",
       "\n",
       "\t* **Strategies**: General strategies journalists employ when wrangling data.\n",
       "\n",
       "\t\t* **Tables Evolve**: Data and objects are destroyed during the wrangling process.\n",
       "\n",
       "\t\t\t* **Value Replacement**: The output of any column calculation is reassigned to an existing column.\n",
       "\n",
       "\t\t\t* **Temporary Joining Column**: When a key for joining two tables is created and destroyed immediately after the join.\n",
       "\n",
       "\t\t\t* **Refine Table**: Table refinement refers to when a table is subset *in place*, a new object is not created in the environment.\n",
       "\n",
       "\t\t* **Data Is Precious**: Data and objects are neverly actually lost in the programming environment.\n",
       "\n",
       "\t\t\t* **Preserve Existing Values**: The output of any column calculation is assigned to a new column\n",
       "\n",
       "\t\t\t* **Create Child Table**: A child table is a subset of the parent table declared as a new object in the environment.\n",
       "\n",
       "\t\t* **Set Data Confidence Threshold**: Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value.\n",
       "\n",
       "\t\t* **Table Splitting**: Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.\n",
       "\n",
       "\t\t\t* **Split, Compute, And Merge**: First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.\n",
       "\n",
       "\t\t\t* **Split And Compute**: One table is split into two or more and identical computations are applied to each table.\n",
       "\n",
       "\t\t* **Tolerate Dirty Data**: Analysis continues despite clear data quality issues.\n",
       "\n",
       "\t* **Pain Points**: Areas where journalist seem/could be frustrated in the wrangling process.\n",
       "\n",
       "\t\t* **Fix Incorrect Calculation**: Calculations in the data are incorrect and the journalist must recalculate them\n",
       "\n",
       "\t\t* **Repetitive Code**: Instances where code is repetitively copied and pasted.\n",
       "\n",
       "\t\t* **Make An Incorrect Conclusion**: Instances where the journalist has made an incorrect conclusion about the data.\n",
       "\n",
       "\t\t* **Post-Merge Clean Up**: Pain points that come from the result of merging two datasets together\n",
       "\n",
       "\t\t\t* **Resort After Merge**: When a sort has to be re-done because a merge ruining the pre-merged order.\n",
       "\n",
       "\t\t\t* **Fill In Na Values After An Outer Join**: As outer joins do not drop non-matching rows, those values have NA\n",
       "\n",
       "\t\t* **Encode Redundant Information**: When data that already exists in the table is recoded into the table.\n",
       "\n",
       "\t\t* **Post-Aggregation Clean Up**: Pain points that come from the result of grouping a table.\n",
       "\n",
       "\t\t\t* **Data Loss From Aggregation**: When table columns are lost because they were dropped form resulting table due to not being relevant in aggregation.\n",
       "\n",
       "\t\t\t* **Silently Dropping Values After Groupby**: Values other than thsoe being grouped and calculated upon are lost in a group by operation\n",
       "\n",
       "\t\t* **Data Too Large For Repo**: Raw data cannot be included in SCM because files are too large\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codeMarkdownTree = [ '{}* **{}**: {}\\n'.format('\\t' * c['level'], c['name'].title(), c['desc']) for i, c in codes.iterrows() ]\n",
    "\n",
    "displayMarkdown(\"\"\"\n",
    "### Codes\\n {}\n",
    "\"\"\".format('\\n'.join(codeMarkdownTree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse coded notebooks\n",
    "\n",
    "For each computational notebook and script used for wrangling data in each analysis, we created PDF printouts with a `.html.pdf`. This extension distinguishes them from possible PDFs checked into the repositories by contributors. All of these printouts fit the glob pattern `notebooks/**/**/*.html.pdf`. We open-coded PDF printouts using the comments feature in [Adobe Acrobat DC](https://acrobat.adobe.com/en/acrobat.html). Open codes are extracted from each PDF using some internals of the open-source [pdfannots CLI](https://github.com/0xabu/pdfannots). See the [main function in pdfannots.py](https://github.com/0xabu/pdfannots/blob/6dd8dd29a93a0f5ec55e4b47f0eb27d8088a11a0/pdfannots.py#L469) for more details. \n",
    "\n",
    "The `codeData` data frame links open codes with the notebooks in which they appear. Warning: this cell may take awhile to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 s, sys: 140 ms, total: 56.2 s\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "codeData = getCodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "The cell below ensures that there aren't any codes in the code tree that aren't in the PDF printouts and vice versa. More precisely, it checks that the difference between the set of open codes in `code_tree.yaml` and the set of unique codes that appear in every PDF printout (`notebooks/**/**/*.html.pdf`) is the empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the code YAML for just the open codes (leaves)\n",
    "leaves = []\n",
    "def collectLeaves(node, repo):\n",
    "    \"\"\"Recursively traverse dictionary tree and collect only the leave nodes\"\"\"\n",
    "    if 'sub' in node.keys():\n",
    "        for subnode in node['sub']:\n",
    "            collectLeaves(subnode, repo)\n",
    "    else:\n",
    "        safeCode = node['name'].strip().lower()\n",
    "        repo.append(safeCode)\n",
    "\n",
    "for grp in code_yaml:\n",
    "    collectLeaves(grp, leaves)\n",
    "\n",
    "# Convert from lists to sets\n",
    "leaves = set(leaves)\n",
    "pdf_codes = set(codeData['code'].unique())\n",
    "\n",
    "# Find any discrepancies\n",
    "diff = lambda a, b, codes: displayMarkdown('Codes in `{}` but not in `{}`:\\n{}\\n'.format(a, b, '\\n'.join(['* ' + c for c in codes])))\n",
    "\n",
    "falsePositives = pdf_codes.difference(leaves)\n",
    "falseNegatives = leaves.difference(pdf_codes)\n",
    "\n",
    "if not (bool(falsePositives) or bool(falseNegatives)):\n",
    "    # Both sets are the null set\n",
    "    displayMarkdown('<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> ')\n",
    "else:\n",
    "    # Problems\n",
    "    if len(pdf_codes.difference(leaves)) > 0:\n",
    "        diff('*.html.pdf', 'code_tree.yaml', pdf_codes.difference(leaves))\n",
    "    if len(leaves.difference(pdf_codes)) > 0:\n",
    "        diff('code_tree.yaml', '*.html.pdf', leaves.difference(pdf_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find notebooks with certain codes\n",
    "\n",
    "If extracted codes and the codes in `code_tree.yaml` don't match, then we can find the corresponding open code by grouping data by code, article, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th>analysis</th>\n",
       "      <th>notebook</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needles = ['calculate normalized values']\n",
    "\n",
    "codeData[codeData.code.isin([n.lower() for n in needles ])] \\\n",
    "    .groupby(['code', 'analysis', 'notebook']) \\\n",
    "    ['notebook'].count() \\\n",
    "    .to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating code-analysis frequency\n",
    "\n",
    "Because PDF printouts have only open codes inside, we have to do a little bit of data wrangling to figure out how many analyses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The minimum analysis count for any code should be 1: True"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codeAnalysisTmp = pd.merge(codes[codes.is_leaf].copy()[['parent', 'name']], codeData[['code', 'analysis']],\n",
    "                        how='left',\n",
    "                        left_on='name',\n",
    "                        right_on='code') \\\n",
    "                 .drop(['code'], axis=1) \\\n",
    "                 .drop_duplicates()\n",
    "\n",
    "codeAnalysis = codeAnalysisTmp[['name', 'analysis']].copy()\n",
    "\n",
    "while codeAnalysisTmp.parent.nunique() > 0:\n",
    "    codeAnalysisTmp = codeAnalysisTmp[['parent', 'analysis']] \\\n",
    "        .rename(columns={'parent': 'name'}) \\\n",
    "        .drop_duplicates()\n",
    "\n",
    "    codeAnalysisTmp = pd.merge(\n",
    "        codeAnalysisTmp,\n",
    "        codes[['parent', 'name']],    \n",
    "        how = 'left',\n",
    "        on = 'name')\n",
    "\n",
    "    codeAnalysis = pd.concat([codeAnalysis, codeAnalysisTmp[['name', 'analysis']]]) \\\n",
    "        .drop_duplicates()\n",
    "\n",
    "codeAnalysis = codeAnalysis.groupby('name')['analysis'].nunique().to_frame('analysis').reset_index()\n",
    "\n",
    "displayMarkdown('The minimum analysis count for any code should be 1: {}'.format(1 == min(codeAnalysis.analysis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The data frame `codes` differ by 0 rows after the join"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "      <th>level</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>root</td>\n",
       "      <td>actions</td>\n",
       "      <td>Codes that describe actions the journalist has...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actions</td>\n",
       "      <td>import</td>\n",
       "      <td>How raw data is introduced into the programmin...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import</td>\n",
       "      <td>fetch</td>\n",
       "      <td>Data is retrieved from some external sources t...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fetch</td>\n",
       "      <td>pull tables out of pdf</td>\n",
       "      <td>Using a table extraction tool, such as Tabula,...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fetch</td>\n",
       "      <td>geocode addresses</td>\n",
       "      <td>Translate addresses to latitude-longitude coor...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parent                    name  \\\n",
       "0     root                 actions   \n",
       "1  actions                  import   \n",
       "2   import                   fetch   \n",
       "3    fetch  pull tables out of pdf   \n",
       "4    fetch       geocode addresses   \n",
       "\n",
       "                                                desc  level  is_leaf  analysis  \n",
       "0  Codes that describe actions the journalist has...      0    False        50  \n",
       "1  How raw data is introduced into the programmin...      1    False        39  \n",
       "2  Data is retrieved from some external sources t...      2    False         6  \n",
       "3  Using a table extraction tool, such as Tabula,...      3     True         1  \n",
       "4  Translate addresses to latitude-longitude coor...      3     True         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priorSize = codes.shape[0]\n",
    "\n",
    "codes = pd.merge(codes, codeAnalysis, how='left', on='name')\n",
    "\n",
    "displayMarkdown(('The data frame `codes` differ by {} rows after the join'.format(priorSize - codes.shape[0])))\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.to_csv('data/codes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
