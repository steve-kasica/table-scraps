{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook\n",
    "\n",
    "This method contains a human-readable version of the codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, subprocess\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pdfannots import pdfannots\n",
    "import codecs\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate rows when printing a Pandas DataFrame instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Codes\n",
    "\n",
    "All open codes, their descriptions, and the corresponding axial codes are stored in the `code_tree.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('code_tree.yaml', 'r') as f:\n",
    "    code_yaml = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the master copy for all open and axial codes resides in the `code_tree.yaml` file, the raw text itself can be difficult to read. Thus, this snippet renders all the codes in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Codes\n",
       "* **Actions**: Codes that describe actions the journalist has taken to wrangle data for further analysis.\n",
       "\t* **Amend**: *Amending* a table constitutes creating new columns in the table without *integrating* other tables.\n",
       "\t\t* **Detrend**: \"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating,\" Philip Meyer in *Precision Journalism*.\n",
       "\t\t\t* **Adjust For Inflation**: TK\n",
       "\t\t\t* **Adjust For Season**: TK\n",
       "\t\t\t* **Compute Index Number**: TK\n",
       "\t\t* **Encode Table-Level Data**: Adding columns populated with data aggregated from the whole table, such as the frequency of nominal variables.\n",
       "\t\t\t* **Encode Table Identification In Row**: When some way of identifying the table is encoded as a separate column in each row. Common identification methods include the name of the corresponding file, an arbitrary table name, or boolean value.\n",
       "\t\t\t* **Encode Table Summary Data In Row**: When high-level, aggregated data about the table is encoded in the rows. For example, a table column contains the frequency of nominal values in a different column of the same table.\n",
       "\t\t* **Formulate Performance Metric**: Codes in this category specify a calculation that is later used to compare different entities or the same entity over time. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.\n",
       "\t\t\t* **Calculate Standardized Score**: Standardized scores are metrics that quantify deviation from some definition of \"normal.\"\n",
       "\t\t\t\t* **Calculate Z-Score**: Calculate how many standard deviations a value in a column is away from the mean. Journalists perform this function to simply find outliers in a dataset or when preparing the data for principle component analysis.\n",
       "\t\t\t* **Figure A Ratio**: Operations that normalize quantitative variables to allow comparisons between groups of different sizes.\n",
       "\t\t\t\t* **Calculate Ratio**: Dividing a quantitative variable by another in such a way that enables fair comparisons.\n",
       "\t\t\t\t* **Calculate Scaled Ratio**: For example, calculating per 1,000 rates and percentages.\n",
       "\t\t\t* **Calculate Central Tendency**: These metrics try to find typical value in the data.\n",
       "\t\t\t\t* **Calculate Mean**: TK\n",
       "\t\t\t\t* **Calculate Median**: The middle value in a range of numbers.\n",
       "\t\t\t* **Quantify Change**: Measuring how much things change, usually over time.\n",
       "\t\t\t\t* **Calculate Percentage Difference**: \"the difference between two values taken as a percentage of whichever value you are using as the base,\" according to Philip Meyer in *Precision Journalism.* This term is synonymous with percent change.\n",
       "\t\t\t\t* **Calculate Difference**: Subtracting two quantitative variables, including scalar values, vectors, and matricies.\n",
       "\t\t\t* **Calculate Spread**: TK\n",
       "\t\t* **Key Generation**: Operations that create \"key\" columns. These columns are often, but not always, used in group by or join operations. As this step is often a discrete precursor to data *integration*, it belongs in the *amend* group.\n",
       "\t\t\t* **Create A Semi-Unique Key**: TK\n",
       "\t\t\t* **Create A Unique Key**: TK\n",
       "\t\t\t* **Concatenate Columns Into Key**: TK\n",
       "\t\t\t* **Designate Column As Primary Key**: TK\n",
       "\t\t* **Rank Data**: Operations that encode semantic meaning about the data with table index.\n",
       "\t\t\t* **Assign Ranks**: When a column of numerical ranks is explicitly assigned to rows in the table.\n",
       "\t\t\t* **Break Ties**: TK\n",
       "\t\t\t* **Sort Table**: When rank is implicitly assigned by rearranging row position in the table.\n",
       "\t\t* **Create Flag**: Flags are boolean expressed computed upon column values and used in filtering and grouping\n",
       "\t* **Clean**: Operations to correct erroneous or remove otherwise unwanted rows and values from the table.\n",
       "\t\t* **Trim Fat**: Removing portions of the table not relevant to analysis.\n",
       "\t\t\t* **Prune Columns**: Simply put, these operations remove table columns.\n",
       "\t\t\t\t* **Drop Columns**: TK\n",
       "\t\t\t\t* **Select Columns**: TK\n",
       "\t\t\t\t* **Align Table Columns For Consolidation**: TK\n",
       "\t\t\t* **Prune Rows**: Simply put, these operations remove table rows.\n",
       "\t\t\t\t* **Trim By Date Range**: TK\n",
       "\t\t\t\t* **Trim By Geographic Area**: TK\n",
       "\t\t\t\t* **Trim By Quantitative Threshold**: TK\n",
       "\t\t\t* **Filter Rows**: TK\n",
       "\t\t\t* **Drop Erroneous Rows**: TK\n",
       "\t\t\t* **Remove Incomplete Data**: TK\n",
       "\t\t\t* **Deduplicate**: Remove rows from the table that contain two or more of the same \"observation.\" Duplicates may constitute rows with identical values in all, one, or zero columns.\n",
       "\t\t\t\t* **Prevent Double-Counting**: TK\n",
       "\t\t\t\t* **Drop Entirely Duplicate Rows**: TK\n",
       "\t\t\t\t* **Drop Rows With Duplicate Value In One Column**: TK\n",
       "\t\t\t\t* **Remove All Rows But The Master Record**: TK\n",
       "\t\t* **Edit**: Operations that modify table values\n",
       "\t\t\t* **Replace Na Values**: Raw data may contain incomplete table values (denoted as NA) or empty values (denoted as NULL)\n",
       "\t\t\t* **Fix Data Errors Manually**: TK\n",
       "\t\t\t* **Fix Incorrect Calculation**: TK\n",
       "\t\t\t* **Remove With Regular Expression**: TK\n",
       "\t\t\t* **Resolve Entity Names**: A surjective mapping from previous column values to new column values\n",
       "\t\t\t\t* **Perform Name Entity Resolution Manually**: Manually specify the mapping between old and new column values\n",
       "\t\t\t\t* **Strip Whitespace**: Note that this might also fall under *resolving entity names*.\n",
       "\t\t\t\t* **Combine Entities By String Matching**: TK\n",
       "\t\t\t* **Translate Entity Names**: Performing a bijective mapping between values, often to improve semantic meaning.\n",
       "\t\t\t\t* **Translate Entity Names Manually**: Manually specify the mapping between individual\n",
       "\t\t\t\t* **Join With Lookup Table**: Two column tables meant for mapping a key from one table to the unique column in the lookup table.\n",
       "\t\t\t* **Scale Values**: Operations that apply some mathematical operation to columns of quantitative data. This code is different from the codes under **Formulate performance metric** because this closer to cleaning.\n",
       "\t\t\t\t* **Log-Ify Values**: TK\n",
       "\t\t\t\t* **Perform Scalar Multiplication**: TK\n",
       "\t\t\t\t* **Whiten Matrix**: Divide each feature by its standard deviation across all observations to give it unit variance.\n",
       "\t\t* **Format**: Operations that modify the table values appearance or style.\n",
       "\t\t\t* **Format Values**: Operations that modify the values within the table.\n",
       "\t\t\t\t* **Change Case**: TK\n",
       "\t\t\t\t* **Change Date Format**: TK\n",
       "\t\t\t\t* **Round Floating Point**: TK\n",
       "\t\t\t* **Format Schema**: Operations that modify anything except table values.\n",
       "\t\t\t\t* **Canonicalize Column Names**: Operations that change column names\n",
       "\t\t\t\t* **Change Column Data Type**: For example, changing a column of values from strings to integers\n",
       "\t\t* **Separate**: Mapping one column into more than one because multiple dimensions of the dataset packed into one column.\n",
       "\t\t\t* **Extract Property From Datetime**: Such as extracting the day of the month, year, etc.. from a datetime column\n",
       "\t\t\t* **Slice Column Values**: Extracting the relevant column values by character position, e.g. the first five digits of a zip code.\n",
       "\t\t\t* **Split Column On Delimiter**: TK\n",
       "\t\t\t* **Get Unique Values**: TK\n",
       "\t* **Integrate**: Combining data residing in different tables into one table.\n",
       "\t\t* **Consolidate**: Combination of multiple tables into one. Schema changes are non-existent or inconsequential.\n",
       "\t\t\t* **Union Tables**: TK\n",
       "\t\t\t* **Concatenate Files Together**: TK\n",
       "\t\t\t* **Full Join Tables**: Combine all rows and all columns of the two tables.\n",
       "\t\t* **Intersect**: Joining two tables such that non-matching rows are excluded from the combined table.\n",
       "\t\t\t* **Inner Join Tables**: TK\n",
       "\t\t\t* **Natural Join**: TK\n",
       "\t\t* **Supplement**: Joining a table with a primary table such that all the rows in the primary table are in the combined table.\n",
       "\t\t\t* **Right Join Tables**: TK\n",
       "\t\t\t* **Left Join Tables**: TK\n",
       "\t\t\t* **Merge Metadata**: TK\n",
       "\t\t\t* **Ping Web Service**: TK\n",
       "\t\t\t\t* **Add Calculated Column From Axillary Data**: TK\n",
       "\t\t\t\t* **Geocode Addresses**: TK\n",
       "\t\t* **Other**: Integration operations that do not fall into the previous two categories\n",
       "\t\t\t* **Cartesian Product**: TK\n",
       "\t\t\t* **Self Join Table**: TK\n",
       "\t* **Transform**: Operations that transform a table into an aggregated, lower-resolution view of the original table.\n",
       "\t\t* **Summarize**: \n",
       "\t\t\t* **Aggregate**: Codes that group the table along one or more table dimension.\n",
       "\t\t\t\t* **Group By Single Axis**: Grouping one or more columns such that grouped columns are hierarchically ordered when grouping by two or more columns. This operation is commonly implemented with `groupby` in Pandas.\n",
       "\t\t\t\t\t* **Group By Single Column**: \n",
       "\t\t\t\t\t* **Group By Multiple Columns**: \n",
       "\t\t\t\t* **Group By Double Axis**: Grouping by more than one column such that one grouped column is not hierarchically paired with another grouped column.\n",
       "\t\t\t\t\t* **Construct Pivot Table**: Is essentially the same as a crosstab except that the table axes may contain hierarchical, nominal data.\n",
       "\t\t\t\t\t* **Create A Crosstab**:  User performs a crosstab query, as defined by [Microsoft Office](https://support.office.com/en-us/article/make-summary-data-easier-to-read-by-using-a-crosstab-query-8465b89c-2ff2-4cc8-ba60-2cd8484667e8). Crosstabs are very similar to the reshaping operation *spread*, except that they summarize values using aggregate functions.\n",
       "\t\t\t\t* **Create Rolling Window**: \n",
       "\t\t* **Calculate**: These are within-column calculations that often, but not always, immediately follow an *aggregation* operation.\n",
       "\t\t\t* **Sum Column Values**: \n",
       "\t\t\t* **Get Max Value**: \n",
       "\t\t\t* **Count Value Frequency**: \n",
       "\t\t\t* **Count Unique Values In Column**: \n",
       "\t\t* **Reshape**: Operations fundamentally change the table's structure, but do not perform any kind of summarization calculation. *Constructing a pivot table* often involves a *spread-like* operation when defining what values to use as columns in the new table. The difference with *reshaping* is that sometimes the journalist may not summarize the reshaped table.\n",
       "\t\t\t* **Spread Table**: \n",
       "\t\t\t* **Gather Table**: Collapses table into key value pairs.\n",
       "\t* **Display Dataset**: Different ways to check in on the state of the dataset during wrangling.\n",
       "\t\t* **Display A Table**: Operations that have to do with displaying the raw data as a table.\n",
       "\t\t\t* **Format Table Display**: \n",
       "\t\t\t* **Display Entire Table**: \n",
       "\t\t* **Understand Distribution**: Operations that reveal something of the underlying distribution of data.\n",
       "\t\t\t* **Plot Histogram**: \n",
       "\t\t\t* **Plot Stacked Bar Chart**: \n",
       "\t\t\t* **Plot Stacked Column Chart**: \n",
       "\t\t\t* **Plot Scatterplot**: \n",
       "\t\t\t* **Plot Trendline**: \n",
       "\t\t\t* **Plot Column Chart**: \n",
       "\t\t\t* **Plot Violin Plot**: \n",
       "\t\t\t* **Plot Boxplot**: \n",
       "\t\t\t* **Plot Scree Plot**: \n",
       "\t\t\t* **Plot Line Chart**: Visualizations with lines connecting points on a chart.\n",
       "\t* **Check Sanity**: Operations that confirm the effect of a previous wrangling operation.\n",
       "\t\t* **Check Results Of Previous Operation**: \n",
       "\t\t* **Compare Total Number Of Rows**: \n",
       "\t\t* **Test For Equality**: Test if two data structures are exactly the same, e.g. two data frames.\n",
       "\t\t* **Peek At Data**: Display the first *n* rows and all columns of the table\n",
       "\t\t* **Inspect Table Schema**: \n",
       "* **Observations**: \n",
       "\t* **Document**: When journalist annotate their data wrangling processes with non-executing comments or notes.\n",
       "\t\t* **Annotate Workflow**: \n",
       "\t* **Cache Results From External Service**: \n",
       "\t* **Export Data**: Ways in which journalist export the results of their data wrangling.\n",
       "\t\t* **Export Intermediate Results**: \n",
       "\t\t* **Export Results**: \n",
       "\t* **Workflow Building**: \n",
       "\t\t* **Think Computationally**: Codes that demonstrate computational thinking on the part of the journalist.\n",
       "\t\t\t* **Architect A Subroutine**: \n",
       "\t\t\t* **Architect Repeating Process**: Instances where journalists employed a loop.\n",
       "\t\t* **Toggle Step On And Off**: Some wrangling steps were not always run. Toggling off is often accomplished by commenting out code.\n",
       "\t* **Acquire Data**: Codes relating to how data is originally acquired by journalists.\n",
       "\t\t* **Extracted Data**: Extraction occurs when data is originally in a format that is not readily accessible for wrangling and analysis through programmatic methods. \n",
       "\t\t\t* **Pull Tables Out Of Pdf**: Instances where journalists used a PDF extraction tool, such as Tabula, to work with raw data.\n",
       "\t\t\t* **Scrape Web For Data**: \n",
       "\t* **Create**: Data used in wrangling/analysis is collected or generated by the journalist. In \"Heat and Index\" Sahil Chinoy computationally generates temperature and humidity data.\n",
       "\t\t* **Construct Table Manually**: Journalists hand-type the column names and table values.\n",
       "\t\t* **Generate Data Computationally**: \n",
       "\t* **Collect Raw Data**: First-hand observations or logs\n",
       "\t* **Data Properties**: \n",
       "\t\t* **History**: \n",
       "\t\t\t* **Use Previously Cleaned Data**: \n",
       "\t\t* **Structure**: Is the data tabular, geospatial. What kind of data is the journalist dealing with?\n",
       "\t\t\t* **Use Structured Ascii**: \n",
       "\t\t\t* **Use Geospatial Data**: \n",
       "\t\t\t* **Use Tabular Data**: \n",
       "\t\t* **Source**: Where did this data come from?\n",
       "\t\t\t* **Use Public Disclosure Data**: \n",
       "\t\t\t* **Use Public Data**: \n",
       "\t\t\t* **Use Academic Data**: \n",
       "\t\t\t* **Use Non-Public, Provided Data**: \n",
       "\t\t\t* **Use Another News Orgs Data**: \n",
       "\t\t\t* **Use Data From Colleague**: \n",
       "\t* **Purpose**: Why does this data need to be wrangled? For what end does wrangling serve? This category ventures into analysis, which not wrangling.\n",
       "\t\t* **Analysis**: Kinds of analysis data journalists need to wrangle data to perform.\n",
       "\t\t\t* **Extract Single Value**: Sometimes, the whole point of wrangling is to calculate and report a single value for a story.\n",
       "\t\t\t* **Analyze Principle Components**: \n",
       "\t\t\t* **Run Cluster Analysis**: Run some kind of clusting analysis, such as K-means.\n",
       "\t\t\t* **Fit A Generalized Linear Model**: \n",
       "\t\t\t* **Look For Trends**: \n",
       "\t\t\t* **Find Most Frequently Occurring**: \n",
       "\t\t\t* **Find Worst Offender**: \n",
       "\t\t\t* **Count Number Of Records**: \n",
       "\t\t\t* **Image Analysis**: A programmatic, quantitative analysis of images.\n",
       "\t\t* **Wrangle Data For Graphics**: When a purpose of the notebook is to format data for other visualization tools\n",
       "\t\t* **Combine Seemingly Disparate Datasets**: When a notebook largely constitutes combining seemingly unrelated datasets.\n",
       "\t* **Strategies**: \n",
       "\t\t* **Value Replacement**: The output of an intra- or inter- column calculation is reassigned to an existing column.\n",
       "\t\t* **Preserve Existing Values**: The output of an intra- or inter- column calculation is assigned to a new row\n",
       "\t\t* **Set Data Confidence Threshold**: \n",
       "\t\t* **Table Splitting**: Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.\n",
       "\t\t\t* **Split, Compute, And Merge**: First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.\n",
       "\t\t\t* **Split And Compute**: One table is split into two or more and identical computations are applied to each table.\n",
       "\t\t\t* **Peel And Merge**: When a single column of a data frame is isolated and computed upon, such as computing the frequency of a nominal column, and the results are merged back into the original table.\n",
       "\t\t\t* **Merge Tables To Create Pivot Table**: \n",
       "\t\t* **Tolerate Dirty Data**: \n",
       "\t\t* **Omits Data Quality Exploration**: \n",
       "\t\t* **Temporary Joining Column**: \n",
       "\t* **Pain Points**: \n",
       "\t\t* **Repetitive Code**: Instances where code is repetitively copied and pasted.\n",
       "\t\t* **Make An Incorrect Conclusion**: Instances where the journalist has made an incorrect conclusion about the data.\n",
       "\t\t* **Resort After Merge**: \n",
       "\t\t* **Data Loss From Aggregation**: \n",
       "\t\t* **Encoding Provenance In Data**: \n",
       "\t\t* **Data Too Large For Repo**: Raw data cannot be included in SCM because files are too large\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codes = []\n",
    "\n",
    "def getCodeTree(node, func, lvl=0):\n",
    "    \"\"\" A recursive, pre-order traversal of the code groups YAML structure\"\"\"\n",
    "    func(node['name'], node['desc'], lvl)\n",
    "    if 'sub' in node.keys():\n",
    "        for child in node['sub']:\n",
    "            getCodeTree(child, func, lvl + 1)\n",
    "\n",
    "parseYaml = lambda k, d, l: codes.append('{}* **{}**: {}\\n'.format('\\t' * l, k.title(), d))\n",
    "\n",
    "for grp in code_yaml:\n",
    "    getCodeTree(grp, parseYaml)\n",
    "\n",
    "display(Markdown('### Codes\\n' + ''.join(codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Extracting open codes from PDF files\n",
    "\n",
    "Open codes were extracted from each PDF using some internals of the open-source [pdfannots CLI](https://github.com/0xabu/pdfannots). See the [main function in pdfannots.py](https://github.com/0xabu/pdfannots/blob/6dd8dd29a93a0f5ec55e4b47f0eb27d8088a11a0/pdfannots.py#L469) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rep = lambda s, n: [ s for i in range(n) ]\n",
    "codec = codecs.lookup('cp1252')\n",
    "data = pd.DataFrame(columns=['org', 'article', 'analysis', 'index', 'cell', 'code'])\n",
    "code_re = r'\\[([^\\]]+)\\]\\s([A-za-z][^\\n]+)\\n?'  # Regular expression for parsing my coding comments\n",
    "\n",
    "ptrn = os.path.join('.', 'notebooks', '**', '**', '*.html.pdf')\n",
    "for fn in glob.iglob(ptrn, recursive=False):        \n",
    "    org, article, analysis = fn.split('/')[2:]\n",
    "    with open(fn, 'rb') as fobj:\n",
    "        annots, outlines = pdfannots.process_file(fobj, codec, False)\n",
    "    codes = []\n",
    "    for annot in annots:\n",
    "        if annot.contents != None:\n",
    "            codes += re.findall(code_re, annot.contents)\n",
    "    df = pd.DataFrame({\n",
    "        'org': rep(org, len(codes)),\n",
    "        'article': rep(article, len(codes)),\n",
    "        'analysis': rep(analysis[:-9], len(codes)),  # slice off file extension\n",
    "        'index': [ i for i in range(len(codes)) ],\n",
    "        'cell': [ c[0].strip() for c in codes ],\n",
    "        'code': [ c[1].strip().lower() for c in codes ]\n",
    "    })\n",
    "    data = data.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many data journalists take a peek at the data many times over the course of wrangling their data and so will I. \n",
    "\n",
    "* **org**: The organization that published the analysis.\n",
    "* **article**: THe name of the repository that contains analysis.\n",
    "* **index**: ??\n",
    "* **cell**: The execution order of the cell in the PDF or the line number. This column is useful for tracing open codes back to where they occurred in these computational notebooks.\n",
    "* **code**: The name of the open code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(frac=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Control\n",
    "\n",
    "Summarize the current coding progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = [\n",
    "    len(data['article'].unique()) + 1,  # Add one for two stories in wuft/Power_of_Irma repo\n",
    "    len(data['code'].unique())\n",
    "]\n",
    "\n",
    "print('Articles: {}\\nCodes: {}'.format(*summary_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check \n",
    "\n",
    "Double check that every code generated from open coding has been covered in `code_tree.yaml` and every entity in `code_tree.yaml` is actually in a `.html.pdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parse the code YAML for just the open codes (leaves)\n",
    "leaves = []\n",
    "def collectLeaves(node, repo):\n",
    "    \"\"\"Recursively traverse dictionary tree and collect only the leave nodes\"\"\"\n",
    "    if 'sub' in node.keys():\n",
    "        for subnode in node['sub']:\n",
    "            collectLeaves(subnode, repo)\n",
    "    else:\n",
    "        safeCode = node['name'].strip().lower()\n",
    "        repo.append(safeCode)\n",
    "for grp in code_yaml:\n",
    "    collectLeaves(grp, leaves)\n",
    "\n",
    "# Convert from lists to sets\n",
    "leaves = set(leaves)\n",
    "pdf_codes = set(data['code'].unique())\n",
    "\n",
    "# Find any discrepancies\n",
    "diff = lambda a, b, codes: display(Markdown('Codes in `{}` but not in `{}`:\\n{}\\n'.format(a, b, '\\n'.join(['* ' + c for c in codes]))))\n",
    "\n",
    "falsePositives = pdf_codes.difference(leaves)\n",
    "falseNegatives = leaves.difference(pdf_codes)\n",
    "\n",
    "if not (bool(falsePositives) or bool(falseNegatives)):\n",
    "    # Both sets are the null set\n",
    "    display(Markdown('<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> '))\n",
    "else:\n",
    "    # Problems\n",
    "    if len(pdf_codes.difference(leaves)) > 0:\n",
    "        diff('*.html.pdf', 'code_tree.yaml', pdf_codes.difference(leaves))\n",
    "    if len(leaves.difference(pdf_codes)) > 0:\n",
    "        diff('code_tree.yaml', '*.html.pdf', leaves.difference(pdf_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If extracted codes and the codes in `code_tree.yaml` don't match, then we can find the corresponding open code by grouping data by code, article, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th>article</th>\n",
       "      <th>analysis</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>run cluster analysis</th>\n",
       "      <th>data</th>\n",
       "      <th>cluster-paintings.py</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count\n",
       "code                 article analysis                   \n",
       "run cluster analysis data    cluster-paintings.py      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needles = []\n",
    "\n",
    "data[data.code.isin([n.lower() for n in needles ])] \\\n",
    "    .groupby(['code', 'article', 'analysis']) \\\n",
    "    ['analysis'].count() \\\n",
    "    .to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all codes\n",
    "\n",
    "Show all the unique codes generated so far, and link them to the articles in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['mark'] = 'âœ”'\n",
    "\n",
    "(\n",
    "    data[['code', 'org', 'mark']]\n",
    "        .drop_duplicates(['code', 'org'])  # Drop duplicate codes within an article\n",
    "        .set_index(['code', 'org'])\n",
    "        .unstack(fill_value='')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
