{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, subprocess\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pdfannots import pdfannots\n",
    "import codecs\n",
    "import treelib\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate rows when printing a Pandas DataFrame instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract codes from PDFs\n",
    "\n",
    "The cell below extracts the codes from each PDF using some internals of the [pdfannots CLI](https://github.com/0xabu/pdfannots). See the [main function in pdfannots.py](https://github.com/0xabu/pdfannots/blob/6dd8dd29a93a0f5ec55e4b47f0eb27d8088a11a0/pdfannots.py#L469) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 80 ms, total: 19 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rep = lambda s, n: [ s for i in range(n) ]\n",
    "\n",
    "codec = codecs.lookup('cp1252')\n",
    "\n",
    "data = pd.DataFrame(columns=['org', 'article', 'analysis', 'index', 'cell', 'code'])\n",
    "\n",
    "code_re = r'\\[([^\\]]+)\\]\\s([A-za-z][^\\n]+)\\n?'  # Regular expression for parsing my coding comments\n",
    "\n",
    "ptrn = os.path.join('.', 'notebooks', '**', '**', '*.html.pdf')\n",
    "for fn in glob.iglob(ptrn, recursive=False):        \n",
    "    org, article, analysis = fn.split('/')[2:]\n",
    "    with open(fn, 'rb') as fobj:\n",
    "        annots, outlines = pdfannots.process_file(fobj, codec, False)\n",
    "    codes = []\n",
    "    for annot in annots:\n",
    "        if annot.contents != None:\n",
    "            codes += re.findall(code_re, annot.contents)\n",
    "    df = pd.DataFrame({\n",
    "        'org': rep(org, len(codes)),\n",
    "        'article': rep(article, len(codes)),\n",
    "        'analysis': rep(analysis[:-9], len(codes)),  # slice off file extension\n",
    "        'index': [ i for i in range(len(codes)) ],\n",
    "        'cell': [ c[0].strip() for c in codes ],\n",
    "        'code': [ c[1].strip().lower() for c in codes ]\n",
    "    })\n",
    "    data = data.append(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org</th>\n",
       "      <th>article</th>\n",
       "      <th>analysis</th>\n",
       "      <th>index</th>\n",
       "      <th>cell</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baltimore-sun-data</td>\n",
       "      <td>2018-voter-registration</td>\n",
       "      <td>01_processing</td>\n",
       "      <td>0</td>\n",
       "      <td>paragraph 1</td>\n",
       "      <td>use third-party data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baltimore-sun-data</td>\n",
       "      <td>2018-voter-registration</td>\n",
       "      <td>01_processing</td>\n",
       "      <td>1</td>\n",
       "      <td>paragraph 1</td>\n",
       "      <td>pull tables out of pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baltimore-sun-data</td>\n",
       "      <td>2018-voter-registration</td>\n",
       "      <td>01_processing</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>annotate workflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baltimore-sun-data</td>\n",
       "      <td>2018-voter-registration</td>\n",
       "      <td>01_processing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>change column data type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baltimore-sun-data</td>\n",
       "      <td>2018-voter-registration</td>\n",
       "      <td>01_processing</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>canonicalize column names</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  org                  article       analysis index  \\\n",
       "0  baltimore-sun-data  2018-voter-registration  01_processing     0   \n",
       "1  baltimore-sun-data  2018-voter-registration  01_processing     1   \n",
       "2  baltimore-sun-data  2018-voter-registration  01_processing     2   \n",
       "3  baltimore-sun-data  2018-voter-registration  01_processing     3   \n",
       "4  baltimore-sun-data  2018-voter-registration  01_processing     4   \n",
       "\n",
       "          cell                       code  \n",
       "0  paragraph 1       use third-party data  \n",
       "1  paragraph 1     pull tables out of pdf  \n",
       "2            1          annotate workflow  \n",
       "3            1    change column data type  \n",
       "4            1  canonicalize column names  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the current coding progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles: 17\n",
      "Codes: 140\n"
     ]
    }
   ],
   "source": [
    "summary_stats = [\n",
    "    len(data['article'].unique()),\n",
    "    len(data['code'].unique())\n",
    "]\n",
    "\n",
    "print('Articles: {}\\nCodes: {}'.format(*summary_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Code Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkTheYaml(parent, children, func):\n",
    "    \"\"\" A recursive, pre-order traversal of the code groups YAML structure\"\"\"\n",
    "    for child in children:\n",
    "        if isinstance(child, str):\n",
    "            # Leaf nodes are strings.\n",
    "            func(parent, child, True)\n",
    "        elif isinstance(child, dict):\n",
    "            # Interior nodes are dictionaries.\n",
    "            key = list(child.keys())[0]\n",
    "            func(parent, key, False)\n",
    "            walkTheYaml(key, child[key], func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "Double check that every code generated from open coding has been covered in the hierarchy and every entity in `code_tree.yaml` is actually in a `.html.pdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All codes have been grouped ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "root = 'Wrangling'\n",
    "leaves = []\n",
    "gatherLeaves = lambda p, c, l: leaves.append(c.strip().lower()) if l else None\n",
    "code_tree = 'code_tree.yaml'\n",
    "\n",
    "with open(code_tree, 'r') as f:\n",
    "    code_hierarchy = yaml.safe_load(f)\n",
    "\n",
    "walkTheYaml(root, code_hierarchy, gatherLeaves)\n",
    "leaves = set(leaves)\n",
    "pdf_codes = set(data['code'].unique())\n",
    "\n",
    "diff = lambda a, b, codes: print('Codes in {} but not in {}:\\n{}\\n'.format(a, b, '\\n'.join(['\\t- ' + c for c in codes])))\n",
    "\n",
    "if len(pdf_codes - leaves) == 0:  # is null set\n",
    "    print(\"All codes have been grouped ðŸ˜Ž\")\n",
    "else:\n",
    "    if len(pdf_codes - leaves) > 0:\n",
    "        diff('*.html.pdf', code_tree, pdf_codes - leaves)\n",
    "    if len(leaves - pdf_codes) > 0:\n",
    "        diff(code_tree, '*.html.pdf', leaves - pdf_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display hierarchy\n",
    "\n",
    "### Notes on Codes\n",
    "\n",
    "* **Formulate performance metric**: specifying a calculation that is later used to compare different entities. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.\n",
    "* **Figure a rate**: any operation that considers one group's relation to the whole. This code covers: simple rational numbers, percentages, and per-1000 rates.\n",
    "* **Merge metadata**: Joining an auxilary table to the primary table to provide context to the phenomenon currently being analyzed.\n",
    "* **Merge data sources** refers to combining different schemas into one table. For example, *The Oregonian* compared complaints provided from a government agency with complaints scraped from the web.\n",
    "* **Detrend data**: \"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating,\" Philip Meyer in *Precision Journalism*. This includes adjusting for inflation, population growth, and season. \n",
    "* **Extract data from non-tabular form** includes scraping data from the web, parsing structured ASCII data (such as .fec files)\n",
    "* **Change dataset resolution** refers to decreasing, usually but not necessarily, the granularity of observations represents as rows in the table. Changes to dataset resolution often are caused by aggregation operations. For example, if every row in a table represents the date of an observation, then the dataset can be grouped by a coarser time interval, such as month, and aggregate quantitative values, such as sum or mean, can be computed.\n",
    "* **Consolidate data sources** refers to combining multiple tables into one table. This wrangling activity often occurs when data is located in separate, although not disparate, sources. For example, a government agency may publish data in a CSV file every year, but a data journalist wants to compare data across many years.\n",
    "* **Generate data computationally** refers to programatically generating raw data, e.g. `range` in Python. In \"Heat and Index\" Sahil Chinoy computationally generates temperature and humidity data.\n",
    "* **Create Unique Key** *added donor-movement* is an interesting code because it occurs frequently when dealing with campaign finance data. It seems like there could be algorithmic approaches that find a unique key out of any given combination of columns. Mainly unique keys are names and places concatenated. You could maybe random sample the dataset to save time?\n",
    "* **Calculate z-score** Calculate how many standard deviations a value in a column is away from the mean, $(x_i - \\bar{x})/\\sigma_x \\quad \\forall x_i \\in x$. Journalists perform this function to simply find outliers in a dataset or when preparing the data for principle component analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = treelib.Tree()\n",
    "addNode = lambda p, c, foo: tree.create_node(c.title(), c.lower(), parent=p.lower() if p != None else None)\n",
    "\n",
    "addNode(None, root, False)\n",
    "walkTheYaml(root, code_hierarchy, addNode)\n",
    "\n",
    "tree.show(line_type='ascii-em')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all codes\n",
    "\n",
    "Show all the unique codes generated so far, and link them to the articles in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['code', 'article', 'analysis'])['analysis'].count().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['mark'] = 'âœ”'\n",
    "\n",
    "(\n",
    "    data[['code', 'org', 'mark']]\n",
    "        .drop_duplicates(['code', 'org'])  # Drop duplicate codes within an article\n",
    "        .set_index(['code', 'org'])\n",
    "        .unstack(fill_value='')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
