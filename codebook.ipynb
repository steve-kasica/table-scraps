{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `codebook.ipynb` notebook has three purposes. First, to parse the taxonomy of open and axial codes in `code_tree.yaml`. Second, to parse all the open codes in PDF printouts of computational notebooks located in the `notebooks/` directory. Third, it calculates code-analysis frequency for each code, the number of unique analyses that contain at least one instance of each open and axial code. It combines all this data in the `codes` data frame and exports this for further analysis in `data/codes.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import re, yaml\n",
    "import pandas as pd\n",
    "from lib.util import getCodes, displayMarkdown\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate rows when printing a Pandas DataFrame instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse code tree\n",
    "\n",
    "Recursively traverse the YAML code tree to transform the data from a tree into tabular form. The node called \"root\" does not actually exist in the code tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "      <th>level</th>\n",
       "      <th>is_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>root</td>\n",
       "      <td>actions</td>\n",
       "      <td>Codes that describe actions the journalist has...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actions</td>\n",
       "      <td>import</td>\n",
       "      <td>How raw data is introduced into the programmin...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import</td>\n",
       "      <td>fetch</td>\n",
       "      <td>Data is retrieved from some external sources t...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fetch</td>\n",
       "      <td>pull tables out of pdf</td>\n",
       "      <td>Using a table extraction tool, such as Tabula,...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fetch</td>\n",
       "      <td>api request</td>\n",
       "      <td>Make a request to a web API, such as addresses...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parent                    name  \\\n",
       "0     root                 actions   \n",
       "1  actions                  import   \n",
       "2   import                   fetch   \n",
       "3    fetch  pull tables out of pdf   \n",
       "4    fetch             api request   \n",
       "\n",
       "                                                desc  level  is_leaf  \n",
       "0  Codes that describe actions the journalist has...      0    False  \n",
       "1  How raw data is introduced into the programmin...      1    False  \n",
       "2  Data is retrieved from some external sources t...      2    False  \n",
       "3  Using a table extraction tool, such as Tabula,...      3     True  \n",
       "4  Make a request to a web API, such as addresses...      3     True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('code_tree.yaml', 'r') as f:\n",
    "    code_yaml = yaml.safe_load(f)\n",
    "    \n",
    "codes = []\n",
    "\n",
    "def preTreeWalk(pNode, node, func, lvl=0):\n",
    "    \"\"\" A recursive, pre-order traversal of the code groups YAML structure\"\"\"\n",
    "    leaf = 'sub' not in node.keys()\n",
    "    func(pNode, node, lvl, leaf)\n",
    "    if not leaf:\n",
    "        for child in node['sub']:\n",
    "            preTreeWalk(node, child, func, lvl + 1)\n",
    "\n",
    "parseYaml = lambda parent, child, lvl, leaf: codes.append({\n",
    "    'parent': parent['name'].lower(),\n",
    "    'name': child['name'].lower(),\n",
    "    'desc': child['desc'],\n",
    "    'level': lvl,\n",
    "    'is_leaf': leaf\n",
    "})\n",
    "\n",
    "for grp in code_yaml:\n",
    "    preTreeWalk({'name': 'root'}, grp, parseYaml)\n",
    "\n",
    "codes = pd.DataFrame(codes)[['parent', 'name', 'desc', 'level', 'is_leaf']]\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display code tree\n",
    "\n",
    "All open codes, their descriptions, and the corresponding axial codes are stored in the `code_tree.yaml` file. As the master copy for all open and axial codes resides here, the raw text itself can be difficult to read. Thus, it can be helpful to read this tree in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minLevel = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Codes\n",
       " 1. **Actions**: Codes that describe actions the journalist has taken to wrangle data for further analysis\n",
       "\n",
       "\t1. **Import**: How raw data is introduced into the programming/wrangling environment\n",
       "\n",
       "\t\t1. **Fetch**: Data is retrieved from some external sources to the programming environment\n",
       "\n",
       "\t\t\t1. **Pull Tables Out Of Pdf**: Using a table extraction tool, such as Tabula, to parse tables inside PDF documents.\n",
       "\n",
       "\t\t\t1. **Api Request**: Make a request to a web API, such as addresses translation service for lat-long coordinates from Bing.\n",
       "\n",
       "\t\t\t1. **Query Database**: Data is imported through a database query\n",
       "\n",
       "\t\t\t1. **Scrape Web For Data**: Systematically parsing HTML web pages for relevant data\n",
       "\n",
       "\t\t1. **Create**: Data is created inside the programming environment\n",
       "\n",
       "\t\t\t1. **Construct Table Manually**: Using tables where column names and table values were either copy-and-pasted or entered manually.\n",
       "\n",
       "\t\t\t1. **Generate Data Computationally**: Using tables populated programmatically.\n",
       "\n",
       "\t\t\t1. **Copy Table Schema**: A table is copied without any values but table column names and type identical, or nearly identical, to another table\n",
       "\n",
       "\t\t\t1. **Backfill Missing Data**: Create data observations where there are missing entries.\n",
       "\n",
       "\t\t1. **Load**: Raw data resides on the local disk and is *loaded* into the environment, includes these file formats: .csv, .xlsx, .fec, .shp, .RData, etc.\n",
       "\n",
       "\t1. **Recalculate**: Expanding the table by calculating new columns based on existing columns without *integrating* other tables.*\n",
       "\n",
       "\t\t1. **Detrend**: \"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating,\" Philip Meyer in *Precision Journalism*.\n",
       "\n",
       "\t\t\t1. **Adjust For Inflation**: TK\n",
       "\n",
       "\t\t\t1. **Compute Index Number**: TK\n",
       "\n",
       "\t\t\t1. **Adjust For Season**: Making seasonal adjustments to the data to detrend for seasonal trends.\n",
       "\n",
       "\t\t1. **Formulate Performance Metric**: Perform a calculation that is later used to compare different entities or the same entity over time. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.\n",
       "\n",
       "\t\t\t1. **Standardize Values**: Measuring deviation from some definition of \"normal\", e.g. Z-scores\n",
       "\n",
       "\t\t\t1. **Figure A Rate**: Convert numbers to a normalized rate to \"provide a comparison against some easily recognized baseline\" Philip Meyer in *Precision Journalism*\n",
       "\n",
       "\t\t\t1. **Calculate Central Tendency**: Measuring what a typical value is in the data, e.g. mean, median.\n",
       "\n",
       "\t\t\t1. **Calculate Change Over Time**: Such as the percentage difference over time.\n",
       "\n",
       "\t\t\t1. **Calculate Spread**: Calculating the difference between two values or rates\n",
       "\n",
       "\t\t\t1. **Domain-Specific Performance Metric**: A domain specific metric, such as the Cube Root Law for legislatures.\n",
       "\n",
       "\t\t\t1. **Get Extreme Values**: Calculate the highest or lowest value(s)\n",
       "\n",
       "\t1. **Modify**: *Modifying* the data constitutes make minor changes without *integrating* other tables.\n",
       "\n",
       "\t\t1. **Encode Table Identification In Row**: When some way of identifying the table is encoded as a separate column in each row. Common identification methods include the name of the corresponding file, an arbitrary table name, or boolean value\n",
       "\n",
       "\t\t1. **Network-Ify The Data**: When the data is inherently a graph, encode table columns and values to represent this structure tabularly\n",
       "\n",
       "\t\t\t1. **Create Edge**: A column with value that define a relationship to another row, which is not necessarily in a different table\n",
       "\n",
       "\t\t\t1. **Define Edge Weights**: Columns that define edge weights\n",
       "\n",
       "\t\t1. **Generate Keys**: Operations that create \"key\" columns.\n",
       "\n",
       "\t\t\t1. **Create Soft Key**: Keys used in matching without a guarentee of uniqueness, such as combinations of names and addresses\n",
       "\n",
       "\t\t\t1. **Create A Unique Key**: Journalist create a key that is actually unique in the table\n",
       "\n",
       "\t\t1. **Rank Data**: Operations that encode semantic meaning about the data with table index.\n",
       "\n",
       "\t\t\t1. **Assign Ranks**: When a column of numerical ranks is explicitly assigned to rows in the table.\n",
       "\n",
       "\t\t\t1. **Sort Table**: When rank is implicitly assigned by rearranging row position in the table.\n",
       "\n",
       "\t\t1. **Column Reshaping**: Codes concerning either separating one column into more than one or combining more than one column into one.\n",
       "\n",
       "\t\t\t1. **Extract Column Values**: Separating a column containing multiple rows\n",
       "\n",
       "\t\t\t1. **Combine Columns**: Combining two columns into one, either through concatenation, addition, etc...\n",
       "\n",
       "\t\t1. **Create Flag**: Flags are boolean expressed computed upon column values and used in filtering and grouping\n",
       "\n",
       "\t\t1. **Pad Column Values**: Adding either character prefixes or suffixes consistently to every row within a column\n",
       "\n",
       "\t\t1. **Scale Values**: Operations that apply some mathematical operation to columns of quantitative data. This code is different from the codes under **Formulate performance metric** because this closer to cleaning.\n",
       "\n",
       "\t\t1. **Consolidate Values Of A Single Column**: Codes that map a set of entities to a smaller set of entities\n",
       "\n",
       "\t\t\t1. **Bin Values**: Consolidating a range of quantitative data into ordinal data\n",
       "\n",
       "\t\t\t1. **Combine Entities**: Consolidating a range of categorical values into a smaller set of categorical values\n",
       "\n",
       "\t1. **Clean**: Operations to correct data that might be considered \"dirty\"\n",
       "\n",
       "\t\t1. **Trim Fat**: Remove complete sections of data that just are relevant\n",
       "\n",
       "\t\t\t1. **Subset Columns**: Removing columns from a table by specifying which ones to remove or keep.\n",
       "\n",
       "\t\t\t1. **Winnow Rows**: Simply put, these operations remove table rows.\n",
       "\n",
       "\t\t\t\t1. **Trim By Date Range**: Removing rows that are inside or outside a specific date range.\n",
       "\n",
       "\t\t\t\t1. **Trim By Geographic Area**: Remove rows that are inside or outside the geographic area.\n",
       "\n",
       "\t\t\t\t1. **Trim By Quantitative Threshold**: Remove rows that are above, below, equal to, or not equal to a numeric value.\n",
       "\n",
       "\t\t\t\t1. **Trim By Contains Value**: Remove rows that do or do not contain specific values or types of values.\n",
       "\n",
       "\t\t1. **Remove Incomplete Data**: Drop row if value(s) are incomplete, usually denoted as NA.\n",
       "\n",
       "\t\t1. **Deduplicate**: Remove rows that contain two or more of the same observation, with identical values in all, one, or zero columns.\n",
       "\n",
       "\t\t1. **Fix Values**: Individual values have errors that must be corrected.\n",
       "\n",
       "\t\t\t1. **Resolve Entities**: Classic entity resolution: a column of categorical values has different names for the same entity.\n",
       "\n",
       "\t\t\t1. **Fix Data Errors Manually**: Instances where individual row-column values are changed manually.\n",
       "\n",
       "\t\t\t1. **Fix Mixed Data Types**: Sometimes a column with be mixed with two data type, e.g. integers and strings.\n",
       "\n",
       "\t\t\t1. **Remove Value Characters**: When characters inside a value are removed, such as periods, commas, dollar signs, etc\n",
       "\n",
       "\t\t\t1. **Replace Na Values**: Raw data may contain incomplete table values (denoted as NA) or empty values (denoted as NULL)\n",
       "\n",
       "\t\t\t1. **Strip Whitespace**: Removing extra whitespace characters from entity name\n",
       "\n",
       "\t\t1. **Format**: Operations that modify the table values appearance or style\n",
       "\n",
       "\t\t\t1. **Format Values**: Operations that change value appearence, e.g. change case, specifying date format, rounding floats.\n",
       "\n",
       "\t\t\t1. **Format Schema**: Operations that modify anything except table values\n",
       "\n",
       "\t\t\t\t1. **Canonicalize Column Names**: Operations that change column names\n",
       "\n",
       "\t\t\t\t1. **Change Column Data Type**: For example, changing a column of values from strings to integers\n",
       "\n",
       "\t1. **Integrate**: Combining data residing in different tables into one table.\n",
       "\n",
       "\t\t1. **Union Tables**: TK\n",
       "\n",
       "\t\t1. **Inner Join Tables**: TK\n",
       "\n",
       "\t\t1. **Supplement**: Supplementation is characterized by integration operations that essentially add columns to existing data\n",
       "\n",
       "\t\t\t1. **Outer Join Tables**: A join that returns rows with no corresponding match in the table being joined two, e.g. left or right joins.\n",
       "\n",
       "\t\t\t1. **Full Join Tables**: Combine all rows and all columns of the two tables. a.k.a full outer join\n",
       "\n",
       "\t\t\t1. **Concat Parallel Tables**: When columns from multiple, parallel tables are concatenated together to form a new table.\n",
       "\n",
       "\t\t\t1. **Use Lookup Table**: Using a table with two columns to map from one value to another.\n",
       "\n",
       "\t\t1. **Cartesian Product**: TK\n",
       "\n",
       "\t\t1. **Self Join Table**: Join a table with itself\n",
       "\n",
       "\t1. **Transform**: Operations that transform a table into an aggregated, lower-resolution view of the original table.\n",
       "\n",
       "\t\t1. **Summarize**: Codes that aggregate and calculate tables to get a more coarse view of the data.\n",
       "\n",
       "\t\t\t1. **Rollup**: Rename entity to the name of its parent (for hierarchical data)\n",
       "\n",
       "\t\t\t1. **Join Aggregate**: Extend the table (columnwise) with aggregate values, hence the number of rows stays constant but columns increase\n",
       "\n",
       "\t\t\t1. **Group By Single Column**: When a table is grouped by a single column.\n",
       "\n",
       "\t\t\t1. **Group By Multiple Columns**: When a table is grouped by multiple columns, creating hierarchy.\n",
       "\n",
       "\t\t\t1. **Rolling Window Calculation**: Performs rolling-window aggregation\n",
       "\n",
       "\t\t\t1. **Create Frequency Table**: Count the frequency of non-quantitative variables within a column\n",
       "\n",
       "\t\t1. **Reshape**: Operations fundamentally change the table's structure, but do not perform any kind of summarization calculation. *Constructing a pivot table* often involves a *spread-like* operation when defining what values to use as columns in the new table. The difference with *reshaping* is that sometimes the journalist may not summarize the reshaped table.\n",
       "\n",
       "\t\t\t1. **Spread Table**: Expand two columns of key value pairs into multiple columns.\n",
       "\n",
       "\t\t\t1. **Gather Table**: Collapses table into key value pairs.\n",
       "\n",
       "\t\t\t1. **Cross Tabulate**: such as with a pivot table/crosstab\n",
       "\n",
       "\t1. **Display Dataset**: Different ways to check in on the state of the dataset during wrangling.\n",
       "\n",
       "\t\t1. **Format Table Display**: Operations that adjust the table displace, such as how many decimals to round floats\n",
       "\n",
       "\t\t1. **Visualize Data**: Employing any kind of data visualization, including a table\n",
       "\n",
       "\t\t1. **Describe Statistically**: Generates any kind of descriptive statistics of the dataset's central tendency, dispersion and distribution shape\n",
       "\n",
       "\t1. **Check Sanity**: Operations that confirm the effect of a previous wrangling operation.\n",
       "\n",
       "\t\t1. **Run A Test**: Operations output a clear pass or fail value, often implemented by counting things\n",
       "\n",
       "\t\t\t1. **Report Rows With Column Number Discrepancies**: Finds if a row has a different number of columns than the header row\n",
       "\n",
       "\t\t\t1. **Test For Equality**: Test if two data structures are exactly the same, e.g. two data frames\n",
       "\n",
       "\t\t\t1. **Test Different Computations For Equality**: Test the results of a calculation against different methods/packages. The Upshot did this with variance.\n",
       "\n",
       "\t\t\t1. **Validate Data Quality With Domain-Specific Rules**: Such as if the average temperature is higher than the maximum recorded temperature\n",
       "\n",
       "\t\t1. **Check Results**: Operations that output some visual representation of the table\n",
       "\n",
       "\t\t\t1. **Peek At Data**: Display the first *n* rows and all columns of the table\n",
       "\n",
       "\t\t\t1. **Inspect Table Schema**: Check the data types of columns\n",
       "\n",
       "\t\t\t1. **Display Rows With Missing Values**: E.g. filtering rows with a NA value in a particular column\n",
       "\n",
       "\t\t\t1. **Check For Nas**: See if any rows have NA values.\n",
       "\n",
       "\t\t1. **Count The Data**: Operation that count things in the data set\n",
       "\n",
       "\t\t\t1. **Count Number Of Rows**: Printing out the total number of rows in a table\n",
       "\n",
       "\t\t\t1. **Count Unique Values**: Report the number of unique values in one or more columns\n",
       "\n",
       "\t1. **Export**: Ways in which journalist export the results of their data wrangling.\n",
       "\n",
       "1. **Observations**: These codes cover observations from the coder about the wrangling processes, not actions performed by the journalist.\n",
       "\n",
       "\t1. **Data Acquisition**: How the data was acquired by journalists\n",
       "\n",
       "\t\t1. **Collect Raw Data**: Using first-hand observations or logs as data.\n",
       "\n",
       "\t\t1. **Use Previously Cleaned Data**: Data that originated from a colleague.\n",
       "\n",
       "\t\t1. **Use Public Data**: Includes open-source datasets, tables on Wikipedia, etc..\n",
       "\n",
       "\t\t1. **Use Academic Data**: \n",
       "\n",
       "\t\t1. **Use Non-Public, Provided Data**: \n",
       "\n",
       "\t\t1. **Use Open Government Data**: Data publically available on open data portals, such as data.gov\n",
       "\n",
       "\t\t1. **Freedom Of Information Data**: Data that was obtained via FOI/FOIA requests.\n",
       "\n",
       "\t\t1. **Use Another News Orgs Data**: A dataset previously published by another news organization\n",
       "\n",
       "\t\t1. **Use Data From Colleague**: A dataset was provided by another journalist.\n",
       "\n",
       "\t1. **Workflow Building**: Codes pertaining to how the wrangling workflow is built.\n",
       "\n",
       "\t\t1. **Annotate Workflow**: Adding comments or notes in Markdown that explain what the journalists doing.\n",
       "\n",
       "\t\t1. **Think Computationally**: Codes that demonstrate computational thinking on the part of the journalist.\n",
       "\n",
       "\t\t\t1. **Architect A Subroutine**: A set of instructions grouped together to be performed multiple times.\n",
       "\n",
       "\t\t\t1. **Architect Repeating Process**: Instances where journalists employed a loop.\n",
       "\n",
       "\t\t1. **Toggle Step On And Off**: Some wrangling steps were not always run. Toggling off is often accomplished by commenting out code.\n",
       "\n",
       "\t1. **Wrangling Purpose**: Why does this data need to be wrangled?\n",
       "\n",
       "\t\t1. **Input For Downstream Applications**: Output from wrangling will be input into some other program\n",
       "\n",
       "\t\t\t1. **Wrangle Data For Graphics**: Data need to be formatted in order to be visualized in an article, including tables.\n",
       "\n",
       "\t\t\t1. **Wrangle Data For Model**: Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification\n",
       "\n",
       "\t\t1. **Remove Erroneous Data**: There are errors in the data that need to be removed\n",
       "\n",
       "\t\t1. **Creating New Datasets**: \n",
       "\n",
       "\t\t\t1. **Combine Drifting Datasets**: Reconcile difference in periodically published datasets that have superficially changed over time, such as schema differences or entity names, to consolidate more than one dataset.\n",
       "\n",
       "\t\t\t1. **Combine Seemingly Disparate Datasets**: When a notebook largely constitutes combining seemingly unrelated datasets.\n",
       "\n",
       "\t\t\t1. **Combine Data And Geography**: Pairing data with GIS info.\n",
       "\n",
       "\t\t1. **Aggregate The Forest From The Trees**: Data of individual observations is aggregated in an attempt to find some meaningful structure or patterns\n",
       "\n",
       "\t1. **Analysis**: Kinds of analysis data journalists need to wrangle data to perform.\n",
       "\n",
       "\t\t1. **Interpret Statistical/Ml Model**: Analyze features from a model such as linear regression or classification trees\n",
       "\n",
       "\t\t1. **Compare Different Groups Along A Common Metric**: The end analysis is just comparing different groups by a common metric.\n",
       "\n",
       "\t\t1. **Identify Extreme Values**: \n",
       "\n",
       "\t\t1. **Outlier Detection**: Finding extreme cases or outliers in the data\n",
       "\n",
       "\t\t1. **Show Trend Over Time**: Analysis consists of showing how values change over time\n",
       "\n",
       "\t\t1. **Calculate A Statistic**: Calculate a single value for from a dataset, such as number of records.\n",
       "\n",
       "\t\t1. **Answer A Question**: Analysis consists of using data to answer a specific question\n",
       "\n",
       "\t\t1. **Examine Relationship**: Analysis consists of examining the relationship between different phenomena\n",
       "\n",
       "\t\t1. **Explain Variance**: This can be done via PCA\n",
       "\n",
       "\t\t1. **Identify Clusters Or Lack Of Clusters**: Look for meaningingful groups within the data\n",
       "\n",
       "\t\t1. **Find Nearest Neighbours In The Network**: (Network analysis) Find the closest neighbours for all points\n",
       "\n",
       "\t\t1. **Explore Dynamic Network Flow**: (Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities.\n",
       "\n",
       "\t1. **Strategies**: General strategies journalists employ when wrangling data.\n",
       "\n",
       "\t\t1. **Tables Evolve**: Data and objects are destroyed during the wrangling process.\n",
       "\n",
       "\t\t\t1. **Value Replacement**: The output of any column calculation is reassigned to an existing column.\n",
       "\n",
       "\t\t\t1. **Temporary Joining Column**: When a key for joining two tables is created and destroyed immediately after the join.\n",
       "\n",
       "\t\t\t1. **Refine Table**: Table refinement refers to when a table is subset *in place*, a new object is not created in the environment.\n",
       "\n",
       "\t\t1. **Data Is Precious**: Data and objects are neverly actually lost in the programming environment.\n",
       "\n",
       "\t\t\t1. **Preserve Existing Values**: The output of any column calculation is assigned to a new column\n",
       "\n",
       "\t\t\t1. **Create Child Table**: A child table is a subset of the parent table declared as a new object in the environment.\n",
       "\n",
       "\t\t1. **Set Data Confidence Threshold**: Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value.\n",
       "\n",
       "\t\t1. **Table Splitting**: Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.\n",
       "\n",
       "\t\t\t1. **Split, Compute, And Merge**: First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.\n",
       "\n",
       "\t\t\t1. **Split And Compute**: One table is split into two or more and identical computations are applied to each table.\n",
       "\n",
       "\t\t1. **Tolerate Dirty Data**: Analysis continues despite clear data quality issues.\n",
       "\n",
       "\t1. **Pain Points**: Areas where journalist seem/could be frustrated in the wrangling process.\n",
       "\n",
       "\t\t1. **Fix Incorrect Calculation**: Calculations in the data are incorrect and the journalist must recalculate them\n",
       "\n",
       "\t\t1. **Repetitive Code**: Instances where code is repetitively copied and pasted.\n",
       "\n",
       "\t\t1. **Make An Incorrect Conclusion**: Instances where the journalist has made an incorrect conclusion about the data.\n",
       "\n",
       "\t\t1. **Post-Merge Clean Up**: Pain points that come from the result of merging two datasets together\n",
       "\n",
       "\t\t\t1. **Resort After Merge**: When a sort has to be re-done because a merge ruining the pre-merged order.\n",
       "\n",
       "\t\t\t1. **Fill In Na Values After An Outer Join**: As outer joins do not drop non-matching rows, those values have NA\n",
       "\n",
       "\t\t1. **Encode Redundant Information**: When data that already exists in the table is recoded into the table.\n",
       "\n",
       "\t\t1. **Post-Aggregation Clean Up**: Pain points that come from the result of grouping a table.\n",
       "\n",
       "\t\t\t1. **Data Loss From Aggregation**: When table columns are lost because they were dropped form resulting table due to not being relevant in aggregation.\n",
       "\n",
       "\t\t\t1. **Silently Dropping Values After Groupby**: Values other than thsoe being grouped and calculated upon are lost in a group by operation\n",
       "\n",
       "\t\t1. **Data Too Large For Repo**: Raw data cannot be included in SCM because files are too large\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codeMarkdownTree = [ '{}1. **{}**: {}\\n'.format('\\t' * c['level'], c['name'].title(), c['desc']) for i, c in codes[codes.level <= minLevel].iterrows() ]\n",
    "\n",
    "displayMarkdown(\"\"\"\n",
    "### Codes\\n {}\n",
    "\"\"\".format('\\n'.join(codeMarkdownTree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse coded notebooks\n",
    "\n",
    "For each computational notebook and script used for wrangling data in each analysis, we created PDF printouts with a `.html.pdf`. This extension distinguishes them from possible PDFs checked into the repositories by contributors. All of these printouts fit the glob pattern `notebooks/**/**/*.html.pdf`. We open-coded PDF printouts using the comments feature in [Adobe Acrobat DC](https://acrobat.adobe.com/en/acrobat.html). Open codes are extracted from each PDF using some internals of the open-source [pdfannots CLI](https://github.com/0xabu/pdfannots). See the [main function in pdfannots.py](https://github.com/0xabu/pdfannots/blob/6dd8dd29a93a0f5ec55e4b47f0eb27d8088a11a0/pdfannots.py#L469) for more details. \n",
    "\n",
    "The `codeData` data frame links open codes with the notebooks in which they appear. Warning: this cell may take awhile to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 160 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "codeData = getCodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assurance\n",
    "\n",
    "This section contains various coding QA measures.\n",
    "\n",
    "### Matching codes between notebooks and the Code Tree\n",
    "\n",
    "The cell below ensures that there aren't any codes in the code tree that aren't in the PDF printouts and vice versa. More precisely, it checks that the difference between the set of open codes in `code_tree.yaml` and the set of unique codes that appear in every PDF printout (`notebooks/**/**/*.html.pdf`) is the empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the code YAML for just the open codes (leaves)\n",
    "leaves = []\n",
    "def collectLeaves(node, repo):\n",
    "    \"\"\"Recursively traverse dictionary tree and collect only the leave nodes\"\"\"\n",
    "    if 'sub' in node.keys():\n",
    "        for subnode in node['sub']:\n",
    "            collectLeaves(subnode, repo)\n",
    "    else:\n",
    "        safeCode = node['name'].strip().lower()\n",
    "        repo.append(safeCode)\n",
    "\n",
    "for grp in code_yaml:\n",
    "    collectLeaves(grp, leaves)\n",
    "\n",
    "# Convert from lists to sets\n",
    "leaves = set(leaves)\n",
    "pdf_codes = set(codeData['code'].unique())\n",
    "\n",
    "# Find any discrepancies\n",
    "diff = lambda a, b, codes: displayMarkdown('Codes in `{}` but not in `{}`:\\n{}\\n'.format(a, b, '\\n'.join(['* ' + c for c in codes])))\n",
    "\n",
    "falsePositives = pdf_codes.difference(leaves)\n",
    "falseNegatives = leaves.difference(pdf_codes)\n",
    "\n",
    "if not (bool(falsePositives) or bool(falseNegatives)):\n",
    "    # Both sets are the null set\n",
    "    displayMarkdown('<p>All codes have been grouped!</p><img src=\"https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif\"> ')\n",
    "else:\n",
    "    # Problems\n",
    "    if len(pdf_codes.difference(leaves)) > 0:\n",
    "        diff('*.html.pdf', 'code_tree.yaml', pdf_codes.difference(leaves))\n",
    "    if len(leaves.difference(pdf_codes)) > 0:\n",
    "        diff('code_tree.yaml', '*.html.pdf', leaves.difference(pdf_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find notebooks with certain codes\n",
    "\n",
    "If extracted codes and the codes in `code_tree.yaml` don't match, then we can find the corresponding open code by grouping data by code, article, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>split, compute, and merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <th>analysis</th>\n",
       "      <th>notebook</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la_times</th>\n",
       "      <th>california-ccscore-analysis</th>\n",
       "      <th>analysis.ipynb</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">nytimes</th>\n",
       "      <th>gunsales</th>\n",
       "      <th>analysis.R</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prison-admissions</th>\n",
       "      <th>export.rmd</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicl</th>\n",
       "      <th>employment-discrimination</th>\n",
       "      <th>employment-discrimination.ipynb</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-tribune</th>\n",
       "      <th>201901-hospitalquality</th>\n",
       "      <th>hospital_quality_script.R</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stlpublicradio</th>\n",
       "      <th>2018-05-31-crime-and-heat-analysis</th>\n",
       "      <th>crimes-and-heat.ipynb</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vox</th>\n",
       "      <th>vox-central-line-infections</th>\n",
       "      <th>build.sh</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wuft</th>\n",
       "      <th>Power_of_Irma</th>\n",
       "      <th>bailey_code.R</th>\n",
       "      <td>✔️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       mark\n",
       "code                                                                              split, compute, and merge\n",
       "org            analysis                           notebook                                                 \n",
       "la_times       california-ccscore-analysis        analysis.ipynb                                         ✔️\n",
       "nytimes        gunsales                           analysis.R                                             ✔️\n",
       "               prison-admissions                  export.rmd                                             ✔️\n",
       "publicl        employment-discrimination          employment-discrimination.ipynb                        ✔️\n",
       "star-tribune   201901-hospitalquality             hospital_quality_script.R                              ✔️\n",
       "stlpublicradio 2018-05-31-crime-and-heat-analysis crimes-and-heat.ipynb                                  ✔️\n",
       "vox            vox-central-line-infections        build.sh                                               ✔️\n",
       "wuft           Power_of_Irma                      bailey_code.R                                          ✔️"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needles = ['split, compute, and merge']\n",
    "\n",
    "codeData['mark'] = '✔️'\n",
    "\n",
    "codeData[codeData.code.isin([n.lower() for n in needles ])] \\\n",
    "    [['org', 'analysis', 'notebook', 'code', 'mark']] \\\n",
    "     .drop_duplicates() \\\n",
    "     .set_index(['org', 'analysis', 'notebook', 'code']) \\\n",
    "     .unstack(fill_value='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code group gaps\n",
    "\n",
    "There are some code groups that should be applied to all analyses.\n",
    "\n",
    "#### Analysis Codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "All analyses have analysis codes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysisCodes = codes[codes.parent == 'analysis'].name.unique()\n",
    "codedAnalyses = set(codeData[codeData.code.isin(analysisCodes)].analysis.unique())\n",
    "analyses = set(codeData.analysis.unique())\n",
    "codeDiff = analyses.difference(codedAnalyses)\n",
    "\n",
    "if len(codeDiff) > 0:\n",
    "    displayMarkdown(\"\"\"\n",
    "    The following analyses do not have analysis codes:\n",
    "\n",
    "    * {}\n",
    "\n",
    "    \"\"\".format('\\n* '.join(codeDiff)))\n",
    "else:\n",
    "    displayMarkdown(\"All analyses have analysis codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating code-analysis frequency\n",
    "\n",
    "Because PDF printouts have only open codes inside, we have to do a little bit of data wrangling to figure out how many analyses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeAnalysisTmp = pd.merge(codes[codes.is_leaf].copy()[['parent', 'name']], codeData[['code', 'analysis', 'notebook']],\n",
    "                        how='left',\n",
    "                        left_on='name',\n",
    "                        right_on='code') \\\n",
    "                 .drop(['code'], axis=1) \\\n",
    "                 .drop_duplicates()\n",
    "\n",
    "codeAnalysis = codeAnalysisTmp[['name', 'analysis', 'notebook']].copy()\n",
    "\n",
    "while codeAnalysisTmp.parent.nunique() > 0:\n",
    "    codeAnalysisTmp = codeAnalysisTmp[['parent', 'analysis', 'notebook']] \\\n",
    "        .rename(columns={'parent': 'name'}) \\\n",
    "        .drop_duplicates()\n",
    "\n",
    "    codeAnalysisTmp = pd.merge(\n",
    "        codeAnalysisTmp,\n",
    "        codes[['parent', 'name']],    \n",
    "        how = 'left',\n",
    "        on = 'name')\n",
    "\n",
    "    codeAnalysis = pd.concat([codeAnalysis, codeAnalysisTmp[['name', 'analysis', 'notebook']]]) \\\n",
    "        .drop_duplicates()\n",
    "\n",
    "codeAnalysis = pd.merge(\n",
    "    codeAnalysis,\n",
    "    codes[codes.name != 'root'][['name', 'level', 'is_leaf']], \n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The minimum analysis count for any code should be 1: True"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codeAnalysisGrp = codeAnalysis.groupby('name')['analysis'].nunique().to_frame('analysis').reset_index()\n",
    "\n",
    "displayMarkdown('The minimum analysis count for any code should be 1: {}'.format(1 == min(codeAnalysisGrp.analysis)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The data frame `codes` differ by 0 rows after the aggregate join"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "      <th>level</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>root</td>\n",
       "      <td>actions</td>\n",
       "      <td>Codes that describe actions the journalist has...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actions</td>\n",
       "      <td>import</td>\n",
       "      <td>How raw data is introduced into the programmin...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import</td>\n",
       "      <td>fetch</td>\n",
       "      <td>Data is retrieved from some external sources t...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fetch</td>\n",
       "      <td>pull tables out of pdf</td>\n",
       "      <td>Using a table extraction tool, such as Tabula,...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fetch</td>\n",
       "      <td>api request</td>\n",
       "      <td>Make a request to a web API, such as addresses...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parent                    name  \\\n",
       "0     root                 actions   \n",
       "1  actions                  import   \n",
       "2   import                   fetch   \n",
       "3    fetch  pull tables out of pdf   \n",
       "4    fetch             api request   \n",
       "\n",
       "                                                desc  level  is_leaf  analysis  \n",
       "0  Codes that describe actions the journalist has...      0    False        50  \n",
       "1  How raw data is introduced into the programmin...      1    False        39  \n",
       "2  Data is retrieved from some external sources t...      2    False         6  \n",
       "3  Using a table extraction tool, such as Tabula,...      3     True         1  \n",
       "4  Make a request to a web API, such as addresses...      3     True         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priorSize = codes.shape[0]\n",
    "\n",
    "codes = pd.merge(codes, codeAnalysisGrp, how='left', on='name')\n",
    "\n",
    "displayMarkdown(('The data frame `codes` differ by {} rows after the aggregate join'.format(priorSize - codes.shape[0])))\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results\n",
    "\n",
    "We export a couple of CSV files for other notebooks to use.\n",
    "\n",
    "* `data/codes.csv` contains information on individual axial codes such as their level in the tree and how many analyses in which the code occurs.\n",
    "\n",
    "* `data/code-analysis-network.csv` contains the occurrence of open and axial codes in individual notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.to_csv('data/codes.csv', index=False)\n",
    "\n",
    "codeAnalysis.to_csv('data/code-analysis-network.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
