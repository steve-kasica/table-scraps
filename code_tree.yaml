- name: actions
  desc: 'Codes that describe actions journalists take to wrangle data'
  sub:
    - name: import
      desc: 'How raw data is introduced into the programming/wrangling environment'
      sub:
        - name: fetch
          desc: 'Data is retrieved from some external sources to the programming environment'
          sub:
            - name: pull tables out of pdf
              alias: extract data from PDF
              desc: 'Use a table extraction tool, such as Tabula, to parse tables inside PDF documents'
            - name: API request
              alias: Make an API request
              desc: 'Make a request to a web service'
            - name: query database
              alias: Query a database
              desc: 'Data is imported through a database connection'
            - name: scrape web for data
              alias: Scrape the web
              desc: 'Systematically parsing HTML web pages for data'
        - name: create
          desc: 'Data is created inside the programming environment'
          sub:
            - name: construct table manually
              desc: 'The table is either copy-and-pasted or values are created manually'
            - name: generate data computationally
              desc: 'Using tables with values generated programmatically'
            - name: copy table schema
              desc: 'A table is copied with a schema but without any values'
            - name: backfill missing data
              desc: 'Create data observations where there are missing entries.'
        - name: load
          desc: 'Data resides on the local disk and is *loaded* into the environment'
    - name: recalculate
      desc: 'Creating or revising table variables based on existing variables, without *integrating* other tables'
      sub:
        - name: detrend
          desc: 'Removing the secular effect from a variable "filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating." (Meyer, p41)'
          sub:
            - name: adjust for inflation
              desc: 'Removing the effect of price inflation from data'
            - name: compute index number
              desc: 'Calculate the change in a variable over time'
            - name: adjust for season
              desc: 'Adjusting a variable to compensate for season'                  
        - name: formulate a performance metric
          desc: 'A quantitative variable that facilitates fair comparisons'
          sub:
            - name: standardize values
              alias: standardize variable
              desc: 'Measuring deviation from "normal," such as z-scores'
            - name: figure a rate
              desc: 'Calculating a normalized rate to "provide a comparison against some easily recognized baseline" (Meyer, 38)'
            - name: calculate central tendency
              name: calculate a central tendency
              desc: 'Measuring what a typical value is in the data, such as mean, median, or mode'
            - name: calculate change over time  # TODO how is this different from figure a rate?
              desc: 'Such as the percentage difference over time'
            - name: calculate spread
              desc: 'Calculating the difference between two values or rates'
            - name: domain-specific performance metric
              alias: calculate domian-specific performance metric
              desc: 'Calculate a domain specific metric'
            - name: get extreme values
              desc: 'Calculate the highest or lowest value(s) in a variable'              
    - name: modify
      desc: '*Modifying* the data constitutes changes to variables in the table, without *integrating* other tables'
      sub:
        - name: encode table identification in row
          desc: 'Adding some table identification value as a table variable for all observations'
        - name: network-ify the data
          desc: 'Codes related to network data'
          sub:
            - name: create edge
              alias: create an edge
              desc: 'Reference another observation in the table'
            - name: define edge weights
              desc: 'Adding a quantitative variable to the relationship between two observations'
        - name: generate keys
          desc: 'Operations that attempt to create unique identifiers for observations'
          sub:
              - name: create soft key
                desc: create a soft key
                desc: 'Keys not guarenteed to be unique per observation'
              - name: create a unique key
                desc: 'Keys that are guarenteed to be unique per observation'
              - name: prep key for joining  # This is more like a higher level code for some kind of cleaning operation
                desc: 'Clean existing key column prior to joining'
        - name: rank data
          desc: 'Operations impose meaning on observations by their order in the table'
          sub:
            - name: assign ranks
              desc: 'Explicitly ordering observations as a variable'
            - name: sort table
              desc: 'Implicitly ordering observations by table position'
        - name: variable molding
          desc: 'Codes concerning the relationship between table columns and variables'
          sub:
            - name: extract column values
              alias: separate variables in column
              desc: 'Extract a column with more than one variable into separate colvars'
            - name: combine columns
              alias: combine variables
              desc: 'Combining multiple colvars into one column'
        - name: create flag
          alias: create a flag
          desc: 'Create a variable of boolean values'
        - name: pad column values
          alias: pad variable
          desc: 'Adding either character prefixes or suffixes consistently to every observation in a variable'
        - name: scale values # This code is different from the codes under **Formulate performance metric** because this closer to cleaning.
          alias: scale variable
          desc: 'Operations that apply some mathematical operation to a quantitative variable'
        - name: consolidate values of a single column
          alias: consolidate variable levels
          desc: 'Codes that map a set of unique values to a smaller set'
          sub:
            - name: bin values
              desc: 'Consolidate a quantitative variable into a smaller set of ordinal data'
            - name: combine entities
              name: combine categorial values
              desc: 'Consolidate the levels of a categorical variable into a smaller set of levels'
    - name: clean
      desc: 'Operations to correct data that might be considered "dirty"'
      sub:
        - name: trim fat
          alias: trim the fat
          desc: 'Remove sections of data that are not relevant'
          sub:
            - name: remove variables
              desc: 'Removing variables from a table by specifying which to remove or retain'
            - name: remove observations
              desc: 'Remove observations from a table by filtering on variables'
              sub:
                - name: trim by date range
                  desc: 'Removing observations inside or outside a range of dates'
                - name: trim by geographic area
                  desc: 'Remove observations that are inside or outside the geographic region'
                - name: trim by quantitative threshold
                  desc: 'Remove observations that are above, below, equal to, or not equal to a quantitative value'
                - name: trim by contains value
                  desc: 'Remove observations that do or do not contain specific a specific value or multiple values'
        - name: remove incomplete data
          desc: 'Drop observation if it contains incomplete values, often denoted as NA'
        - name: deduplicate
          desc: 'Remove duplicate observations'
        - name: fix values
          desc: 'Individual values have errors that must be corrected'
          sub:
            - name: resolve entities  # Note this is different from combine entitites because those entitites are unique
              desc: 'Resolving the issue of different categorical values for the same entitiy'
            - name: fix data errors manually
              desc: 'Instances where individual row-column values are changed manually'
            - name: fix mixed data types
              desc: 'Casting all the values of a variable to one data type'
            - name: remove value characters
              desc: 'When characters inside a value are removed, such as periods, commas, and dollar signs'
            - name: replace NA values
              desc: 'Replace NA values in a table section with the same value'
            - name: strip whitespace
              desc: 'Remove whitespace characters from the beginning and end of a string value'
        - name: format
          desc: 'Operations that modify the table values appearance or style'
          sub:
            - name: format values
              desc: 'Operations that change value appearence, such as change case, specifying date format, rounding floats.'
            - name: format schema
              desc: 'Operations that modify the table schema'
              sub:
                - name: canonicalize column names
                  desc: 'Operations that change column names'
                - name: change column data type
                  desc: 'For example, changing a column of values from dates to strings'
    - name: integrate
      desc: 'Combining data residing in different tables into one table'
      sub:
        - name: union tables
          desc: 'Combining multiple tables "row-wise" such that it adds more observations to the table'
        - name: inner join tables
          desc: 'Take the intersection of two tables on a shared key variable'
        - name: supplement
          desc: 'The variables of one table are supplemented with the variables of another table'
          sub:
            - name: outer join tables
              desc: 'Retain observations with no corresponding match in table being joined upon'
            - name: full join tables
              desc: 'Retain observations with no corresponding match in either table'
            - name: concat parallel tables  # TODO this seems like an outer join
              desc: 'When two tables are joined without a joining key'
            - name: use lookup table
              desc: 'Using a table with two columns to map from one value to another'
        - name: cartesian product
          desc: 'When a new table is created by the unique paring of each key in their respective tables'
        - name: self join table
          desc: 'A table is joined with itself'
    - name: transform
      desc: 'Operations that transform a table into an aggregated, coarser view of the original table.'
      sub:
        - name: summarize
          desc: 'Codes that aggregate and calculate tables to get a more coarse view of the data.'
          sub:
            - name: rollup
              desc: 'Rename entity to the name of its parent (for hierarchical data)'                                
            - name: join aggregate
              desc: 'Extend the table (columnwise) with aggregate values, hence the number of rows stays constant but columns increase'
            - name: split, apply, combine
              desc: 'Partition a table, apply the same calculation on each partition, and union partitions'
              sub:
                - name: group by single column
                  desc: 'The partition is formed by a single column'
                - name: group by multiple columns
                  desc: 'The partition is formed by multiple columns, creating hierarchy'
            - name: rolling window calculation
              desc: 'Performs rolling-window aggregation'
            - name: create frequency table  # TODO this may be covered by group by single column
              desc: 'Count the frequency of non-quantitative variables within a column'
            - name: cross tabulate
              desc: 'such as with a pivot table/crosstab'                              
        - name: reshape
          desc: "Operations fundamentally change the table's structure, without summarizing any data"
          sub:
            - name: spread table
              desc: 'Expand two columns of key value pairs into multiple columns'
            - name: gather table
              desc: 'Collapses table into key value pairs'
    - name: display dataset
      desc: 'Different ways to check in on the state of the dataset during wrangling'
      sub:
        - name: format table display
          desc: 'Operations that adjust the table displace, such as how many decimals to round floats'
        - name: visualize data
          desc: 'Employing any kind of data visualization, including a table'
        - name: describe statistically
          desc: "Generates any kind of descriptive statistics of the dataset's central tendency, dispersion and distribution shape"
    - name: check sanity
      desc: 'Operations that confirm the inspect the state of the data during wrangling'
      sub:
          - name: run a test
            desc: 'Operations output a clear pass or fail value'
            sub:
              - name: report rows with column number discrepancies
                alias: check for column mismatch
                desc: 'Check the number of columns between rows or tables'
              - name: test for equality
                desc: 'Test if two data structures are exactly the same'
              - name: test different computations for equality
                desc: 'Test the results of a calculation against different methods/packages'
              - name: Validate data quality with domain-specific rules
                desc: 'Such as if the average temperature is higher than the maximum recorded temperature'
          - name: check results
            desc: 'Operations that output some visual representation of the table'
            sub:
              - name: peek at data
                desc: 'Display the first *n* rows and all columns of the table'
              - name: inspect table schema
                desc: 'Check the data types of columns'
              - name: display rows with missing values
                desc: 'Show rows that contain an NA value'
              - name: check for NAs
                desc: 'See if any rows have NA values'
          - name: count the data
            desc: 'Operation that count things in the table'
            sub:
               - name: count number of rows
                 desc: 'Printing out the total number of observations in a table'                
               - name: count unique values
                 desc: 'Report the number of unique values in one or more variables'
    - name: export
      desc: 'Export the results of data wrangling.'
- name: observations
  desc: 'These codes cover observations from the coder about the wrangling processes, not actions performed by the journalist'
  sub:
    - name: data acquisition
      desc: 'How the data was acquired by journalists'
      sub:
          - name: collect raw data
            desc: 'Using first-hand observations or logs as data'
          - name: use previously cleaned data
            desc: 'Data that originated from a colleague'
          - name: use public data
            desc: 'Includes open-source datasets, tables on Wikipedia, etc..'
          - name: use academic data
            desc: 'Use data collected from an academic study'
          - name: use non-public, provided data
            desc: 'Use data that is not publically available'
          - name: use open government data
            desc: 'Data publically available on open data portals'
          - name: Freedom of Information data
            desc: 'Data that was obtained via FOI/FOIA requests'
          - name: use another news orgs data
            desc: 'A dataset previously published by another news organization'
          - name: use data from colleague
            desc: 'A dataset was provided by another journalist'
    - name: workflow building
      desc: 'Codes pertaining to how the wrangling workflow is built.'
      sub:
          - name: annotate workflow
            desc: 'Adding comments or notes in Markdown that explain what the journalists doing.'      
          - name: think computationally
            desc: 'Codes that demonstrate computational thinking on the part of the journalist.'
            sub:
              - name: architect a subroutine
                desc: 'A set of instructions grouped together to be performed multiple times'
              - name: architect repeating process
                desc: 'Instances where journalists employed a loop'
          - name: toggle step on and off
            desc: 'Ensuring that some code segments are not always run, such as by commenting out lines of code'
    - name: wrangling purpose
      desc: 'Why does this data need to be wrangled?'
      sub:
        - name: input for downstream applications
          desc: 'Output from wrangling will be input into some other program'
          sub:
            - name: wrangle data for graphics
              desc: 'Data need to be formatted in order to be visualized in an article, including tables.'
            - name: wrangle data for model
              desc: 'Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification'
        - name: remove erroneous data
          desc: 'There are errors in the data that need to be removed'
        - name: creating new datasets
          desc: 'The purpose of wrangling is to create a new dataset'
          sub:
            - name: combine drifting datasets
              desc: fix schema drift
              desc: 'Reconcile difference in periodically published datasets that have superficially changed over time'
            - name: combine seemingly disparate datasets
              desc: 'When a notebook largely constitutes combining seemingly unrelated datasets'
            - name: combine data and geography
              desc: 'Pairing data with GIS info'
        - name: aggregate the forest from the trees
          alias: Get a summary of the data
          desc: 'Data of individual observations is aggregated in an attempt to find some meaningful structure or patterns'
    - name: analysis
      desc: 'Kinds of analysis data journalists need to wrangle data to perform'
      sub:
        - name: interpret statistical/ml model
          desc: 'Analyze features from a model such as linear regression or classification trees'
        - name: compare different groups along a common metric
          desc: 'The end analysis is just comparing different groups by a common metric.'
        - name: identify extreme values
          desc: 'Identify values that are at the ends of the range, but not strictly outliers.'
        - name: outlier detection # TODO merge with identify extreme values
          desc: 'Finding extreme cases or outliers in the data'
        - name: show trend over time
          desc: 'Analysis consists of showing how values change over time'
        - name: calculate a statistic
          desc: 'Calculate a single value for from a dataset, such as number of records.'
        - name: answer a question
          desc: 'Analysis consists of using data to answer a specific question'          
        - name: examine relationship
          desc: 'Analysis consists of examining the relationship between different phenomena'
        - name: explain variance
          desc: 'This can be done via PCA'
        - name: identify clusters or lack of clusters
          desc: 'Look for meaningingful groups within the data'
        - name: find nearest neighbours in the network
          desc: '(Network analysis) Find the closest neighbours for all points'
        - name: explore dynamic network flow
          desc: '(Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities.'
    - name: strategies
      desc: 'General strategies journalists employ when wrangling data.'
      sub:
        - name: tables evolve
          desc: 'Data and objects are destroyed during the wrangling process.'
          sub:
            - name: value replacement
              desc: 'The output of any column calculation is reassigned to an existing column.'
            - name: temporary joining column
              desc: 'When a key for joining two tables is created and destroyed immediately after the join.'              
            - name: refine table
              desc: 'Table refinement refers to when a table is subset *in place*, a new object is not created in the environment.'
        - name: data is precious
          desc: 'Data and objects are neverly actually lost in the programming environment.'
          sub:
            - name: preserve existing values
              desc: 'The output of any column calculation is assigned to a new column'
            - name: Create child table
              desc: 'A child table is a subset of the parent table declared as a new object in the environment.'
        - name: set data confidence threshold
          desc: 'Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value.'
        - name: table splitting
          desc: 'Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.'
          sub:
            - name: split, compute, and merge
              desc: 'First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.'
            - name: split and compute
              desc: 'One table is split into two or more and identical computations are applied to each table'
        - name: tolerate dirty data
          desc: 'Analysis continues despite clear data quality issues.'
    - name: pain points
      desc: 'Areas where journalist seem/could be frustrated in the wrangling process.'
      sub:
        - name: fix incorrect calculation
          desc: 'Calculations in the data are incorrect and the journalist must recalculate them'      
        - name: repetitive code
          desc: 'Instances where code is repetitively copied and pasted.'
        - name: make an incorrect conclusion
          desc: 'Instances where the journalist has made an incorrect conclusion about the data.'
        - name: post-merge clean up
          desc: 'Pain points that come from the result of merging two datasets together'
          sub:
            - name: resort after merge
              desc: 'When a sort has to be re-done because a merge ruining the pre-merged order.'
            - name: fill in NA values after an outer join
              desc: 'As outer joins do not drop non-matching rows, those values have NA'
        - name: encode redundant information
          desc: 'When data that already exists in the table is recoded into the table.'
        - name: post-aggregation clean up
          desc: 'Pain points that come from the result of grouping a table.'
          sub:
            - name: data loss from aggregation
              desc: 'When table columns are lost because they were dropped form resulting table due to not being relevant in aggregation.'
            - name: silently dropping values after groupby
              desc: 'Values other than thsoe being grouped and calculated upon are lost in a group by operation'
        - name: data too large for repo
          desc: 'Raw data cannot be included in SCM because files are too large'