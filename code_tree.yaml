- transform:
    - combine:
        - inner join tables
        - cartesian product        
        - key generation:
            - designate a primary key
            - create and discard temporary join key
            - join on geography
        - append:
            - right join tables
            - left join tables
            - append to table
            - merge data sources
            - merge metadata
        - consolidate data sources:
            - union tables
    - reshape:
        - gather table
        - spread table
        - extract single value
        - use lookup table
        - create a crosstab # is this the same as "use lookup table?"
        - drop columns
        - create join key        
        - add calculated column from axillary data
        - add column from intra-table calculation
        - changing resolution:
            - aggregate and calculate:
                - group by
                - group by geography
                - group by nominal
                - group by datetime
                - group by boolean expression
                - multi-dimensional transform
                - create rolling window
                - sum column
                - construct pivot table
    - split:
        - split, compute, and merge
        - split and compute
        - architect parallel workflows        
- prep for analysis:
    - calculate frequency:
        - count column values
        - count rows
        - count unique values in column
    - rank entities by common metric:
        - formulate performance metric:
            - figure a rate:
                - calculate percentage
                - calculate per 1k
                - calculate proportion
            - calculate central tendency:
                - calculate mean
            - compare trends over time:
                - calculate percentage difference # a.k.a precent change
                - calculate difference
            - calculate spread
            - calculate standardized scores:  # for locating outliers
                - calculate z-score
        - sort table and view top        
- cleaning:
    - detrending:
        - adjust for inflation
        - adjust for season
        - compute index number
    - deduplicate:
        - prevent double-counting
        - drop entirely duplicate rows
        - drop rows with duplicate value in one column
        - create a unique key
        - remove all rows but the master record
    - format column values:
        - strip whitespace
        - change case
        - convert to date object
        - replace NA values
        - scale numeric values
    - standardize table:
        - resolve entity names
        - impose standardized column names
    - extract value from column:
        - regular expression replace    
        - extract property from datetime
        - slice column values
        - split column on delimiter
    - pruning:
        - trim by date range
        - trim by geographic area
        - filter rows
        - drop erroneous rows
        - remove incomplete data
        - set data confidence threshold
    - schema:
        - canonicalize column names
        - change column data type
        - rename column
        - name all columns
    - fix errors:
        - fix data errors manually
        - geocode addresses
    - sort table
    - Log-ify values
- document provenance:
    - encode table name as new column
    - encode file name as new column
- build workflow:
    - document:
        - annotate workflow        
    - think computationally:
        - architect a subroutine
        - architect repeating process
        - repetitive code
    - export data:
        - export intermediate results
        - export results
        - export data for graphics  # Make wrangle data for graphics, measurement, etc... What need'st thou wrangle so much data about?
    - cache results from external service
- acquire:
    - data type:
        - use non-tabular data:
            - use structured ascii
            - use geospatial data
        - use tabular data
    - data source:
        - extraction:
            - pull tables out of pdf
            - scrape web for data
        - use existing data:
            - use third-party data
            - use another news orgs data
            - use previously cleaned data
        - create new data:
            - construct table manually
           # - collect raw data # First-hand observations or logs (Have not seen yet)
            - generate data computationally
- display:
    - display a table:
        - peek at data
        - inspect table schema        
        - format table display
        - display entire table
    - Understand data:
        - plot histogram
        - plot stacked bar chart
        - plot stacked column chart
        - plot scatterplot
        - plot trendline
        - plot column chart
- wtf:
    - pain point
    - omits data quality exploration
    - Wrangle data for graphics
    - toggle step on and off
    - tolerate dirty data
- not wrangling:
    - analysis:
        - fit a generalized linear model
        - Find most frequently occurring  # although this is tied closely with sort
        - Find worst offender