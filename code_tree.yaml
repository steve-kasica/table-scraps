- name: actions
  desc: 'Codes that describe actions the journalist has taken to wrangle data for further analysis.'
  sub:
    - name: import
      desc: 'Methods for importing data into an environment for wrangling.'
      sub:
        - name: download
          desc: 'Data is imported via download from an external source, such as a RESTful API.'
          sub:
            - name: geocode addresses
              desc: 'Translate addresses to latitude-longitude coordinates through web service, such as those from Bing.'
            - name: scrape web for data
              desc: 'Systematically parsing webpages for relevant data.'
            - name: query database
              desc: 'Data is imported through a database query.'
        - name: create
          desc: 'Data is created inside the wrangling environment.'
          sub:
            - name: construct table manually
              desc: 'Using tables where column names and table values were either copy-and-pasted or entered manually.'
            - name: generate data computationally
              desc: 'Using tables populated programatically.'
        - name: extract
          desc: 'Extraction occurs when data is one step removed from the format it needs to be in to be imported into the environment.'
          sub:
            - name: pull tables out of pdf
              desc: 'Using a table extraction tool, such as Tabula, to parse tables inside PDF documents.'
        - name: read
          desc: 'Import data by reading a file on disk such as a CSV'
          sub:
            - name: read as tabular data
              desc: 'Refers to importing files from disk as a table in the environment. Files can be .csv, .xlsx, .fec, and .shp, .RData'
    - name: amend
      desc: '*Amending* a table constitutes creating new columns in the table without *integrating* other tables.'
      sub:
          - name: detrend
            desc: '"filter out the secular effect in order to see what is going on specifically with the phenomenon you are investigating," Philip Meyer in *Precision Journalism*.'
            sub:
                - name: adjust for inflation
                  desc: 'TK'
                - name: compute index number
                  desc: 'TK'
          - name: encode table identification in row
            desc: 'When some way of identifying the table is encoded as a separate column in each row. Common identification methods include the name of the corresponding file, an arbitrary table name, or boolean value.'
          - name: support network analysis
            desc: 'Actions that modify a table to directly support network analysis'
            sub:
              - name: add foreign key column  # TODO rename to "create edge"
                desc: 'A column with value that define a relationship to another row, which is not necessarily in a different table.'
              - name: define edge weights
                desc: 'Columns that define edge weights'
          - name: formulate performance metric
            desc: 'Codes in this category specify a calculation that is later used to compare different entities or the same entity over time. A recurring theme between many of these notebooks is to compare different entities, such as political parties, by a common, quantitative metric, such as percentage of all newly registered voters.'
            sub:
                - name: calculate standardized score
                  desc: 'Measuring deviation from some definition of "normal."'
                  sub:
                    - name: calculate z-score
                      desc: 'Calculate how many standard deviations a value in a column is away from the mean. Journalists perform this function to simply find outliers in a dataset or when preparing the data for principle component analysis.'
                - name: calculate normalized score  # normalized and standardized can have very different uses between communities
                  desc: 'Measuring the differences between groups of different sizes.'
                  sub:
                      - name: calculate ratio
                        desc: 'Dividing a quantitative variable by another in such a way that enables fair comparisons. Such as per capita'
                      - name: calculate scaled ratio
                        desc: 'For example, calculating per 1,000 rates and percentages.'
                - name: calculate the central tendency
                  desc: 'Measuring what a typical value is in the data.'
                  sub:
                    - name: calculate mean
                      desc: 'The average of a set of numbers.'
                    - name: calculate median
                      desc: 'The middle value in a range of numbers.'
                - name: calculate change
                  desc: 'Measuring how much things change, usually over time.'
                  sub:
                    - name: calculate percentage difference
                      desc: '"the difference between two values taken as a percentage of whichever value you are using as the base," according to Philip Meyer in *Precision Journalism.* This term is synonymous with percent change.'
                    - name: calculate difference
                      desc: 'Subtracting two quantitative variables, including scalar values, vectors, and matricies.'
                # - name: calculate spread  # is this different from calculate difference?
                #   desc: 'TK'
                - name: calculate using an external data structure
                  desc: 'When new column values are calculated using table values and some auxiliary data structure, e.g. an array'
                - name: calculate edge weights
                  desc: '(Network analysis specific): calculate weights between nodes, such as Haversine distance.'
          - name: key generation
            desc: 'Operations that create "key" columns.'
            sub:
                - name: create a semi-unique key
                  desc: 'Journalist creates a key that is a close, but imperfect, unique key, e.g. concatenating first name and surname.'
                - name: create a unique key
                  desc: 'Journalist create a key that is actually unique in the table'
                - name: concatenate columns into key
                  desc: 'TK'
                - name: designate column as primary key
                  desc: 'Designating a column as the unique identifier for all rows in the table.'
          - name: rank data
            desc: 'Operations that encode semantic meaning about the data with table index.'
            sub:
                - name: assign ranks         
                  desc: 'When a column of numerical ranks is explicitly assigned to rows in the table.'
                - name: break ties
                  desc: 'TK'
                - name: sort table
                  desc: 'When rank is implicitly assigned by rearranging row position in the table.'
          - name: create flag
            desc: 'Flags are boolean expressed computed upon column values and used in filtering and grouping'
    - name: clean
      desc: 'Operations to correct erroneous or remove otherwise unwanted rows and values from the table.'
      sub:
          - name: trim fat
            desc: 'Winnow down data that is not relevant to analysis.'
            sub:
                - name: winnow columns
                  desc: 'Simply put, these operations remove table columns.'
                  sub:
                    - name: drop columns  # TODO merge into subset columns
                      desc: 'Remove columns from table by specifying the ones you want to remove.'
                    - name: select columns  # TODO merge into subset columns
                      desc: 'Remove columns from table by specifying the ones you want to keep.'
                    - name: subset columns
                      desc: 'Removing columns from a table by specifying which ones to remove or keep.'
                    - name: align table columns for consolidation  # TODO WTF was this?
                      desc: 'TK'
                - name: winnow rows
                  desc: 'Simply put, these operations remove table rows.'
                  sub:
                      - name: trim by date range
                        desc: 'Removing rows that are inside or outside a specific date range. This can be a method for detrending data by adjusting for season.'
                      - name: trim by geographic area
                        desc: 'Remove rows that are inside or outside a geographic area.'
                      - name: trim by quantitative threshold
                        desc: 'Remove rows that are above, below, equal to, or not equal to a numeric value.'
                      - name: trim by contains value
                        desc: 'Remove rows that do or do not contain specific values or types of values.'
                - name: filter rows  # TODO how is this different from prune rows?
                  desc: 'TK'
                - name: drop erroneous rows
                  desc: 'Remove rows that have any number of kinds of errors in them.'
                - name: remove incomplete data
                  desc: 'Drop row if value(s) are incomplete, usually denoted as NA.'
                - name: deduplicate
                  desc: 'Remove rows from the table that contain two or more of the same "observation." Duplicates may constitute rows with identical values in all, one, or zero columns.'
                  sub:
                      # - name: prevent double-counting
                      #   desc: ''
                      - name: drop duplicate rows
                        desc: 'Remove a row from a table if one or more column values exactly matches all the column values of another row.'
                      # - name: drop rows with duplicate value in one column  # Merge into drop duplicate rows
                      #   desc: 'Remove a row if it share the same value in a specific column with another row.'
                      - name: remove all rows but the master record
                        desc: 'TK'
          - name: edit
            desc: 'Operations that modify table values'
            sub:
                - name: replace NA values
                  desc: 'Raw data may contain incomplete table values (denoted as NA) or empty values (denoted as NULL)'
                - name: fix data errors manually
                  desc: 'Instances where individual row-column values are changed by a journalist.'
                - name: fix incorrect calculation
                  desc: 'TK'
                - name: remove with regular expression
                  desc: 'When column values are replaced with empty strings using regular expressions.'
                - name: pad column values
                  desc: 'Adding either character prefixes or suffixes consistently to every row within a column'
                - name: resolve entity names
                  desc: 'A surjective mapping from previous column values to new column values'
                  sub:
                      - name: perform name entity resolution manually  # TODO this seems like two axes: categorical vs. quantiative and manually vs. automatic.
                        desc: 'Manually specifying the mapping between old and new column categorical values. Not manually changing individual rows.'
                      - name: strip whitespace
                        desc: 'Removing extra whitespace characters from entity name'
                      - name: combine entities by string matching  # Double check definition
                        desc: 'If column contains a specific string, then rename entire column to another string.'
                      - name: reconcile primary keys between tables  # This is a good one
                        desc: 'Name entity resolution between tables to facilitate joining'
                      - name: resolve to arbitrary entity name among choices
                        desc: 'The actual text of the entity is not necessary as import as uniqueness.'
                      - name: resolve by substring
                        desc: 'Taking a substring of each entity with the expectation that a fixed, shorter version will combine some entities.'
                      - name: bin values
                        desc: 'Classifying quantitative data into categories, e.g. x > 100 <=> category = "under spent" and x > 100 <=> category = "over spent"'
                - name: translate entity names
                  desc: 'Performing a bijective mapping between values, often to improve semantic meaning.'
                  sub:
                      - name: translate entity names manually
                        desc: 'Manually specify the mapping between individual'
                      - name: join with lookup table
                        desc: 'Two column tables meant for mapping a key from one table to the unique column in the lookup table.'
                - name: scale values
                  desc: 'Operations that apply some mathematical operation to columns of quantitative data. This code is different from the codes under **Formulate performance metric** because this closer to cleaning.'
                  sub:
                      - name: Log-ify values
                        desc: 'TK'
                      - name: perform scalar multiplication
                        desc: 'TK'
                      - name: whiten matrix
                        desc: 'Divide each feature by its standard deviation across all observations to give it unit variance.'
                - name: backfill missing data
                  desc: 'Create new "rows" in the data where there are missing entries.'
          - name: format
            desc: 'Operations that modify the table values appearance or style.'
            sub:
                - name: format values
                  desc: 'Operations that modify the values within the table.'
                  sub:
                      - name: change case
                        desc: 'TK'
                      - name: change date format
                        desc: 'TK'
                      - name: round floating point
                        desc: 'TK'
                      - name: remove delimiting characters
                        desc: 'Remove characters such as newline (\n) that might make data ill-formed.'
                - name: format schema
                  desc: 'Operations that modify anything except table values.'
                  sub:
                      - name: canonicalize column names
                        desc: 'Operations that change column names'
                      - name: change column data type
                        desc: 'For example, changing a column of values from strings to integers'
                - name: sort table rows  # TODO how is sorting not ranking?
                  desc: 'Sorting a table in a way that does not rank rows, such as by a unique identifier'
          - name: separate
            desc: 'Mapping one column into more than one because multiple dimensions of the dataset packed into one column.'
            sub:
              - name: extract property from datetime
                desc: 'Such as extracting the day of the month, year, etc.. from a datetime column'
              - name: slice column values
                desc: 'Extracting the relevant column values by character position, e.g. the first five digits of a zip code.'
              - name: split column on delimiter  # merge into split column
                desc: 'Separate data dimensions by a common character, e.g. lat-long coordinates separated by a comma.'
              - name: get unique values
                desc: 'TK'            
    - name: integrate
      desc: 'Combining data residing in different tables into one table.'
      sub:
        - name: consolidate
          desc: 'Consolidation is characterized by actions that add essentially combine rows of two tables.'
          sub:
            - name: union tables
              desc: 'TK'
            - name: concatenate files together
              desc: 'TK'
            - name: full join tables
              desc: 'Combine all rows and all columns of the two tables. a.k.a full outer join'
        - name: intersect
          desc: 'Joining two tables such that non-matching rows are excluded from the combined table.'
          sub:
            - name: inner join tables
              desc: 'TK'
            - name: natural join  # TODO what does this really mean?        
              desc: 'TK'
        - name: supplement
          desc: 'Supplementation is characterized by integration operations that add dimensions to existing data'
          sub:
            - name: outer join tables
              desc: 'A join that returns rows with no corresponding match in the table being joined two, e.g. left or right joins.'
            - name: amend with column from another table
              desc: 'When a table users a column from a *parallel* table (like arrays) to compute a new column.'
            - name: concat parallel tables
              desc: 'When columns from multiple, parallel tables are concatenated together to form a new table.'
            - name: self join table
              desc: 'Join a table with itself'
        - name: other
          desc: 'Integration operations that do not fall into the previous two categories'
          sub:
            - name: cartesian product  # seems like the opposite of intersection
              desc: 'TK'
    - name: transform
      desc: 'Operations that transform a table into an aggregated, lower-resolution view of the original table.'
      sub:
          - name: summarize
            desc: ''
            sub:
                - name: join aggregate
                  desc: '"extends the input data objects with aggregate values in a new field" - Vega-Lite Join Aggregate docs.'
                - name: group
                  desc: 'Codes that group the table along one or more table dimension.'
                  sub:
                      - name: single dimensional group by
                        desc: 'Grouping one or more columns such that grouped columns are hierarchically ordered when grouping by two or more columns. This operation is commonly implemented with `groupby` in Pandas.'
                        sub:
                            - name: group by single column
                              desc: 'When a table is grouped by a single column.'
                            - name: group by multiple columns
                              desc: 'When a table is grouped by multiple columns, creating hierarchy.'
                            - name: create lookup table
                              desc: 'Creating a table with two columns that serves as a map from one value to another.'
                      - name: group by double axis
                        desc: 'Grouping by more than one column such that one grouped column is not hierarchically paired with another grouped column.'
                        sub:
                          - name: construct pivot table
                            desc: 'Is essentially the same as a crosstab except that the table axes may contain hierarchical, nominal data.'
                          - name: create a crosstab
                            desc: 'User performs a crosstab query, as defined by [Microsoft Office](https://support.office.com/en-us/article/make-summary-data-easier-to-read-by-using-a-crosstab-query-8465b89c-2ff2-4cc8-ba60-2cd8484667e8). Crosstabs are very similar to the reshaping operation *spread*, except that they summarize values using aggregate functions.'
                      - name: create rolling window
                        desc: ''
          - name: calculate  # TODO are these really any different from performance metrics?
            desc: 'These are within-column calculations that often, but not always, immediately follow an *aggregation* operation.'
            sub:
                # - name: sum column values  # Merge with sum along a dimension
                #   desc: 'Calculate the sum of all values within a column'
                - name: sum along dimension
                  desc: 'Calculate the sum of all values within a row or column'
                - name: get extreme values
                  desc: 'Calculate the highest or lowest value(s)'
                # - name: get min value  # TODO merge with get extreme value
                #   desc: 'Calculate the lowest value in a column ofquantitative values.'
                - name: count value frequency
                  desc: 'Count the frequency of categorical variables within a column'
                - name: count unique values in column  # TODO What is this? Won't this be a scalar?
                  desc: ''
          - name: reshape
            desc: "Operations fundamentally change the table's structure, but do not perform any kind of summarization calculation. *Constructing a pivot table* often involves a *spread-like* operation when defining what values to use as columns in the new table. The difference with *reshaping* is that sometimes the journalist may not summarize the reshaped table."
            sub:
                - name: spread table
                  desc: 'Expand two columns of key value pairs into multiple columns.'
                - name: gather table
                  desc: 'Collapses table into key value pairs.'
    - name: display dataset
      desc: 'Different ways to check in on the state of the dataset during wrangling.'
      sub:
          - name: display a table
            desc: 'Operations that have to do with displaying the raw data as a table.'
            sub:
                - name: format table display
                  desc: 'Operations that adjust the table displace, such as how many decimals to round floats'
                - name: display entire table
                  desc: 'Displaying all rows and all columns of a table'
          - name: Understand distribution
            desc: 'Operations that reveal something of the underlying distribution of data.'
            sub:
                - name: Visualize data
                  desc: 'Employing any kind of data visualzation'
                # - name: Plot histogram
                #   desc: ''
                # - name: plot stacked bar chart
                #   desc: ''
                # - name: plot stacked column chart
                #   desc: ''
                # - name: plot scatterplot
                #   desc: ''
                # - name: plot trendline
                #   desc: ''
                # - name: plot column chart
                #   desc: ''
                # - name: plot violin plot
                #   desc: ''
                # - name: plot boxplot
                #   desc: ''
                # - name: plot scree plot
                #   desc: ''
                # - name: plot line chart
                #   desc: 'Visualizations with lines connecting points on a chart.'
    - name: check sanity
      desc: 'Operations that confirm the effect of a previous wrangling operation.'
      sub:
          - name: run a test
            desc: 'Operations output a clear pass or fail value, often implemented by counting things.'
            sub:
              - name: report rows with column number discrepancies
                desc: 'Finds if a row has a different number of columns than the header row.'
              - name: compare total number of rows  # rename to test for equality?
                desc: ''
              - name: test for equality
                desc: 'Test if two data structures are exactly the same, e.g. two data frames.'
              - name: test different computations for equality  # TODO Upshot also did this with variance
                desc: ''
          - name: check results
            desc: 'Operations that output some visual representation of the table.'
            sub:
              - name: check results of previous operation  # seems too vague
                desc: ''
              - name: peek at data
                desc: 'Display the first *n* rows and all columns of the table'
              - name: inspect table schema  # Tamara had issues with this one
                desc: ''
              - name: display rows with missing values
                desc: 'E.g. filtering rows with a NA value in a particular column'
              - name: check for NAs
                desc: 'See if any rows have NA values.'
              - name: count number of rows
                desc: 'Printing out the total number of rows in a table'                
    - name: export data
      desc: 'Ways in which journalist export the results of their data wrangling.'
      sub:
          - name: export intermediate results
            desc: ''
          - name: export results
            desc: ''                
- name: observations
  desc: 'These codes cover observations from the coder about the wrangling processes, not actions performed by the journalist.'
  sub:
    - name: data acquisition
      desc: 'How the data was acquired by journalists'
      sub:
          - name: collect raw data
            desc: 'Using first-hand observations or logs as data.'
          - name: use previously cleaned data
            desc: 'Data that originated from a colleague.'
          - name: use public data
            desc: 'Includes open-soucred datasets'
          - name: use academic data
            desc: ''
          - name: use non-public, provided data
            desc: ''
          - name: use open government data
            desc: 'Data publically available on open data portals, such as data.gov'
          - name: Freedom of Information data
            desc: 'Data that was obtained via FOI/FOIA requests.'
          - name: use another news orgs data
            desc: 'A dataset previously published by another news organization'
          - name: use data from colleague
            desc: 'A dataset was provided by another journalist.'            
    - name: workflow building
      desc: 'Codes pretaining to how the wrangling workflow is built.'
      sub:
          - name: cache results from external service
            desc: 'When results from an API call are cached in disk.'
          - name: annotate workflow
            desc: 'Adding comments or notes in Markdown that explain what the journalistis doing.'      
          - name: think computationally
            desc: 'Codes that demonstrate computational thinking on the part of the journalist.'
            sub:
              - name: architect a subroutine
                desc: ''
              - name: architect repeating process
                desc: 'Instances where journalists employed a loop.'
          - name: toggle step on and off
            desc: 'Some wrangling steps were not always run. Toggling off is often accomplished by commenting out code.'
    - name: wrangling purpose
      desc: 'Why does this data need to be wrangled?'
      sub:
        - name: downstream applications
          desc: 'Output from wrangling will be input into some other program'
          sub:
            - name: wrangle data for graphics
              desc: 'Data need to be formatted in order to be visualized in an article'
            - name: wrangle data for machine learning model
              desc: 'Data is being wrangled in order to create a model, whether the main point of the piece is for prediction or classification'
        - name: combine drifting datasets
          desc: 'Reconcile difference in periodically published datasets that have superficially changed over time, such as schema differences or entity names, to consolidate more than one dataset.'
        - name: combine seemingly disparate datasets
          desc: 'When a notebook largely constitutes combining seemingly unrelated datasets.'
    - name: analysis  # TODO revisit all sub codes
      desc: 'Kinds of analysis data journalists need to wrangle data to perform.'
      sub:
        - name: summarize dataset  # Good one
          desc: 'Analysis consists of summarizing and describing different aspects of the dataset.'
        - name: interpret statistical/ml model  # Good one
          desc: 'Analyze features from a model such as linear regression or classification trees'
#         - name: analyze a model for insights  # TODO merge into "interpret statistical/ml mode"
#           desc: 'Looking at the learned features of a model for insight or predictions, e.g. "classification trees"'
        - name: compare different groups along a common metric  # Good one
          desc: 'The end analysis is just comparing different groups by a common metric.'
        - name: show trend over time  # Good one
          desc: 'Analysis consists of showing how values change over time'
        - name: calculate a statistic  # Good one
          desc: 'Calculate a single value for from a dataset, such as number of records.'
          
        - name: analyze principle components
          desc: ''
#         - name: run cluster analysis
#           desc: 'Run some kind of clusting analysis, such as K-means.'
#         - name: fit a generalized linear model
#           desc: ''
        - name: answer a question  # Maybe a good one
          desc: 'Analysis consists of using data to answer a specific question'
        - name: look for trends
          desc: ''
        - name: find most frequently occurring
          desc: ''
        - name: find worst offender
          desc: ''
#         - name: image analysis TODO delete
#           desc: 'A programmatic, quantitative analysis of images.'
        - name: create a table to lookup values
          desc: 'The end to wrangling is just to create a table to lookup values.'
        - name: find nearest neighbours in the network
          desc: '(Network analysis) Find the closest neighbours for all points'
        - name: explore dynamic network flow
          desc: '(Network analysis) explore the flow between different nodes in the graph, e.g. migration between cities.'
    - name: strategies
      desc: 'General strategies journalists employ when wrangling data.'
      sub:
        - name: value replacement
          desc: 'The output of any column calculation is reassigned to an existing column.'
        - name: preserve existing values
          desc: 'The output of any column calculation is assigned to a new column'
        - name: set data confidence threshold
          desc: 'Removes rows where a quantitative value is less than, greater than, or not equal to a numeric value.'
        - name: table splitting
          desc: 'Tables may be divided, partitioned, or otherwise split into multiple tables to accomplish a transformation goal.'
          sub:
            - name: split, compute, and merge  # wait is it filter or split? Is it a clean partition?
              desc: 'First, the journalist partitions a single data frame into multiple, separate data frames. Then, often identical computations are run on all the data frame. Finally, the multiple data frames are consolidated into one data frame again.'
            - name: split and compute
              desc: 'One table is split into two or more and identical computations are applied to each table.'
            - name: peel and merge
              desc: 'When a single column of a data frame is isolated and computed upon, such as computing the frequency of a nominal column, and the results are merged back into the original table.'
            - name: merge tables to create pivot table
              desc: ''
        - name: tolerate dirty data
          desc: 'Analysis continues despite clear data quality issues.'
        - name: temporary joining column
          desc: ''
    - name: pain points
      desc: 'Areas where journalist seem/could be frustrated in the wrangling process.'
      sub:
        - name: omits data quality exploration
          desc: 'When it appears the journalist has excluded steps taken to explore the quality of the data'
        - name: repetitive code
          desc: 'Instances where code is repetitively copied and pasted.'
        - name: make an incorrect conclusion
          desc: 'Instances where the journalist has made an incorrect conclusion about the data.'
        - name: post-merge clean up
          desc: 'Pain points that come from the result of merging two datasets together'
          sub:
            - name: resort after merge
              desc: 'When a sort has to be re-done because a merge ruining the pre-merged order.'
            - name: fill in NA values after an outer join
              desc: 'As outer joins do not drop non-matching rows, those values have NA'
        - name: encode redundant information
          desc: 'When data that already exists in the table is recoded into the table.'
        - name: data loss from aggregation
          desc: ''
        - name: encoding provenance in data
          desc: ''
        - name: data too large for repo
          desc: 'Raw data cannot be included in SCM because files are too large'
        - name: Silently dropping values after groupby
          desc: 'Pandas silently drops NA values in a groupby'