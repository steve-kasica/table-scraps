{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.util import getCodes, displayMarkdown, getCitations, getCodeset\n",
    "from IPython.core.display import HTML, Markdown, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import re, yaml\n",
    "import vega_datasets\n",
    "\n",
    "codeset = pd.read_csv('data/codeset.csv', ).replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import codes\n",
    "#\n",
    "# The cell below recursively searches the `notebooks/` directory for files with a `.html.pdf` extension. These \n",
    "# are PDF printouts of computational notebooks and scripts that I coded using the comments feature in \n",
    "# Adobe Acrobat DC (https://acrobat.adobe.com/ca/en/acrobat.html). This notebook needs to import all \n",
    "# codes from the open coding process.\n",
    "codes = pd.read_csv('data/code-analysis-network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata on analyzed notebooks\n",
    "# \n",
    "# The cell below parses the works-cited section of the `README.md` document with regular expressions. \n",
    "# A demo of this regular expression can be found on [regexr.com](https://regexr.com/4htcn). \n",
    "# This section contains a citation for every notebook included in this analysis. \n",
    "# Some of the URLs from the works cited list are cleaned so that the path matches the path in this repository \n",
    "# under `notebooks/`.\n",
    "\n",
    "citations = getCitations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import repos and contributors\n",
    "#\n",
    "# The file `notebook-search.ipynb` mines GitHub for repos containing data-journalism \n",
    "# workflows and exports this data to `data/repos.csv` and `data/contributors.csv`.\n",
    "\n",
    "# Get all repos\n",
    "repos = pd.read_csv('data/repos.csv')\n",
    "\n",
    "# Subset repos to only those that contained data analysis\n",
    "\n",
    "\n",
    "# Get contributors, which is really contributors to keeper notebooks\n",
    "contributors = pd.read_csv('data/contributors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Notebook coding order\n",
    "# \n",
    "# The works cited page of analyzed computational notebooks \n",
    "# serves as a list of coded notebooks, but it doesn't preserve the order \n",
    "# in which they were coded. The `reposIncluded` list has lists each repo in \n",
    "# reverse chronological order.\n",
    "\n",
    "pathsIncluded = [\n",
    "    'demolitions',\n",
    "    'gunsales',\n",
    "    'us-weather-history',\n",
    "    'california-buildings-in-severe-fire-hazard-zones',\n",
    "    'swana-population-map',\n",
    "    '1805-regionen im fokus des US-praesidenten',\n",
    "    'school-choice',\n",
    "    '201901-achievementgap',\n",
    "    'general-election-2015-classification-tree',\n",
    "    '201901-hospitalquality',\n",
    "    'awb-notebook',\n",
    "    'skatemusic',\n",
    "    'new-york-schools-assessment',\n",
    "    'lending-club',\n",
    "    'auditData',\n",
    "    '2019-ems-analysis',\n",
    "    'federal_employees_trump_2017', \n",
    "    'infrastructure-jobs',\n",
    "    'librarians',\n",
    "    'midwife-led-units',\n",
    "    'internal-migration-london',\n",
    "    'electric-car-charging-points',\n",
    "    'school-star-ratings-2018',\n",
    "    'prison-admissions',\n",
    "    'vox-central-line-infections',\n",
    "    'verge-uber-launch-dates',\n",
    "    'buster-posey-mvp',\n",
    "    'work-from-home',\n",
    "    'nyc-trips',\n",
    "    'bob-ross',\n",
    "    'bechdel',\n",
    "    'employment-discrimination',\n",
    "    '2015-11-refugees-in-the-united-states',\n",
    "    'babyname_politics',\n",
    "    'wikipedia-rankings',\n",
    "    'Power_of_Irma',\n",
    "    'Endangered-Species-Act-Louisiana',\n",
    "    'california-h2a-visas-analysis',\n",
    "    '2016-04-republican-donor-movements',\n",
    "    'the-cube-root-law',\n",
    "    '2016-09-shy-trumpers',\n",
    "    '2018-05-31-crime-and-heat-analysis',\n",
    "    '2016-11-bellwether-counties',\n",
    "    'heat-index',\n",
    "    '2018-voter-registration',\n",
    "    'long-term-care-db',\n",
    "    'census-hard-to-map-analysis',\n",
    "    'california-crop-production-wages-analysis',\n",
    "    'california-ccscore-analysis',\n",
    "    '2019-04-democratic-candidate-codonors',\n",
    "]\n",
    "\n",
    "codingOrder = pd.DataFrame({'analysis': pathsIncluded[::-1] }).reset_index().rename(columns={'index': 'coding order'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#\n",
    "# Make sure that I've manually added all the repos to `reposIncluded` that are listed in `README.md`.\n",
    "\n",
    "citMinusPath = set(citations.path.unique()).difference(set(pathsIncluded))\n",
    "pathMinusCit = set(pathsIncluded).difference(set(citations.path.unique()))\n",
    "\n",
    "if len(citMinusPath) > 0:\n",
    "    raise RuntimeError('In `citations` but not in `pathsIncluded`: {}'.format(', '.join(list(citMinusPath))))\n",
    "\n",
    "if len(pathMinusCit) > 0:\n",
    "    raise RuntimeError('In `pathsIncluded` but not in `citations`: {}'.format(', '.join(list(pathMinusCit))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing Saturation\n",
    "\n",
    "We establish saturation in our codeset by monitoring the number of unique codes with respect to the number of repos included in our technical observation study. Approaching 50 repos we notice the size of the codeset leveling off. At this point, we determine the codeset has reached saturation, adequately describing data wrangling actions and processes in this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](figs/codeset_growth.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to visualize the cardinality of the code set per notebook coded, \n",
    "# the `codes` data frame needs to be grouped by article.\n",
    "\n",
    "codesByArticle = codes.groupby(['analysis']).name \\\n",
    "    .unique() \\\n",
    "    .to_frame('codes') \\\n",
    "    .reset_index() \\\n",
    "    .merge(codingOrder, on='analysis') \\\n",
    "    .sort_values('coding order') \\\n",
    "    .reset_index()\n",
    "\n",
    "codesByArticle['cumulative count'] = 0\n",
    "\n",
    "codeset = set()\n",
    "for i, row in codesByArticle.iterrows():\n",
    "    setDiff = set(row.codes).difference(codeset)\n",
    "    codeset = codeset.union(setDiff)\n",
    "    codesByArticle.loc[i, 'cumulative count'] = len(codeset)\n",
    "    codesByArticle.loc[i, 'new codes'] = ', '.join(setDiff)\n",
    "    \n",
    "# Plot the size of the code set as more computational notebooks are analyzed.\n",
    "\n",
    "chart = alt.Chart(data = codesByArticle, title = 'Code Set Growth') \\\n",
    "    .mark_line() \\\n",
    "    .encode(\n",
    "        x = alt.X('coding order:Q', title=\"Repos Coded\"),\n",
    "        y = alt.Y('cumulative count:Q', title=\"Total Unique Codes\")\n",
    "    )\n",
    "\n",
    "# chart\n",
    "# chart.save('codeset_growth.png')\n",
    "# alt.renderers.enable('altair_saver', ['vega-lite', 'png'])\n",
    "\n",
    "# from altair_saver import save\n",
    "# save(chart, 'codeset_growth.png')\n",
    "\n",
    "Markdown('![](figs/codeset_growth.png)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig. S1**: Codeset growth per repo coded. For each notebook included in analysis list which codes were introduced to the code set. After 23 notebooks, some computational notebooks didn't add any new codes. By 50 notebooks, code set growth was so minimal that we declared our code set converged.\n",
    "\n",
    "## Newly introduced codes by repo\n",
    "\n",
    "Below we explicitly list which repos defined new open codes in our codeset. Repos are ordered by when they were coded in our technical observation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. **2019-04-democratic-candidate-codonors**: create child table, trim by categorical value, repetitive code, count unique values, figure a rate, create annotations, outer join, compare groups, deduplicate, create soft key, group by variable, create a frequency table, trim by quantitative threshold, gather, load, format values, export, canonicalize variable names, remove variables, peek at data, govt data portal, union datasets, sort, change var type, self join dataset, aggregate, standardize categorical variables, construct a subroutine, align variables"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. **california-ccscore-analysis**: describe statistically, show trend over time, remove incomplete data, visualize data, calculate spread, count number of rows, standardize variable, trim by date range, inspect data schema, identify extreme values, cross tabulate, divide & conquer, calculate change over time, trim fat"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. **california-crop-production-wages-analysis**: adjust for inflation, construct data manually, construct data pipeline, wrangle data for graphics, combine periodic data, trim by geographic area, inner join, lookup table values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. **census-hard-to-map-analysis**: parse variable, tolerate dirty data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5. **long-term-care-db**: generate high-level summary, generate dataset identification, scrape web for data, create lookup table, refine table, fill in na values after an outer join, count the data, combine categorical values, edit values, replace na values, use non-public, provided data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6. **2018-voter-registration**: impute missing data, calculate a statistic, aggregate join, join aggregate, extract data from pdf, assign ranks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7. **heat-index**: generate data computationally, cartesian product, examine relationship, compute index number"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8. **2016-11-bellwether-counties**: rolling window calculation, get extreme values, create a unique key, remove non-data rows, spread table, use academic data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9. **2018-05-31-crime-and-heat-analysis**: split, compute, and merge, merge seemingly disparate datasets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "10. **2016-09-shy-trumpers**: use another news orgs data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11. **the-cube-root-law**: domain-specific performance metric, use public data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "12. **2016-04-republican-donor-movements**: explore dynamic network flow"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "13. **california-h2a-visas-analysis**: consolidate variables, temporary joining column, preserve existing values, select rows with missing values, resolve entities, api request, schema drift"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "14. **Endangered-Species-Act-Louisiana**: scale values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15. **Power_of_Irma**: variable replacement, set data confidence threshold, use data from colleague, fix incorrect calculation, create togglable operations, use previously cleaned data, interpret statistical/ml model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "16. **wikipedia-rankings**: collect raw data, explain variance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "17. **babyname_politics**: resort after merge, data loss from aggregation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "18. **2015-11-refugees-in-the-united-states**: test for equality, make an incorrect conclusion, lossy join"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "19. **employment-discrimination**: replace variable levels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "20. **bechdel**: data type shyness"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "21. **bob-ross**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "22. **nyc-trips**: full join"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "23. **work-from-home**: concat parallel datasets, create a flag, copy table schema, data too large for repo, split and compute"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "24. **buster-posey-mvp**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25. **verge-uber-launch-dates**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "26. **vox-central-line-infections**: geolocate dataset records, report rows with column number discrepancies"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "27. **prison-admissions**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "28. **school-star-ratings-2018**: remove duplicate variables"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29. **electric-car-charging-points**: perform network analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30. **internal-migration-london**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "31. **midwife-led-units**: freedom of information data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "32. **librarians**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "33. **infrastructure-jobs**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "34. **federal_employees_trump_2017**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "35. **2019-ems-analysis**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "36. **auditData**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "37. **lending-club**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "38. **new-york-schools-assessment**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "39. **skatemusic**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "40. **awb-notebook**: test for null values, silently dropping values after groupby"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "41. **201901-hospitalquality**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "42. **general-election-2015-classification-tree**: wrangle data for model, check for nas"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "43. **201901-achievementgap**: bin values, query database"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "44. **school-choice**: transpose"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "45. **1805-regionen im fokus des US-praesidenten**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "46. **swana-population-map**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "47. **california-buildings-in-severe-fire-hazard-zones**: search for clusters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "48. **us-weather-history**: validate data quality with domain-specific rules"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "49. **gunsales**: adjust for season"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "50. **demolitions**: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, row in codesByArticle.iterrows():\n",
    "    displayMarkdown('{}. **{}**: {}'.format(i + 1, row.analysis, row['new codes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating diversity\n",
    "\n",
    "In order to prevent this code set from being biased by one individual or organization's data wrangling behavior, we deliberately sought out notebooks from a variety of news organizations and data journalists. This analysis comes from, but is not limited to, news organizations that constitute \"major players\" in data journalism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCoverage(df, title, metric, xlab, ylab, ykind='organizations'):\n",
    "    \"\"\"\"\"\"\n",
    "    rank = '{}_rank'.format(metric)\n",
    "    count = '{}_count'.format(metric)\n",
    "    \n",
    "    bars = alt.Chart(data = df.sort_values(rank).head(50), title = title) \\\n",
    "        .mark_bar() \\\n",
    "        .encode(\n",
    "            x = alt.X('{}:Q'.format(count), axis = alt.Axis(title = xlab)),\n",
    "            y = alt.Y('name:N',\n",
    "                  sort = alt.EncodingSortField(field = count, order = 'descending'),\n",
    "                  axis = alt.Axis(title = ylab)\n",
    "            ),\n",
    "            color = alt.Color('is_included:N', title = 'Included in analysis?')\n",
    "        )\n",
    "\n",
    "    display(bars.properties(height=500, width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolificness of news organizations\n",
    "\n",
    "Some news organizations are more engaged in data journalism than others. In order for the result of our technical observation study to be representative of the practices of a variety of organizations, we deliberately selected notebooks for inclusion in our technical observation study by news organizations across the spectrum of prolificness in this genre of journalism.\n",
    "\n",
    "We ranked these organizations by two metrics based on our pool of journalistic code repositories containing data analysis: \n",
    "\n",
    "* The count of individual code repositories \n",
    "* The number of commits by journalists working for different news organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orgs = repos[repos.is_keeper == True] \\\n",
    "    .groupby('org') \\\n",
    "    .agg({\n",
    "        'url': 'nunique',\n",
    "        'commits': 'sum'\n",
    "    }) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={\n",
    "        'org': 'name', \n",
    "        'url': 'repo_count',\n",
    "        'commits': 'commit_count'\n",
    "    })\n",
    "\n",
    "# Assign ranks to each organization per repo count and commit count\n",
    "def rank(df, sort_col, rank_col):\n",
    "    df.sort_values(sort_col, ascending=False, inplace=True)\n",
    "    df[rank_col] = df.reset_index().index + 1\n",
    "\n",
    "rank(orgs, 'repo_count', 'repo_rank')\n",
    "rank(orgs, 'commit_count', 'commit_rank')\n",
    "\n",
    "# Find which organizations have been included in analysis\n",
    "includedOrgs = list(citations.organization.unique())\n",
    "orgs['is_included'] = False\n",
    "orgs.loc[orgs.name.isin(includedOrgs), 'is_included'] = True\n",
    "\n",
    "# Ok, so what did I do?\n",
    "# orgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By number of repos\n",
    "\n",
    "Most news organizations, including *BuzzFeed News*, *Los Angeles Times*, and the *Austin American-Statesman*, create one repository per analysis work flow. We include at least one repository from the top 19 news organizations by the number of unique repositories in our pool journalistic code repositories containing data analysis. We also deliberately select repositories from news organization that only have one repository in this pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](figs/repo-counts-news-orgs.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displayCoverage(orgs,\n",
    "#                 title = 'News Organizations by Repository Counts', \n",
    "#                 metric = 'repo',\n",
    "#                 xlab = 'Number of Repos',\n",
    "#                 ylab = 'News Organization')\n",
    "Markdown(\"![](figs/repo-counts-news-orgs.png)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig. S2**: Repository count by news organization. This bar chart show the number of repositories per news organization in our curated pool of journalistic, data-analysis repositories, color-coded by whether at least one repository from that news organization was included in our technical observation study. Orange values indicate the news organization was included and blue indicates otherwise.\n",
    "\n",
    "### By commits\n",
    "\n",
    "However, one limitation of ranking news organizations by the number of repositories that some organizations, such as *FiveThirtyEight* keep computational notebooks for multiple data journalism articles in one master code repository. A *commit* in Git can be thought of as a unit of change. Thus, the more a repository has changed overtime, the more commits. If a news organization is only using one repository for all their data journalism work, then it should have lots of commits.\n",
    "\n",
    "When ranking news organizations by commit counts, our qualitative analysis includes include the top 18 news organizations by commit count in addition to news organizations with only a few commits in our pool of journalistic code repositories containing data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](figs/repo-commits-news-orgs.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displayCoverage(orgs,\n",
    "#                 title = 'News Organizations by Repositories Commits', \n",
    "#                 metric = 'commit',\n",
    "#                 xlab = 'Number of Commits',\n",
    "#                 ylab = 'News Organization')\n",
    "Markdown('![](figs/repo-commits-news-orgs.png)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig. S3**: News organizations ranked by number of commits. This bar chart show the number of commits per users associated with various news organization in our curated pool of journalistic, data-analysis repositories. The chart is color-coded by whether at least one repository from that news organization was included in our technical observation study. Orange values indicate the news organization was included and blue indicates otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "This analysis includes 25 news organizations out of 37 that had computational notebooks deemed relevant to this analysis (67.57%).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Organization | Is included? |\n",
       "| ------------ | ------------ |\n",
       "| Austin American-Statesman | Yes |\n",
       " | Australian Broadcasting Corporation | No |\n",
       " | BBC | Yes |\n",
       " | Baltimore Sun | Yes |\n",
       " | BuzzFeed News | Yes |\n",
       " | CORRECTIV | Yes |\n",
       " | Center for Public Integrity | Yes |\n",
       " | Chicago Tribune | No |\n",
       " | DataMade | No |\n",
       " | Datastory | No |\n",
       " | FiveThirtyEight | Yes |\n",
       " | Los Angeles Times | Yes |\n",
       " | NOLA | Yes |\n",
       " | National Public Radio | Yes |\n",
       " | Neue Zürcher Zeitung | Yes |\n",
       " | New York Times | Yes |\n",
       " | Politico | No |\n",
       " | Polygraph | Yes |\n",
       " | ProPublica | Yes |\n",
       " | Quartz | Yes |\n",
       " | South Florida Sun Sentinel | No |\n",
       " | St Louis Public Radio | Yes |\n",
       " | Star Tribune | Yes |\n",
       " | Süddeutsche Zeitung | No |\n",
       " | Tampa Bay Times | No |\n",
       " | The Atlantic | No |\n",
       " | The Buffalo News | Yes |\n",
       " | The Economist | No |\n",
       " | The Oregonian | Yes |\n",
       " | The Texas Tribune | No |\n",
       " | The Times and Sunday Times | Yes |\n",
       " | The Washington Post | Yes |\n",
       " | Time | Yes |\n",
       " | TrendCT | Yes |\n",
       " | Vox | Yes |\n",
       " | WBEZ Chicago | No |\n",
       " | WUFT | Yes |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Which organizations were included?\n",
    "\n",
    "included_count = sum(orgs.is_included)\n",
    "total_orgs = len(orgs.name.unique())\n",
    "\n",
    "displayMarkdown(\"\"\"\n",
    "This analysis includes {included_count} news organizations out of {total} that had computational notebooks deemed relevant to this analysis ({percent}%).\n",
    "\"\"\".format(**{\n",
    "    'included_count': included_count,\n",
    "    'total': total_orgs,\n",
    "    'percent': round((included_count / total_orgs) * 100, 2),\n",
    "}))\n",
    "\n",
    "displayMarkdown(\"\"\"\n",
    "| Organization | Is included? |\n",
    "| ------------ | ------------ |\n",
    "{rows}\n",
    "\"\"\".format(**{\n",
    "    'rows': '\\n '.join([ '| {} | {} |'.format(row[0], 'Yes' if row[5] else 'No') for i, row in orgs.sort_values('name').iterrows() ])\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolificness of individual journalists\n",
    "\n",
    "In addition to taking steps to incorporate comprehensiveness and diversity of news organization into our descriptive taxonomy, we also attempt to add comprehensiveness and diversity in the individual journalists.\n",
    "\n",
    "We exclude some data journalist with commits from this summary because their commits were insignificant contributions to repos such as comments, README file updates, initial repo setup, and general code clean up.\n",
    "    \n",
    "* [Andrei Scheinkman](https://github.com/fivethirtyeight/data/commits?author=ascheink), *FiveThirtyEight*\n",
    "\n",
    "* [Dhrumil Mehta](https://github.com/fivethirtyeight/data/commits?author=dmil), *FiveThirtyEight*\n",
    "    \n",
    "* [Stephen Turner](https://github.com/fivethirtyeight/data/commits?author=stephenturner), *FiveThirtyEight*\n",
    "\n",
    "* [Nate Silver](https://github.com/fivethirtyeight/data/commits?author=natesilver538), *FiveThirtyEight*\n",
    "\n",
    "* [Dan Nguyen](https://github.com/TheUpshot/leo-senate-model/commits?author=dannguyen), *The Upshot*\n",
    "\n",
    "* [Derek Willis](https://github.com/BuzzFeedNews/2014-09-rising-sunday-show-guests/commit/780b808606d05a7d79dc6c40e5c64d03a490fe65), *BuzzFeed News*\n",
    "\n",
    "Note that this summary also excludes journalists who:\n",
    "\n",
    "* Worked collaboratively and only one of them committed code.\n",
    "    * Matt Stevens\n",
    "    * Adam Pearce\n",
    "\n",
    "* Only were included in the technical observations study via Observable notebooks\n",
    "    * Sahil Chinoy\n",
    "\n",
    "* Did not commit their own code. For example, *FiveThirtyEight* code appears to be committed by someone else.\n",
    "    * Rob Arthur\n",
    "    * Stefano Ceccon\n",
    "    * Walt Hickey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The first step is to split (a.k.a explode) rows in the `citations` data frame that represent collaborative \n",
    "# data journalism projects done by multiple journalists into separate rows. I've separated multiple authors \n",
    "# in the citations with semicolons. It's important to split the name on semicolon and space when defining \n",
    "# `citationsUnpacked` to prevent duplicates.\n",
    "\n",
    "citationsUnpacked = pd.DataFrame(list(citations.journalist.apply(lambda name: name.split('; '))),\n",
    "            index=citations.path).stack().to_frame().reset_index([0, 'path']) \\\n",
    "    .rename(columns={0: 'journalist'})\n",
    "\n",
    "citationJournalists = pd.merge(citationsUnpacked, citations.drop(['journalist'], axis=1), on='path', how='left')\n",
    "citationJournalists['name'] = citationJournalists.journalist.apply(lambda name: \"{} {}\".format(*name.split(', ')[::-1]))\n",
    "citationJournalists['is_cited'] = True\n",
    "citationJournalists = citationJournalists[['name', 'is_cited']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the `citations` data frame so that it has a primary key to join the `contributors` data frame. \n",
    "# The `journalist` column in `citations` is formatted as \"given name, surname\", so I'll swap those around.\n",
    "\n",
    "# From the `contributors` data frame, we can get a sense of the \"top\" data journalists based on how many \n",
    "# commits they've made and the number of followers of their GitHub user account.\n",
    "\n",
    "# Fun fact, this is an example of aggregate join\n",
    "dataJournalists = pd.merge(\n",
    "    contributors[['login', 'name']],\n",
    "    contributors.groupby('login').agg({'followers': max, 'commits': sum }).reset_index(),\n",
    "    on='login') \\\n",
    "    .drop_duplicates()\n",
    "\n",
    "createPk = lambda df: df.name.str.lower().str.replace(r'\\s', '')\n",
    "\n",
    "dataJournalists['pk'] = createPk(dataJournalists)\n",
    "citationJournalists['pk'] = createPk(citationJournalists)\n",
    "\n",
    "# Combine to get a data frame of journalists included and not included in analysis\n",
    "dataJournalists = pd.merge(dataJournalists, citationJournalists, how='left', on='pk') \\\n",
    "    .rename(columns={\n",
    "        'is_cited': 'is_included',\n",
    "        'followers': 'follower_count',\n",
    "        'commits': 'commit_count',\n",
    "        'name_x': 'name'\n",
    "    }) \\\n",
    "    .drop(['name_y', 'pk'], axis=1)\n",
    "\n",
    "dataJournalists.is_included.fillna(False, inplace=True)\n",
    "\n",
    "# # Rank data journalists by followers and commits\n",
    "rank(dataJournalists, 'follower_count', 'follower_rank')\n",
    "rank(dataJournalists, 'commit_count', 'commit_rank')\n",
    "\n",
    "# # Remove NAs\n",
    "dataJournalists.dropna(inplace=True)\n",
    "\n",
    "# Remove duplicates \n",
    "dataJournalists.drop_duplicates('login', inplace=True)\n",
    "\n",
    "#dataJournalists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#\n",
    "# Did we loose any journalists from the citations list when we merged it with the list of data journalists? \n",
    "# Which journalists were cited that are not in the `dataJournalists` data frame?\n",
    "\n",
    "# missing = displayMarkdown(', '.join(list(set(citationJournalists.name.str.lower()).difference(set(dataJournalists.name.str.lower())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](figs/data-journalists-commits.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklist = ['Dhrumil Mehta', 'Derek Willis', 'Stephen Turner', 'Dan Nguyen', 'Nate Silver', 'Andrei Scheinkman']\n",
    "\n",
    "# displayCoverage(\n",
    "#     df = dataJournalists[~dataJournalists.name.isin(blacklist)],\n",
    "#     title = 'Data Journalists Ranked by Commits',\n",
    "#     metric = 'commit',\n",
    "#     xlab = 'Commit Count',\n",
    "#     ylab = 'Name',\n",
    "#     ykind = 'people'\n",
    "# )\n",
    "Markdown('![](figs/data-journalists-commits.png)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig. S4**: Data journalists who authored code repositories in our pool of journalistic, data-analysis repos, ranked by number of commits. This chart is color-coded orange to indicate that the individual authored an analysis included in our technical observation study.\n",
    "\n",
    "### By followers\n",
    "\n",
    "Our qualitative analysis is based on repositories authored by the top eight data journalists ranked by the number of followers in addition to many GitHub users with less followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](figs/data-journalists-followers.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displayCoverage(\n",
    "#     df = dataJournalists[~dataJournalists.name.isin(blacklist)],\n",
    "#     title = 'Data Journalists Ranked by Followers',\n",
    "#     metric = 'follower',\n",
    "#     xlab = 'Follower Count',\n",
    "#     ylab = 'Name',\n",
    "#     ykind = 'people'\n",
    "# )\n",
    "Markdown('![](figs/data-journalists-followers.png)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure S5**: Data journalists who authored code repositories in our pool of journalistic, data-analysis repos, ranked by number of followers on GitHub. This chart is color-coded orange to indicate that the individual authored an analysis included in our technical observation study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive cross-check of multi-table framework\n",
    "\n",
    "We cross check the descriptive power of our multi-table framework for data wrangling by comparing against the high-level axial codes in our descriptive action taxonomy. We only include actions codes that correspond with table operations, hence excluding codes in the Profile branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://docs.google.com/spreadsheets/d/17XwOJo8EsbTjDwmfrnWdWvDDzeht6YtUNc-PQLSIFtk/edit?usp=sharing\n",
    "# for original chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cross-check-figure](figs/cross-check.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
